{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.detectors.zid_rcnn import ZidRCNN\n",
    "\n",
    "def build_detector(model_cfg):\n",
    "    model_cfg_ = model_cfg.copy()\n",
    "\n",
    "    model_type = model_cfg_.pop('type') \n",
    "    assert model_type == 'ZidRCNN', f'{model_type} is not implemented yet.'\n",
    "    return ZidRCNN(**model_cfg_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.builder import build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "def get_config_from_file(filename, mode):\n",
    "    spec = importlib.util.spec_from_file_location(mode, filename)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "    # Create a dictionary from module attributes\n",
    "    config_dict = {key: getattr(module, key) for key in dir(module) if not key.startswith('__')}\n",
    "    return config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhnh/python_venv/cv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/minhnh/python_venv/cv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from: torchvision://resnet50\n",
      "This is Phase 1, Voxel Reconstruction Training Phase\n",
      "Loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9600/9600 [00:01<00:00, 5598.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos: 9600\n",
      "Loading object size from existing path (we will first crop then resize the image for recon)\n"
     ]
    }
   ],
   "source": [
    "cfg = get_config_from_file('configs/train_reconstruction_conf.py', 'reconstruction')\n",
    "model = build_detector(cfg.get('model'))\n",
    "dataset = build_dataset(cfg.get('data')['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from models.utils.data_container import collate\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "num_workers=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=True,\n",
    "                collate_fn=partial(collate, samples_per_gpu=batch_size),\n",
    "                # sampler=self.train_sampler,\n",
    "                drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rgb': tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), 'traj': tensor([[[[ 1.0000e+00,  9.1633e-08, -5.8942e-08,  0.0000e+00],\n",
      "          [ 9.1633e-08,  1.0000e+00,  8.9407e-08,  0.0000e+00],\n",
      "          [-5.8942e-08,  8.9407e-08,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -6.4889e-02,  1.4234e-01,  0.0000e+00],\n",
      "          [ 6.4889e-02,  9.9788e-01,  4.6470e-03,  0.0000e+00],\n",
      "          [-1.4234e-01,  4.6467e-03,  9.8981e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.5106e-01, -1.2818e-01,  2.8118e-01,  0.0000e+00],\n",
      "          [ 1.2818e-01,  9.9158e-01,  1.8473e-02,  0.0000e+00],\n",
      "          [-2.8118e-01,  1.8472e-02,  9.5948e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0902e-01,  3.9450e-01, -8.6538e-01,  0.0000e+00],\n",
      "          [-3.9450e-01,  8.8111e-01,  2.6080e-01,  0.0000e+00],\n",
      "          [ 8.6538e-01,  2.6080e-01,  4.2791e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-9.8769e-01,  6.4889e-02, -1.4234e-01,  0.0000e+00],\n",
      "          [-6.4889e-02,  6.5800e-01,  7.5022e-01,  0.0000e+00],\n",
      "          [ 1.4234e-01,  7.5022e-01, -6.4569e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 8.0902e-01, -2.4381e-01,  5.3483e-01,  0.0000e+00],\n",
      "          [ 2.4381e-01,  9.6714e-01,  7.2083e-02,  0.0000e+00],\n",
      "          [-5.3483e-01,  7.2083e-02,  8.4188e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000e+00, -2.3206e-08,  1.9280e-08,  0.0000e+00],\n",
      "          [-2.3206e-08,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 1.9280e-08,  0.0000e+00,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -6.4603e-02,  1.4247e-01,  0.0000e+00],\n",
      "          [ 6.4603e-02,  9.9790e-01,  4.6302e-03,  0.0000e+00],\n",
      "          [-1.4247e-01,  4.6309e-03,  9.8979e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 8.9101e-01, -1.8749e-01,  4.1347e-01,  0.0000e+00],\n",
      "          [ 1.8749e-01,  9.8141e-01,  4.0994e-02,  0.0000e+00],\n",
      "          [-4.1347e-01,  4.0994e-02,  9.0960e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5399e-01,  3.6796e-01, -8.1148e-01,  0.0000e+00],\n",
      "          [-3.6796e-01,  9.0688e-01,  2.0536e-01,  0.0000e+00],\n",
      "          [ 8.1148e-01,  2.0536e-01,  5.4711e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-9.5106e-01, -1.2762e-01,  2.8143e-01,  0.0000e+00],\n",
      "          [ 1.2762e-01,  6.6725e-01,  7.3382e-01,  0.0000e+00],\n",
      "          [-2.8143e-01,  7.3382e-01, -6.1831e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -6.4603e-02,  1.4247e-01,  0.0000e+00],\n",
      "          [ 6.4603e-02,  9.9790e-01,  4.6303e-03,  0.0000e+00],\n",
      "          [-1.4247e-01,  4.6309e-03,  9.8979e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000e+00,  1.7342e-08, -2.3771e-08,  0.0000e+00],\n",
      "          [ 1.7342e-08,  1.0000e+00,  5.9605e-08,  0.0000e+00],\n",
      "          [-2.3771e-08,  5.9605e-08,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.5106e-01, -1.1865e-01,  2.8533e-01,  0.0000e+00],\n",
      "          [ 1.1865e-01,  9.9278e-01,  1.7352e-02,  0.0000e+00],\n",
      "          [-2.8533e-01,  1.7353e-02,  9.5827e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 8.9101e-01, -1.7432e-01,  4.1919e-01,  0.0000e+00],\n",
      "          [ 1.7432e-01,  9.8393e-01,  3.8642e-02,  0.0000e+00],\n",
      "          [-4.1919e-01,  3.8642e-02,  9.0708e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5399e-01,  3.4212e-01, -8.2271e-01,  0.0000e+00],\n",
      "          [-3.4212e-01,  9.1950e-01,  1.9358e-01,  0.0000e+00],\n",
      "          [ 8.2271e-01,  1.9358e-01,  5.3449e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-3.5763e-07,  3.8397e-01, -9.2335e-01,  0.0000e+00],\n",
      "          [-3.8397e-01,  8.5257e-01,  3.5454e-01,  0.0000e+00],\n",
      "          [ 9.2335e-01,  3.5454e-01,  1.4743e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-1.5643e-01, -3.7924e-01,  9.1198e-01,  0.0000e+00],\n",
      "          [ 3.7924e-01,  8.2950e-01,  4.1000e-01,  0.0000e+00],\n",
      "          [-9.1198e-01,  4.1000e-01,  1.4063e-02,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0000e+00, -2.2192e-08,  2.2680e-08,  0.0000e+00],\n",
      "          [-2.2192e-08,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 2.2680e-08,  0.0000e+00,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -7.5596e-02,  1.3696e-01,  0.0000e+00],\n",
      "          [ 7.5596e-02,  9.9712e-01,  5.2088e-03,  0.0000e+00],\n",
      "          [-1.3696e-01,  5.2088e-03,  9.9056e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.5106e-01, -1.4933e-01,  2.7054e-01,  0.0000e+00],\n",
      "          [ 1.4933e-01,  9.8857e-01,  2.0707e-02,  0.0000e+00],\n",
      "          [-2.7054e-01,  2.0707e-02,  9.6249e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.9101e-01, -2.1939e-01,  3.9746e-01,  0.0000e+00],\n",
      "          [ 2.1939e-01,  5.5840e-01,  8.0004e-01,  0.0000e+00],\n",
      "          [-3.9746e-01,  8.0004e-01, -4.4941e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-4.5399e-01, -4.3057e-01,  7.8006e-01,  0.0000e+00],\n",
      "          [ 4.3057e-01,  6.6046e-01,  6.1515e-01,  0.0000e+00],\n",
      "          [-7.8006e-01,  6.1515e-01, -1.1445e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-1.5643e-01, -4.7730e-01,  8.6471e-01,  0.0000e+00],\n",
      "          [ 4.7730e-01,  7.2994e-01,  4.8926e-01,  0.0000e+00],\n",
      "          [-8.6471e-01,  4.8926e-01,  1.1362e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000e+00, -1.7223e-08, -3.8344e-09,  0.0000e+00],\n",
      "          [-1.7223e-08,  1.0000e+00,  2.9802e-08,  0.0000e+00],\n",
      "          [-3.8344e-09,  2.9802e-08,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -8.8267e-02,  1.2915e-01,  0.0000e+00],\n",
      "          [ 8.8267e-02,  9.9608e-01,  5.7350e-03,  0.0000e+00],\n",
      "          [-1.2915e-01,  5.7357e-03,  9.9161e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.5106e-01, -1.7436e-01,  2.5513e-01,  0.0000e+00],\n",
      "          [ 1.7436e-01,  9.8442e-01,  2.2800e-02,  0.0000e+00],\n",
      "          [-2.5513e-01,  2.2800e-02,  9.6664e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0902e-01,  5.3663e-01, -7.8520e-01,  0.0000e+00],\n",
      "          [-5.3663e-01,  5.8325e-01,  6.0980e-01,  0.0000e+00],\n",
      "          [ 7.8520e-01,  6.0980e-01,  1.0774e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-9.5106e-01, -1.7436e-01,  2.5513e-01,  0.0000e+00],\n",
      "          [ 1.7436e-01,  3.7884e-01,  9.0889e-01,  0.0000e+00],\n",
      "          [-2.5513e-01,  9.0889e-01, -3.2990e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 5.8779e-01, -4.5648e-01,  6.6793e-01,  0.0000e+00],\n",
      "          [ 4.5648e-01,  8.6876e-01,  1.9203e-01,  0.0000e+00],\n",
      "          [-6.6793e-01,  1.9203e-01,  7.1902e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000e+00,  7.6595e-10, -1.9264e-08,  0.0000e+00],\n",
      "          [ 7.6595e-10,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [-1.9264e-08,  0.0000e+00,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -5.9871e-02,  1.4452e-01,  0.0000e+00],\n",
      "          [ 5.9871e-02,  9.9820e-01,  4.3526e-03,  0.0000e+00],\n",
      "          [-1.4452e-01,  4.3538e-03,  9.8949e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.5106e-01, -1.1827e-01,  2.8549e-01,  0.0000e+00],\n",
      "          [ 1.1827e-01,  9.9283e-01,  1.7305e-02,  0.0000e+00],\n",
      "          [-2.8549e-01,  1.7306e-02,  9.5823e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.8769e-01, -5.9871e-02,  1.4452e-01,  0.0000e+00],\n",
      "          [ 5.9871e-02,  7.0885e-01,  7.0281e-01,  0.0000e+00],\n",
      "          [-1.4452e-01,  7.0281e-01, -6.9654e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-3.0902e-01, -3.6399e-01,  8.7865e-01,  0.0000e+00],\n",
      "          [ 3.6399e-01,  8.0826e-01,  4.6285e-01,  0.0000e+00],\n",
      "          [-8.7865e-01,  4.6285e-01, -1.1728e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 8.0902e-01, -2.2496e-01,  5.4303e-01,  0.0000e+00],\n",
      "          [ 2.2496e-01,  9.7203e-01,  6.7529e-02,  0.0000e+00],\n",
      "          [-5.4303e-01,  6.7528e-02,  8.3699e-01,  0.0000e+00]]]])}\n"
     ]
    }
   ],
   "source": [
    "for x in data:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdab425fa30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x['rgb'][7][34].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'ep01', '100000']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"_ep01_100000\".split(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ep01'[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./results\n",
      "Loading dataset ...\n",
      "This is Phase 1, Voxel Reconstruction Training Phase\n",
      "Loading images...\n",
      "100%|█████████████████████████████████████| 9600/9600 [00:01<00:00, 5592.22it/s]\n",
      "Videos: 9600\n",
      "Loading object size from existing path (we will first crop then resize the image for recon)\n",
      "training...\n",
      "Training on 4 GPUs: 0,1,2,3\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "load model from: torchvision://resnet50\n",
      "load model from: torchvision://resnet50\n",
      "load model from: torchvision://resnet50\n",
      "load model from: torchvision://resnet50\n",
      "Rank: 3 - Device: cuda:3 3\n",
      "Rank: 0 - Device: cuda:0 0\n",
      "Rank: 1 - Device: cuda:1 1\n",
      "Rank: 2 - Device: cuda:2 2\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4377: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4377: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4377: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4377: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | 0.00229  |\n",
      "| grad_norm   | 10.5     |\n",
      "| loss        | 2.32     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.175    |\n",
      "| recon_loss  | 2.22     |\n",
      "| samples     | 32       |\n",
      "| step        | 0        |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0317  |\n",
      "| grad_norm   | 7.69     |\n",
      "| loss        | 2.22     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.124    |\n",
      "| recon_loss  | 2.1      |\n",
      "| samples     | 352      |\n",
      "| step        | 10       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0538  |\n",
      "| grad_norm   | 4.06     |\n",
      "| loss        | 1.83     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0725   |\n",
      "| recon_loss  | 1.77     |\n",
      "| samples     | 672      |\n",
      "| step        | 20       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0647  |\n",
      "| grad_norm   | 3.02     |\n",
      "| loss        | 1.46     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0466   |\n",
      "| recon_loss  | 1.52     |\n",
      "| samples     | 992      |\n",
      "| step        | 30       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0709  |\n",
      "| grad_norm   | 2.62     |\n",
      "| loss        | 1.62     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0384   |\n",
      "| recon_loss  | 1.58     |\n",
      "| samples     | 1.31e+03 |\n",
      "| step        | 40       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0768  |\n",
      "| grad_norm   | 2.71     |\n",
      "| loss        | 1.41     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.035    |\n",
      "| recon_loss  | 1.47     |\n",
      "| samples     | 1.63e+03 |\n",
      "| step        | 50       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0699  |\n",
      "| grad_norm   | 4.14     |\n",
      "| loss        | 1.32     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0388   |\n",
      "| recon_loss  | 1.32     |\n",
      "| samples     | 1.95e+03 |\n",
      "| step        | 60       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.065   |\n",
      "| grad_norm   | 6.85     |\n",
      "| loss        | 1.04     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0377   |\n",
      "| recon_loss  | 1.07     |\n",
      "| samples     | 2.27e+03 |\n",
      "| step        | 70       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0741  |\n",
      "| grad_norm   | 6.33     |\n",
      "| loss        | 0.925    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0326   |\n",
      "| recon_loss  | 0.963    |\n",
      "| samples     | 2.59e+03 |\n",
      "| step        | 80       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.063   |\n",
      "| grad_norm   | 7.05     |\n",
      "| loss        | 0.888    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0271   |\n",
      "| recon_loss  | 0.942    |\n",
      "| samples     | 2.91e+03 |\n",
      "| step        | 90       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0821  |\n",
      "| grad_norm   | 8.73     |\n",
      "| loss        | 0.818    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0234   |\n",
      "| recon_loss  | 0.886    |\n",
      "| samples     | 3.23e+03 |\n",
      "| step        | 100      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.094   |\n",
      "| grad_norm   | 6.58     |\n",
      "| loss        | 0.723    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0189   |\n",
      "| recon_loss  | 0.853    |\n",
      "| samples     | 3.55e+03 |\n",
      "| step        | 110      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.1     |\n",
      "| grad_norm   | 7.12     |\n",
      "| loss        | 0.645    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0166   |\n",
      "| recon_loss  | 0.749    |\n",
      "| samples     | 3.87e+03 |\n",
      "| step        | 120      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.106   |\n",
      "| grad_norm   | 7.61     |\n",
      "| loss        | 0.633    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0155   |\n",
      "| recon_loss  | 0.745    |\n",
      "| samples     | 4.19e+03 |\n",
      "| step        | 130      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.112   |\n",
      "| grad_norm   | 7.69     |\n",
      "| loss        | 0.583    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0138   |\n",
      "| recon_loss  | 0.707    |\n",
      "| samples     | 4.51e+03 |\n",
      "| step        | 140      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.118   |\n",
      "| grad_norm   | 10.3     |\n",
      "| loss        | 0.598    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0132   |\n",
      "| recon_loss  | 0.731    |\n",
      "| samples     | 4.83e+03 |\n",
      "| step        | 150      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.123   |\n",
      "| grad_norm   | 9.06     |\n",
      "| loss        | 0.559    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0126   |\n",
      "| recon_loss  | 0.698    |\n",
      "| samples     | 5.15e+03 |\n",
      "| step        | 160      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.129   |\n",
      "| grad_norm   | 11.5     |\n",
      "| loss        | 0.553    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0117   |\n",
      "| recon_loss  | 0.674    |\n",
      "| samples     | 5.47e+03 |\n",
      "| step        | 170      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.135   |\n",
      "| grad_norm   | 6.11     |\n",
      "| loss        | 0.568    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0114   |\n",
      "| recon_loss  | 0.69     |\n",
      "| samples     | 5.79e+03 |\n",
      "| step        | 180      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.141   |\n",
      "| grad_norm   | 8.21     |\n",
      "| loss        | 0.506    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0106   |\n",
      "| recon_loss  | 0.639    |\n",
      "| samples     | 6.11e+03 |\n",
      "| step        | 190      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.146   |\n",
      "| grad_norm   | 7.63     |\n",
      "| loss        | 0.467    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0105   |\n",
      "| recon_loss  | 0.622    |\n",
      "| samples     | 6.43e+03 |\n",
      "| step        | 200      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.153   |\n",
      "| grad_norm   | 9.95     |\n",
      "| loss        | 0.486    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00953  |\n",
      "| recon_loss  | 0.614    |\n",
      "| samples     | 6.75e+03 |\n",
      "| step        | 210      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.159   |\n",
      "| grad_norm   | 8.63     |\n",
      "| loss        | 0.466    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00965  |\n",
      "| recon_loss  | 0.643    |\n",
      "| samples     | 7.07e+03 |\n",
      "| step        | 220      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.164   |\n",
      "| grad_norm   | 8.06     |\n",
      "| loss        | 0.438    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00902  |\n",
      "| recon_loss  | 0.608    |\n",
      "| samples     | 7.39e+03 |\n",
      "| step        | 230      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.171   |\n",
      "| grad_norm   | 9.85     |\n",
      "| loss        | 0.453    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00836  |\n",
      "| recon_loss  | 0.621    |\n",
      "| samples     | 7.71e+03 |\n",
      "| step        | 240      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.177   |\n",
      "| grad_norm   | 10.1     |\n",
      "| loss        | 0.418    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00836  |\n",
      "| recon_loss  | 0.588    |\n",
      "| samples     | 8.03e+03 |\n",
      "| step        | 250      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.183   |\n",
      "| grad_norm   | 8.04     |\n",
      "| loss        | 0.401    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00801  |\n",
      "| recon_loss  | 0.579    |\n",
      "| samples     | 8.35e+03 |\n",
      "| step        | 260      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.19    |\n",
      "| grad_norm   | 10.2     |\n",
      "| loss        | 0.375    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00747  |\n",
      "| recon_loss  | 0.56     |\n",
      "| samples     | 8.67e+03 |\n",
      "| step        | 270      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.196   |\n",
      "| grad_norm   | 6.18     |\n",
      "| loss        | 0.347    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00759  |\n",
      "| recon_loss  | 0.545    |\n",
      "| samples     | 8.99e+03 |\n",
      "| step        | 280      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.203   |\n",
      "| grad_norm   | 6.3      |\n",
      "| loss        | 0.323    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00702  |\n",
      "| recon_loss  | 0.529    |\n",
      "| samples     | 9.31e+03 |\n",
      "| step        | 290      |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.209   |\n",
      "| grad_norm   | 10.4     |\n",
      "| loss        | 0.324    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00646  |\n",
      "| recon_loss  | 0.524    |\n",
      "| samples     | 9.63e+03 |\n",
      "| step        | 300      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.215   |\n",
      "| grad_norm   | 8.61     |\n",
      "| loss        | 0.317    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00656  |\n",
      "| recon_loss  | 0.541    |\n",
      "| samples     | 9.95e+03 |\n",
      "| step        | 310      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.222   |\n",
      "| grad_norm   | 7.67     |\n",
      "| loss        | 0.309    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0064   |\n",
      "| recon_loss  | 0.522    |\n",
      "| samples     | 1.03e+04 |\n",
      "| step        | 320      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.228   |\n",
      "| grad_norm   | 7.44     |\n",
      "| loss        | 0.281    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00607  |\n",
      "| recon_loss  | 0.512    |\n",
      "| samples     | 1.06e+04 |\n",
      "| step        | 330      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.235   |\n",
      "| grad_norm   | 10       |\n",
      "| loss        | 0.314    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00568  |\n",
      "| recon_loss  | 0.528    |\n",
      "| samples     | 1.09e+04 |\n",
      "| step        | 340      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.242   |\n",
      "| grad_norm   | 8.25     |\n",
      "| loss        | 0.274    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00559  |\n",
      "| recon_loss  | 0.509    |\n",
      "| samples     | 1.12e+04 |\n",
      "| step        | 350      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.248   |\n",
      "| grad_norm   | 5.68     |\n",
      "| loss        | 0.225    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00555  |\n",
      "| recon_loss  | 0.473    |\n",
      "| samples     | 1.16e+04 |\n",
      "| step        | 360      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.255   |\n",
      "| grad_norm   | 7.4      |\n",
      "| loss        | 0.249    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0055   |\n",
      "| recon_loss  | 0.511    |\n",
      "| samples     | 1.19e+04 |\n",
      "| step        | 370      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.261   |\n",
      "| grad_norm   | 8.21     |\n",
      "| loss        | 0.252    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00541  |\n",
      "| recon_loss  | 0.501    |\n",
      "| samples     | 1.22e+04 |\n",
      "| step        | 380      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.268   |\n",
      "| grad_norm   | 10.1     |\n",
      "| loss        | 0.263    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00523  |\n",
      "| recon_loss  | 0.508    |\n",
      "| samples     | 1.25e+04 |\n",
      "| step        | 390      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.274   |\n",
      "| grad_norm   | 10.2     |\n",
      "| loss        | 0.227    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00486  |\n",
      "| recon_loss  | 0.49     |\n",
      "| samples     | 1.28e+04 |\n",
      "| step        | 400      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.281   |\n",
      "| grad_norm   | 8.09     |\n",
      "| loss        | 0.221    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00475  |\n",
      "| recon_loss  | 0.485    |\n",
      "| samples     | 1.32e+04 |\n",
      "| step        | 410      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.288   |\n",
      "| grad_norm   | 9.31     |\n",
      "| loss        | 0.224    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00487  |\n",
      "| recon_loss  | 0.497    |\n",
      "| samples     | 1.35e+04 |\n",
      "| step        | 420      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.294   |\n",
      "| grad_norm   | 10.9     |\n",
      "| loss        | 0.222    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00442  |\n",
      "| recon_loss  | 0.497    |\n",
      "| samples     | 1.38e+04 |\n",
      "| step        | 430      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.301   |\n",
      "| grad_norm   | 7.99     |\n",
      "| loss        | 0.191    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00459  |\n",
      "| recon_loss  | 0.488    |\n",
      "| samples     | 1.41e+04 |\n",
      "| step        | 440      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.308   |\n",
      "| grad_norm   | 5.73     |\n",
      "| loss        | 0.15     |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0043   |\n",
      "| recon_loss  | 0.476    |\n",
      "| samples     | 1.44e+04 |\n",
      "| step        | 450      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.314   |\n",
      "| grad_norm   | 9.11     |\n",
      "| loss        | 0.178    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00423  |\n",
      "| recon_loss  | 0.481    |\n",
      "| samples     | 1.48e+04 |\n",
      "| step        | 460      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.321   |\n",
      "| grad_norm   | 7.41     |\n",
      "| loss        | 0.196    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00423  |\n",
      "| recon_loss  | 0.493    |\n",
      "| samples     | 1.51e+04 |\n",
      "| step        | 470      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.328   |\n",
      "| grad_norm   | 6.55     |\n",
      "| loss        | 0.124    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00397  |\n",
      "| recon_loss  | 0.457    |\n",
      "| samples     | 1.54e+04 |\n",
      "| step        | 480      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.334   |\n",
      "| grad_norm   | 7.63     |\n",
      "| loss        | 0.115    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00402  |\n",
      "| recon_loss  | 0.453    |\n",
      "| samples     | 1.57e+04 |\n",
      "| step        | 490      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.341   |\n",
      "| grad_norm   | 6.6      |\n",
      "| loss        | 0.104    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0037   |\n",
      "| recon_loss  | 0.443    |\n",
      "| samples     | 1.6e+04  |\n",
      "| step        | 500      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.347   |\n",
      "| grad_norm   | 8.07     |\n",
      "| loss        | 0.118    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00387  |\n",
      "| recon_loss  | 0.474    |\n",
      "| samples     | 1.64e+04 |\n",
      "| step        | 510      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.353   |\n",
      "| grad_norm   | 8.61     |\n",
      "| loss        | 0.104    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00364  |\n",
      "| recon_loss  | 0.435    |\n",
      "| samples     | 1.67e+04 |\n",
      "| step        | 520      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.36    |\n",
      "| grad_norm   | 8.07     |\n",
      "| loss        | 0.0721   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00345  |\n",
      "| recon_loss  | 0.432    |\n",
      "| samples     | 1.7e+04  |\n",
      "| step        | 530      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.367   |\n",
      "| grad_norm   | 7.11     |\n",
      "| loss        | 0.0781   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00347  |\n",
      "| recon_loss  | 0.444    |\n",
      "| samples     | 1.73e+04 |\n",
      "| step        | 540      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.373   |\n",
      "| grad_norm   | 8.76     |\n",
      "| loss        | 0.0721   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00331  |\n",
      "| recon_loss  | 0.441    |\n",
      "| samples     | 1.76e+04 |\n",
      "| step        | 550      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.38    |\n",
      "| grad_norm   | 7.85     |\n",
      "| loss        | 0.0634   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00322  |\n",
      "| recon_loss  | 0.434    |\n",
      "| samples     | 1.8e+04  |\n",
      "| step        | 560      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.387   |\n",
      "| grad_norm   | 8.15     |\n",
      "| loss        | 0.068    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00317  |\n",
      "| recon_loss  | 0.437    |\n",
      "| samples     | 1.83e+04 |\n",
      "| step        | 570      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.393   |\n",
      "| grad_norm   | 7.75     |\n",
      "| loss        | 0.0342   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00299  |\n",
      "| recon_loss  | 0.43     |\n",
      "| samples     | 1.86e+04 |\n",
      "| step        | 580      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.399   |\n",
      "| grad_norm   | 5.69     |\n",
      "| loss        | 0.0127   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00298  |\n",
      "| recon_loss  | 0.425    |\n",
      "| samples     | 1.89e+04 |\n",
      "| step        | 590      |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.406   |\n",
      "| grad_norm   | 5.29     |\n",
      "| loss        | 0.0123   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00282  |\n",
      "| recon_loss  | 0.418    |\n",
      "| samples     | 1.92e+04 |\n",
      "| step        | 600      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.413   |\n",
      "| grad_norm   | 6.62     |\n",
      "| loss        | -0.015   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00277  |\n",
      "| recon_loss  | 0.406    |\n",
      "| samples     | 1.96e+04 |\n",
      "| step        | 610      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.42    |\n",
      "| grad_norm   | 7.61     |\n",
      "| loss        | 0.00554  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00282  |\n",
      "| recon_loss  | 0.418    |\n",
      "| samples     | 1.99e+04 |\n",
      "| step        | 620      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.426   |\n",
      "| grad_norm   | 7.64     |\n",
      "| loss        | 0.00805  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00283  |\n",
      "| recon_loss  | 0.44     |\n",
      "| samples     | 2.02e+04 |\n",
      "| step        | 630      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.433   |\n",
      "| grad_norm   | 4.71     |\n",
      "| loss        | -0.0246  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00278  |\n",
      "| recon_loss  | 0.422    |\n",
      "| samples     | 2.05e+04 |\n",
      "| step        | 640      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.439   |\n",
      "| grad_norm   | 4.68     |\n",
      "| loss        | -0.0429  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00258  |\n",
      "| recon_loss  | 0.406    |\n",
      "| samples     | 2.08e+04 |\n",
      "| step        | 650      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.446   |\n",
      "| grad_norm   | 6.69     |\n",
      "| loss        | -0.0508  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00252  |\n",
      "| recon_loss  | 0.418    |\n",
      "| samples     | 2.12e+04 |\n",
      "| step        | 660      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.452   |\n",
      "| grad_norm   | 4.67     |\n",
      "| loss        | -0.0408  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00248  |\n",
      "| recon_loss  | 0.403    |\n",
      "| samples     | 2.15e+04 |\n",
      "| step        | 670      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.459   |\n",
      "| grad_norm   | 6.75     |\n",
      "| loss        | -0.0679  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00241  |\n",
      "| recon_loss  | 0.405    |\n",
      "| samples     | 2.18e+04 |\n",
      "| step        | 680      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.466   |\n",
      "| grad_norm   | 5.69     |\n",
      "| loss        | -0.0877  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0025   |\n",
      "| recon_loss  | 0.389    |\n",
      "| samples     | 2.21e+04 |\n",
      "| step        | 690      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.472   |\n",
      "| grad_norm   | 5.95     |\n",
      "| loss        | -0.0691  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00238  |\n",
      "| recon_loss  | 0.413    |\n",
      "| samples     | 2.24e+04 |\n",
      "| step        | 700      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.479   |\n",
      "| grad_norm   | 6.01     |\n",
      "| loss        | -0.059   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0023   |\n",
      "| recon_loss  | 0.419    |\n",
      "| samples     | 2.28e+04 |\n",
      "| step        | 710      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.485   |\n",
      "| grad_norm   | 7.09     |\n",
      "| loss        | -0.0887  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00222  |\n",
      "| recon_loss  | 0.411    |\n",
      "| samples     | 2.31e+04 |\n",
      "| step        | 720      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.492   |\n",
      "| grad_norm   | 8.56     |\n",
      "| loss        | -0.092   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00204  |\n",
      "| recon_loss  | 0.41     |\n",
      "| samples     | 2.34e+04 |\n",
      "| step        | 730      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.499   |\n",
      "| grad_norm   | 6.3      |\n",
      "| loss        | -0.105   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00217  |\n",
      "| recon_loss  | 0.412    |\n",
      "| samples     | 2.37e+04 |\n",
      "| step        | 740      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.505   |\n",
      "| grad_norm   | 8.37     |\n",
      "| loss        | -0.0815  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0021   |\n",
      "| recon_loss  | 0.415    |\n",
      "| samples     | 2.4e+04  |\n",
      "| step        | 750      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.51    |\n",
      "| grad_norm   | 6.76     |\n",
      "| loss        | -0.123   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00208  |\n",
      "| recon_loss  | 0.394    |\n",
      "| samples     | 2.44e+04 |\n",
      "| step        | 760      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.518   |\n",
      "| grad_norm   | 4.98     |\n",
      "| loss        | -0.126   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00199  |\n",
      "| recon_loss  | 0.402    |\n",
      "| samples     | 2.47e+04 |\n",
      "| step        | 770      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.524   |\n",
      "| grad_norm   | 5.81     |\n",
      "| loss        | -0.122   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.002    |\n",
      "| recon_loss  | 0.416    |\n",
      "| samples     | 2.5e+04  |\n",
      "| step        | 780      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.531   |\n",
      "| grad_norm   | 6.17     |\n",
      "| loss        | -0.126   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00201  |\n",
      "| recon_loss  | 0.396    |\n",
      "| samples     | 2.53e+04 |\n",
      "| step        | 790      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.538   |\n",
      "| grad_norm   | 5.39     |\n",
      "| loss        | -0.168   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00183  |\n",
      "| recon_loss  | 0.382    |\n",
      "| samples     | 2.56e+04 |\n",
      "| step        | 800      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.544   |\n",
      "| grad_norm   | 6.79     |\n",
      "| loss        | -0.164   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00179  |\n",
      "| recon_loss  | 0.382    |\n",
      "| samples     | 2.6e+04  |\n",
      "| step        | 810      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.551   |\n",
      "| grad_norm   | 5.67     |\n",
      "| loss        | -0.18    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0018   |\n",
      "| recon_loss  | 0.39     |\n",
      "| samples     | 2.63e+04 |\n",
      "| step        | 820      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.557   |\n",
      "| grad_norm   | 7.12     |\n",
      "| loss        | -0.158   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00179  |\n",
      "| recon_loss  | 0.405    |\n",
      "| samples     | 2.66e+04 |\n",
      "| step        | 830      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.564   |\n",
      "| grad_norm   | 6.98     |\n",
      "| loss        | -0.196   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00177  |\n",
      "| recon_loss  | 0.373    |\n",
      "| samples     | 2.69e+04 |\n",
      "| step        | 840      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.571   |\n",
      "| grad_norm   | 5.71     |\n",
      "| loss        | -0.191   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00173  |\n",
      "| recon_loss  | 0.371    |\n",
      "| samples     | 2.72e+04 |\n",
      "| step        | 850      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.577   |\n",
      "| grad_norm   | 6.13     |\n",
      "| loss        | -0.186   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0017   |\n",
      "| recon_loss  | 0.39     |\n",
      "| samples     | 2.76e+04 |\n",
      "| step        | 860      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.584   |\n",
      "| grad_norm   | 8.5      |\n",
      "| loss        | -0.208   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00155  |\n",
      "| recon_loss  | 0.374    |\n",
      "| samples     | 2.79e+04 |\n",
      "| step        | 870      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.59    |\n",
      "| grad_norm   | 7.91     |\n",
      "| loss        | -0.183   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00176  |\n",
      "| recon_loss  | 0.408    |\n",
      "| samples     | 2.82e+04 |\n",
      "| step        | 880      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.597   |\n",
      "| grad_norm   | 7.02     |\n",
      "| loss        | -0.195   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00161  |\n",
      "| recon_loss  | 0.384    |\n",
      "| samples     | 2.85e+04 |\n",
      "| step        | 890      |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.604   |\n",
      "| grad_norm   | 8.32     |\n",
      "| loss        | -0.239   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00147  |\n",
      "| recon_loss  | 0.373    |\n",
      "| samples     | 2.88e+04 |\n",
      "| step        | 900      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.61    |\n",
      "| grad_norm   | 9.14     |\n",
      "| loss        | -0.227   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00155  |\n",
      "| recon_loss  | 0.39     |\n",
      "| samples     | 2.92e+04 |\n",
      "| step        | 910      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.616   |\n",
      "| grad_norm   | 8.26     |\n",
      "| loss        | -0.221   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00144  |\n",
      "| recon_loss  | 0.381    |\n",
      "| samples     | 2.95e+04 |\n",
      "| step        | 920      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.623   |\n",
      "| grad_norm   | 7.06     |\n",
      "| loss        | -0.26    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00143  |\n",
      "| recon_loss  | 0.375    |\n",
      "| samples     | 2.98e+04 |\n",
      "| step        | 930      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.629   |\n",
      "| grad_norm   | 7.74     |\n",
      "| loss        | -0.261   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00146  |\n",
      "| recon_loss  | 0.387    |\n",
      "| samples     | 3.01e+04 |\n",
      "| step        | 940      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.636   |\n",
      "| grad_norm   | 7.15     |\n",
      "| loss        | -0.253   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00136  |\n",
      "| recon_loss  | 0.385    |\n",
      "| samples     | 3.04e+04 |\n",
      "| step        | 950      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.643   |\n",
      "| grad_norm   | 6.02     |\n",
      "| loss        | -0.272   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0014   |\n",
      "| recon_loss  | 0.378    |\n",
      "| samples     | 3.08e+04 |\n",
      "| step        | 960      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.65    |\n",
      "| grad_norm   | 6.81     |\n",
      "| loss        | -0.296   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0012   |\n",
      "| recon_loss  | 0.363    |\n",
      "| samples     | 3.11e+04 |\n",
      "| step        | 970      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.656   |\n",
      "| grad_norm   | 7.2      |\n",
      "| loss        | -0.274   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00137  |\n",
      "| recon_loss  | 0.38     |\n",
      "| samples     | 3.14e+04 |\n",
      "| step        | 980      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.663   |\n",
      "| grad_norm   | 6.99     |\n",
      "| loss        | -0.262   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00136  |\n",
      "| recon_loss  | 0.388    |\n",
      "| samples     | 3.17e+04 |\n",
      "| step        | 990      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.67    |\n",
      "| grad_norm   | 5.57     |\n",
      "| loss        | -0.298   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00117  |\n",
      "| recon_loss  | 0.374    |\n",
      "| samples     | 3.2e+04  |\n",
      "| step        | 1e+03    |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.676   |\n",
      "| grad_norm   | 5.44     |\n",
      "| loss        | -0.321   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00126  |\n",
      "| recon_loss  | 0.374    |\n",
      "| samples     | 3.24e+04 |\n",
      "| step        | 1.01e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.683   |\n",
      "| grad_norm   | 6.43     |\n",
      "| loss        | -0.318   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00129  |\n",
      "| recon_loss  | 0.384    |\n",
      "| samples     | 3.27e+04 |\n",
      "| step        | 1.02e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.689   |\n",
      "| grad_norm   | 8.24     |\n",
      "| loss        | -0.296   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00125  |\n",
      "| recon_loss  | 0.392    |\n",
      "| samples     | 3.3e+04  |\n",
      "| step        | 1.03e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.696   |\n",
      "| grad_norm   | 7.46     |\n",
      "| loss        | -0.314   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00122  |\n",
      "| recon_loss  | 0.38     |\n",
      "| samples     | 3.33e+04 |\n",
      "| step        | 1.04e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.702   |\n",
      "| grad_norm   | 6.33     |\n",
      "| loss        | -0.333   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00112  |\n",
      "| recon_loss  | 0.376    |\n",
      "| samples     | 3.36e+04 |\n",
      "| step        | 1.05e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.709   |\n",
      "| grad_norm   | 5.87     |\n",
      "| loss        | -0.347   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00111  |\n",
      "| recon_loss  | 0.367    |\n",
      "| samples     | 3.4e+04  |\n",
      "| step        | 1.06e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.716   |\n",
      "| grad_norm   | 5.69     |\n",
      "| loss        | -0.358   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00111  |\n",
      "| recon_loss  | 0.358    |\n",
      "| samples     | 3.43e+04 |\n",
      "| step        | 1.07e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.722   |\n",
      "| grad_norm   | 5.56     |\n",
      "| loss        | -0.374   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00102  |\n",
      "| recon_loss  | 0.342    |\n",
      "| samples     | 3.46e+04 |\n",
      "| step        | 1.08e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.729   |\n",
      "| grad_norm   | 5.84     |\n",
      "| loss        | -0.344   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00109  |\n",
      "| recon_loss  | 0.392    |\n",
      "| samples     | 3.49e+04 |\n",
      "| step        | 1.09e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.735   |\n",
      "| grad_norm   | 6.7      |\n",
      "| loss        | -0.379   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00107  |\n",
      "| recon_loss  | 0.374    |\n",
      "| samples     | 3.52e+04 |\n",
      "| step        | 1.1e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.742   |\n",
      "| grad_norm   | 7.05     |\n",
      "| loss        | -0.405   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00107  |\n",
      "| recon_loss  | 0.355    |\n",
      "| samples     | 3.56e+04 |\n",
      "| step        | 1.11e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.748   |\n",
      "| grad_norm   | 6.04     |\n",
      "| loss        | -0.393   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000995 |\n",
      "| recon_loss  | 0.356    |\n",
      "| samples     | 3.59e+04 |\n",
      "| step        | 1.12e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.755   |\n",
      "| grad_norm   | 6.42     |\n",
      "| loss        | -0.41    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000967 |\n",
      "| recon_loss  | 0.348    |\n",
      "| samples     | 3.62e+04 |\n",
      "| step        | 1.13e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.761   |\n",
      "| grad_norm   | 5.6      |\n",
      "| loss        | -0.44    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000912 |\n",
      "| recon_loss  | 0.335    |\n",
      "| samples     | 3.65e+04 |\n",
      "| step        | 1.14e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.768   |\n",
      "| grad_norm   | 5.91     |\n",
      "| loss        | -0.433   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0009   |\n",
      "| recon_loss  | 0.338    |\n",
      "| samples     | 3.68e+04 |\n",
      "| step        | 1.15e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.774   |\n",
      "| grad_norm   | 6.01     |\n",
      "| loss        | -0.401   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000944 |\n",
      "| recon_loss  | 0.37     |\n",
      "| samples     | 3.72e+04 |\n",
      "| step        | 1.16e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.781   |\n",
      "| grad_norm   | 5.87     |\n",
      "| loss        | -0.452   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000897 |\n",
      "| recon_loss  | 0.339    |\n",
      "| samples     | 3.75e+04 |\n",
      "| step        | 1.17e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.788   |\n",
      "| grad_norm   | 7.06     |\n",
      "| loss        | -0.423   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000969 |\n",
      "| recon_loss  | 0.357    |\n",
      "| samples     | 3.78e+04 |\n",
      "| step        | 1.18e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.794   |\n",
      "| grad_norm   | 7.07     |\n",
      "| loss        | -0.431   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000928 |\n",
      "| recon_loss  | 0.367    |\n",
      "| samples     | 3.81e+04 |\n",
      "| step        | 1.19e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.801   |\n",
      "| grad_norm   | 6.44     |\n",
      "| loss        | -0.447   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000851 |\n",
      "| recon_loss  | 0.362    |\n",
      "| samples     | 3.84e+04 |\n",
      "| step        | 1.2e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.807   |\n",
      "| grad_norm   | 6.17     |\n",
      "| loss        | -0.469   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000901 |\n",
      "| recon_loss  | 0.355    |\n",
      "| samples     | 3.88e+04 |\n",
      "| step        | 1.21e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.814   |\n",
      "| grad_norm   | 4.66     |\n",
      "| loss        | -0.482   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00085  |\n",
      "| recon_loss  | 0.344    |\n",
      "| samples     | 3.91e+04 |\n",
      "| step        | 1.22e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.82    |\n",
      "| grad_norm   | 5.62     |\n",
      "| loss        | -0.474   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000875 |\n",
      "| recon_loss  | 0.354    |\n",
      "| samples     | 3.94e+04 |\n",
      "| step        | 1.23e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.826   |\n",
      "| grad_norm   | 5.73     |\n",
      "| loss        | -0.501   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000748 |\n",
      "| recon_loss  | 0.33     |\n",
      "| samples     | 3.97e+04 |\n",
      "| step        | 1.24e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.833   |\n",
      "| grad_norm   | 7.04     |\n",
      "| loss        | -0.496   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000826 |\n",
      "| recon_loss  | 0.355    |\n",
      "| samples     | 4e+04    |\n",
      "| step        | 1.25e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.84    |\n",
      "| grad_norm   | 6.53     |\n",
      "| loss        | -0.477   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000946 |\n",
      "| recon_loss  | 0.376    |\n",
      "| samples     | 4.04e+04 |\n",
      "| step        | 1.26e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.846   |\n",
      "| grad_norm   | 6.92     |\n",
      "| loss        | -0.508   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000773 |\n",
      "| recon_loss  | 0.34     |\n",
      "| samples     | 4.07e+04 |\n",
      "| step        | 1.27e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.853   |\n",
      "| grad_norm   | 5.63     |\n",
      "| loss        | -0.494   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000817 |\n",
      "| recon_loss  | 0.359    |\n",
      "| samples     | 4.1e+04  |\n",
      "| step        | 1.28e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.86    |\n",
      "| grad_norm   | 5.38     |\n",
      "| loss        | -0.523   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000749 |\n",
      "| recon_loss  | 0.34     |\n",
      "| samples     | 4.13e+04 |\n",
      "| step        | 1.29e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.866   |\n",
      "| grad_norm   | 6.04     |\n",
      "| loss        | -0.527   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000707 |\n",
      "| recon_loss  | 0.348    |\n",
      "| samples     | 4.16e+04 |\n",
      "| step        | 1.3e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.872   |\n",
      "| grad_norm   | 6.78     |\n",
      "| loss        | -0.525   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000738 |\n",
      "| recon_loss  | 0.354    |\n",
      "| samples     | 4.2e+04  |\n",
      "| step        | 1.31e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.878   |\n",
      "| grad_norm   | 5.89     |\n",
      "| loss        | -0.552   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000702 |\n",
      "| recon_loss  | 0.333    |\n",
      "| samples     | 4.23e+04 |\n",
      "| step        | 1.32e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.885   |\n",
      "| grad_norm   | 6.76     |\n",
      "| loss        | -0.526   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000742 |\n",
      "| recon_loss  | 0.356    |\n",
      "| samples     | 4.26e+04 |\n",
      "| step        | 1.33e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.892   |\n",
      "| grad_norm   | 6.92     |\n",
      "| loss        | -0.546   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000713 |\n",
      "| recon_loss  | 0.346    |\n",
      "| samples     | 4.29e+04 |\n",
      "| step        | 1.34e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.898   |\n",
      "| grad_norm   | 6.31     |\n",
      "| loss        | -0.562   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000709 |\n",
      "| recon_loss  | 0.335    |\n",
      "| samples     | 4.32e+04 |\n",
      "| step        | 1.35e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.904   |\n",
      "| grad_norm   | 6.34     |\n",
      "| loss        | -0.577   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000686 |\n",
      "| recon_loss  | 0.337    |\n",
      "| samples     | 4.36e+04 |\n",
      "| step        | 1.36e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.911   |\n",
      "| grad_norm   | 5.82     |\n",
      "| loss        | -0.585   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000686 |\n",
      "| recon_loss  | 0.331    |\n",
      "| samples     | 4.39e+04 |\n",
      "| step        | 1.37e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.917   |\n",
      "| grad_norm   | 4.47     |\n",
      "| loss        | -0.569   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000691 |\n",
      "| recon_loss  | 0.353    |\n",
      "| samples     | 4.42e+04 |\n",
      "| step        | 1.38e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.924   |\n",
      "| grad_norm   | 6.08     |\n",
      "| loss        | -0.595   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000706 |\n",
      "| recon_loss  | 0.36     |\n",
      "| samples     | 4.45e+04 |\n",
      "| step        | 1.39e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.93    |\n",
      "| grad_norm   | 8.27     |\n",
      "| loss        | -0.547   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000666 |\n",
      "| recon_loss  | 0.381    |\n",
      "| samples     | 4.48e+04 |\n",
      "| step        | 1.4e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.937   |\n",
      "| grad_norm   | 5.89     |\n",
      "| loss        | -0.601   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000594 |\n",
      "| recon_loss  | 0.335    |\n",
      "| samples     | 4.52e+04 |\n",
      "| step        | 1.41e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.943   |\n",
      "| grad_norm   | 6.93     |\n",
      "| loss        | -0.579   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000626 |\n",
      "| recon_loss  | 0.361    |\n",
      "| samples     | 4.55e+04 |\n",
      "| step        | 1.42e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.949   |\n",
      "| grad_norm   | 6.05     |\n",
      "| loss        | -0.616   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000641 |\n",
      "| recon_loss  | 0.348    |\n",
      "| samples     | 4.58e+04 |\n",
      "| step        | 1.43e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.956   |\n",
      "| grad_norm   | 6.37     |\n",
      "| loss        | -0.609   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000624 |\n",
      "| recon_loss  | 0.341    |\n",
      "| samples     | 4.61e+04 |\n",
      "| step        | 1.44e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.963   |\n",
      "| grad_norm   | 4.85     |\n",
      "| loss        | -0.637   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000682 |\n",
      "| recon_loss  | 0.331    |\n",
      "| samples     | 4.64e+04 |\n",
      "| step        | 1.45e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.969   |\n",
      "| grad_norm   | 6.03     |\n",
      "| loss        | -0.627   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000621 |\n",
      "| recon_loss  | 0.346    |\n",
      "| samples     | 4.68e+04 |\n",
      "| step        | 1.46e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.975   |\n",
      "| grad_norm   | 8.03     |\n",
      "| loss        | -0.624   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000624 |\n",
      "| recon_loss  | 0.348    |\n",
      "| samples     | 4.71e+04 |\n",
      "| step        | 1.47e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.982   |\n",
      "| grad_norm   | 6.78     |\n",
      "| loss        | -0.65    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000554 |\n",
      "| recon_loss  | 0.343    |\n",
      "| samples     | 4.74e+04 |\n",
      "| step        | 1.48e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.988   |\n",
      "| grad_norm   | 6.5      |\n",
      "| loss        | -0.677   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000546 |\n",
      "| recon_loss  | 0.322    |\n",
      "| samples     | 4.77e+04 |\n",
      "| step        | 1.49e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -0.995   |\n",
      "| grad_norm   | 6.52     |\n",
      "| loss        | -0.651   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000526 |\n",
      "| recon_loss  | 0.343    |\n",
      "| samples     | 4.8e+04  |\n",
      "| step        | 1.5e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1       |\n",
      "| grad_norm   | 4.59     |\n",
      "| loss        | -0.694   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000564 |\n",
      "| recon_loss  | 0.335    |\n",
      "| samples     | 4.84e+04 |\n",
      "| step        | 1.51e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.01    |\n",
      "| grad_norm   | 5.86     |\n",
      "| loss        | -0.715   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000494 |\n",
      "| recon_loss  | 0.313    |\n",
      "| samples     | 4.87e+04 |\n",
      "| step        | 1.52e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.01    |\n",
      "| grad_norm   | 5.1      |\n",
      "| loss        | -0.696   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00051  |\n",
      "| recon_loss  | 0.326    |\n",
      "| samples     | 4.9e+04  |\n",
      "| step        | 1.53e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.02    |\n",
      "| grad_norm   | 6.08     |\n",
      "| loss        | -0.697   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000558 |\n",
      "| recon_loss  | 0.324    |\n",
      "| samples     | 4.93e+04 |\n",
      "| step        | 1.54e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.03    |\n",
      "| grad_norm   | 6.62     |\n",
      "| loss        | -0.708   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000567 |\n",
      "| recon_loss  | 0.333    |\n",
      "| samples     | 4.96e+04 |\n",
      "| step        | 1.55e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.03    |\n",
      "| grad_norm   | 6.77     |\n",
      "| loss        | -0.714   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000548 |\n",
      "| recon_loss  | 0.314    |\n",
      "| samples     | 5e+04    |\n",
      "| step        | 1.56e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.04    |\n",
      "| grad_norm   | 6.39     |\n",
      "| loss        | -0.735   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000537 |\n",
      "| recon_loss  | 0.319    |\n",
      "| samples     | 5.03e+04 |\n",
      "| step        | 1.57e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.05    |\n",
      "| grad_norm   | 7.31     |\n",
      "| loss        | -0.731   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000622 |\n",
      "| recon_loss  | 0.323    |\n",
      "| samples     | 5.06e+04 |\n",
      "| step        | 1.58e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.05    |\n",
      "| grad_norm   | 6.7      |\n",
      "| loss        | -0.713   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000498 |\n",
      "| recon_loss  | 0.344    |\n",
      "| samples     | 5.09e+04 |\n",
      "| step        | 1.59e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.06    |\n",
      "| grad_norm   | 6.31     |\n",
      "| loss        | -0.723   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000514 |\n",
      "| recon_loss  | 0.324    |\n",
      "| samples     | 5.12e+04 |\n",
      "| step        | 1.6e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.07    |\n",
      "| grad_norm   | 7.87     |\n",
      "| loss        | -0.737   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000511 |\n",
      "| recon_loss  | 0.342    |\n",
      "| samples     | 5.16e+04 |\n",
      "| step        | 1.61e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.07    |\n",
      "| grad_norm   | 8.83     |\n",
      "| loss        | -0.732   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000505 |\n",
      "| recon_loss  | 0.337    |\n",
      "| samples     | 5.19e+04 |\n",
      "| step        | 1.62e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.08    |\n",
      "| grad_norm   | 6.91     |\n",
      "| loss        | -0.748   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000475 |\n",
      "| recon_loss  | 0.319    |\n",
      "| samples     | 5.22e+04 |\n",
      "| step        | 1.63e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.08    |\n",
      "| grad_norm   | 7.55     |\n",
      "| loss        | -0.753   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000448 |\n",
      "| recon_loss  | 0.332    |\n",
      "| samples     | 5.25e+04 |\n",
      "| step        | 1.64e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.09    |\n",
      "| grad_norm   | 5.96     |\n",
      "| loss        | -0.797   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000487 |\n",
      "| recon_loss  | 0.315    |\n",
      "| samples     | 5.28e+04 |\n",
      "| step        | 1.65e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.1     |\n",
      "| grad_norm   | 7.18     |\n",
      "| loss        | -0.766   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000511 |\n",
      "| recon_loss  | 0.335    |\n",
      "| samples     | 5.32e+04 |\n",
      "| step        | 1.66e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.1     |\n",
      "| grad_norm   | 5.75     |\n",
      "| loss        | -0.79    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00048  |\n",
      "| recon_loss  | 0.326    |\n",
      "| samples     | 5.35e+04 |\n",
      "| step        | 1.67e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.11    |\n",
      "| grad_norm   | 6.37     |\n",
      "| loss        | -0.79    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000424 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 5.38e+04 |\n",
      "| step        | 1.68e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.12    |\n",
      "| grad_norm   | 5.43     |\n",
      "| loss        | -0.782   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000456 |\n",
      "| recon_loss  | 0.329    |\n",
      "| samples     | 5.41e+04 |\n",
      "| step        | 1.69e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.12    |\n",
      "| grad_norm   | 5.22     |\n",
      "| loss        | -0.806   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000416 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 5.44e+04 |\n",
      "| step        | 1.7e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.13    |\n",
      "| grad_norm   | 5.4      |\n",
      "| loss        | -0.792   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000516 |\n",
      "| recon_loss  | 0.332    |\n",
      "| samples     | 5.48e+04 |\n",
      "| step        | 1.71e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.13    |\n",
      "| grad_norm   | 5.57     |\n",
      "| loss        | -0.822   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000408 |\n",
      "| recon_loss  | 0.315    |\n",
      "| samples     | 5.51e+04 |\n",
      "| step        | 1.72e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.14    |\n",
      "| grad_norm   | 4.89     |\n",
      "| loss        | -0.832   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000371 |\n",
      "| recon_loss  | 0.315    |\n",
      "| samples     | 5.54e+04 |\n",
      "| step        | 1.73e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.15    |\n",
      "| grad_norm   | 6.4      |\n",
      "| loss        | -0.841   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000455 |\n",
      "| recon_loss  | 0.321    |\n",
      "| samples     | 5.57e+04 |\n",
      "| step        | 1.74e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.15    |\n",
      "| grad_norm   | 6.48     |\n",
      "| loss        | -0.812   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000478 |\n",
      "| recon_loss  | 0.347    |\n",
      "| samples     | 5.6e+04  |\n",
      "| step        | 1.75e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.16    |\n",
      "| grad_norm   | 7.98     |\n",
      "| loss        | -0.819   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000398 |\n",
      "| recon_loss  | 0.33     |\n",
      "| samples     | 5.64e+04 |\n",
      "| step        | 1.76e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.17    |\n",
      "| grad_norm   | 6.05     |\n",
      "| loss        | -0.832   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000398 |\n",
      "| recon_loss  | 0.327    |\n",
      "| samples     | 5.67e+04 |\n",
      "| step        | 1.77e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.17    |\n",
      "| grad_norm   | 6.03     |\n",
      "| loss        | -0.839   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000398 |\n",
      "| recon_loss  | 0.328    |\n",
      "| samples     | 5.7e+04  |\n",
      "| step        | 1.78e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.18    |\n",
      "| grad_norm   | 4.3      |\n",
      "| loss        | -0.865   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000399 |\n",
      "| recon_loss  | 0.322    |\n",
      "| samples     | 5.73e+04 |\n",
      "| step        | 1.79e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.18    |\n",
      "| grad_norm   | 6.72     |\n",
      "| loss        | -0.879   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00042  |\n",
      "| recon_loss  | 0.329    |\n",
      "| samples     | 5.76e+04 |\n",
      "| step        | 1.8e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.19    |\n",
      "| grad_norm   | 5.3      |\n",
      "| loss        | -0.893   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000391 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 5.8e+04  |\n",
      "| step        | 1.81e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.2     |\n",
      "| grad_norm   | 4.45     |\n",
      "| loss        | -0.915   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000434 |\n",
      "| recon_loss  | 0.307    |\n",
      "| samples     | 5.83e+04 |\n",
      "| step        | 1.82e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.2     |\n",
      "| grad_norm   | 6.03     |\n",
      "| loss        | -0.892   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000419 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 5.86e+04 |\n",
      "| step        | 1.83e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.21    |\n",
      "| grad_norm   | 8.85     |\n",
      "| loss        | -0.896   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000381 |\n",
      "| recon_loss  | 0.314    |\n",
      "| samples     | 5.89e+04 |\n",
      "| step        | 1.84e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.22    |\n",
      "| grad_norm   | 7.15     |\n",
      "| loss        | -0.908   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000401 |\n",
      "| recon_loss  | 0.31     |\n",
      "| samples     | 5.92e+04 |\n",
      "| step        | 1.85e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.22    |\n",
      "| grad_norm   | 7.2      |\n",
      "| loss        | -0.926   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000374 |\n",
      "| recon_loss  | 0.297    |\n",
      "| samples     | 5.96e+04 |\n",
      "| step        | 1.86e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.23    |\n",
      "| grad_norm   | 6.36     |\n",
      "| loss        | -0.915   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000373 |\n",
      "| recon_loss  | 0.316    |\n",
      "| samples     | 5.99e+04 |\n",
      "| step        | 1.87e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.23    |\n",
      "| grad_norm   | 5.55     |\n",
      "| loss        | -0.933   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000357 |\n",
      "| recon_loss  | 0.31     |\n",
      "| samples     | 6.02e+04 |\n",
      "| step        | 1.88e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.24    |\n",
      "| grad_norm   | 6.73     |\n",
      "| loss        | -0.938   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00035  |\n",
      "| recon_loss  | 0.305    |\n",
      "| samples     | 6.05e+04 |\n",
      "| step        | 1.89e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.25    |\n",
      "| grad_norm   | 5.75     |\n",
      "| loss        | -0.952   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000388 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 6.08e+04 |\n",
      "| step        | 1.9e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.25    |\n",
      "| grad_norm   | 6.27     |\n",
      "| loss        | -0.922   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000369 |\n",
      "| recon_loss  | 0.334    |\n",
      "| samples     | 6.12e+04 |\n",
      "| step        | 1.91e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.26    |\n",
      "| grad_norm   | 7.48     |\n",
      "| loss        | -0.933   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000347 |\n",
      "| recon_loss  | 0.328    |\n",
      "| samples     | 6.15e+04 |\n",
      "| step        | 1.92e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.26    |\n",
      "| grad_norm   | 5.52     |\n",
      "| loss        | -0.955   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000412 |\n",
      "| recon_loss  | 0.316    |\n",
      "| samples     | 6.18e+04 |\n",
      "| step        | 1.93e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.27    |\n",
      "| grad_norm   | 5.41     |\n",
      "| loss        | -0.978   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00031  |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 6.21e+04 |\n",
      "| step        | 1.94e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.28    |\n",
      "| grad_norm   | 7.26     |\n",
      "| loss        | -0.978   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00035  |\n",
      "| recon_loss  | 0.312    |\n",
      "| samples     | 6.24e+04 |\n",
      "| step        | 1.95e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.28    |\n",
      "| grad_norm   | 6.01     |\n",
      "| loss        | -0.978   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000349 |\n",
      "| recon_loss  | 0.322    |\n",
      "| samples     | 6.28e+04 |\n",
      "| step        | 1.96e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.29    |\n",
      "| grad_norm   | 6.4      |\n",
      "| loss        | -0.994   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00031  |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 6.31e+04 |\n",
      "| step        | 1.97e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.29    |\n",
      "| grad_norm   | 7.53     |\n",
      "| loss        | -0.976   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000357 |\n",
      "| recon_loss  | 0.321    |\n",
      "| samples     | 6.34e+04 |\n",
      "| step        | 1.98e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.3     |\n",
      "| grad_norm   | 6.24     |\n",
      "| loss        | -0.965   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000313 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 6.37e+04 |\n",
      "| step        | 1.99e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.31    |\n",
      "| grad_norm   | 6.37     |\n",
      "| loss        | -0.976   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000322 |\n",
      "| recon_loss  | 0.331    |\n",
      "| samples     | 6.4e+04  |\n",
      "| step        | 2e+03    |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.31    |\n",
      "| grad_norm   | 6.4      |\n",
      "| loss        | -0.985   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000348 |\n",
      "| recon_loss  | 0.319    |\n",
      "| samples     | 6.44e+04 |\n",
      "| step        | 2.01e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.32    |\n",
      "| grad_norm   | 6.23     |\n",
      "| loss        | -0.999   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00039  |\n",
      "| recon_loss  | 0.325    |\n",
      "| samples     | 6.47e+04 |\n",
      "| step        | 2.02e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.32    |\n",
      "| grad_norm   | 6.1      |\n",
      "| loss        | -0.992   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000328 |\n",
      "| recon_loss  | 0.327    |\n",
      "| samples     | 6.5e+04  |\n",
      "| step        | 2.03e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.33    |\n",
      "| grad_norm   | 6.52     |\n",
      "| loss        | -1.03    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000305 |\n",
      "| recon_loss  | 0.313    |\n",
      "| samples     | 6.53e+04 |\n",
      "| step        | 2.04e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.34    |\n",
      "| grad_norm   | 7.37     |\n",
      "| loss        | -1.02    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000303 |\n",
      "| recon_loss  | 0.315    |\n",
      "| samples     | 6.56e+04 |\n",
      "| step        | 2.05e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.34    |\n",
      "| grad_norm   | 7.37     |\n",
      "| loss        | -1.02    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000296 |\n",
      "| recon_loss  | 0.305    |\n",
      "| samples     | 6.6e+04  |\n",
      "| step        | 2.06e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.35    |\n",
      "| grad_norm   | 7.1      |\n",
      "| loss        | -1.05    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000318 |\n",
      "| recon_loss  | 0.309    |\n",
      "| samples     | 6.63e+04 |\n",
      "| step        | 2.07e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.35    |\n",
      "| grad_norm   | 6.79     |\n",
      "| loss        | -1.06    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000263 |\n",
      "| recon_loss  | 0.296    |\n",
      "| samples     | 6.66e+04 |\n",
      "| step        | 2.08e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.36    |\n",
      "| grad_norm   | 5.69     |\n",
      "| loss        | -1.05    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000301 |\n",
      "| recon_loss  | 0.315    |\n",
      "| samples     | 6.69e+04 |\n",
      "| step        | 2.09e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.37    |\n",
      "| grad_norm   | 5.78     |\n",
      "| loss        | -1.07    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000307 |\n",
      "| recon_loss  | 0.311    |\n",
      "| samples     | 6.72e+04 |\n",
      "| step        | 2.1e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.37    |\n",
      "| grad_norm   | 6.96     |\n",
      "| loss        | -1.06    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000299 |\n",
      "| recon_loss  | 0.305    |\n",
      "| samples     | 6.76e+04 |\n",
      "| step        | 2.11e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.38    |\n",
      "| grad_norm   | 6.98     |\n",
      "| loss        | -1.08    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000298 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 6.79e+04 |\n",
      "| step        | 2.12e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.38    |\n",
      "| grad_norm   | 6.43     |\n",
      "| loss        | -1.09    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000326 |\n",
      "| recon_loss  | 0.321    |\n",
      "| samples     | 6.82e+04 |\n",
      "| step        | 2.13e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.39    |\n",
      "| grad_norm   | 6.31     |\n",
      "| loss        | -1.09    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000311 |\n",
      "| recon_loss  | 0.311    |\n",
      "| samples     | 6.85e+04 |\n",
      "| step        | 2.14e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.4     |\n",
      "| grad_norm   | 6.92     |\n",
      "| loss        | -1.11    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000259 |\n",
      "| recon_loss  | 0.307    |\n",
      "| samples     | 6.88e+04 |\n",
      "| step        | 2.15e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.4     |\n",
      "| grad_norm   | 7.85     |\n",
      "| loss        | -1.08    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000295 |\n",
      "| recon_loss  | 0.321    |\n",
      "| samples     | 6.92e+04 |\n",
      "| step        | 2.16e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.41    |\n",
      "| grad_norm   | 6.89     |\n",
      "| loss        | -1.1     |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000276 |\n",
      "| recon_loss  | 0.311    |\n",
      "| samples     | 6.95e+04 |\n",
      "| step        | 2.17e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.41    |\n",
      "| grad_norm   | 4.63     |\n",
      "| loss        | -1.12    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000273 |\n",
      "| recon_loss  | 0.304    |\n",
      "| samples     | 6.98e+04 |\n",
      "| step        | 2.18e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.42    |\n",
      "| grad_norm   | 5.41     |\n",
      "| loss        | -1.14    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000277 |\n",
      "| recon_loss  | 0.295    |\n",
      "| samples     | 7.01e+04 |\n",
      "| step        | 2.19e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.42    |\n",
      "| grad_norm   | 5.43     |\n",
      "| loss        | -1.12    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000292 |\n",
      "| recon_loss  | 0.314    |\n",
      "| samples     | 7.04e+04 |\n",
      "| step        | 2.2e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.43    |\n",
      "| grad_norm   | 5.76     |\n",
      "| loss        | -1.14    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000258 |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 7.08e+04 |\n",
      "| step        | 2.21e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.44    |\n",
      "| grad_norm   | 6.33     |\n",
      "| loss        | -1.13    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000274 |\n",
      "| recon_loss  | 0.318    |\n",
      "| samples     | 7.11e+04 |\n",
      "| step        | 2.22e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.44    |\n",
      "| grad_norm   | 5.07     |\n",
      "| loss        | -1.14    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00029  |\n",
      "| recon_loss  | 0.306    |\n",
      "| samples     | 7.14e+04 |\n",
      "| step        | 2.23e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.45    |\n",
      "| grad_norm   | 5.21     |\n",
      "| loss        | -1.17    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000271 |\n",
      "| recon_loss  | 0.296    |\n",
      "| samples     | 7.17e+04 |\n",
      "| step        | 2.24e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.45    |\n",
      "| grad_norm   | 5.74     |\n",
      "| loss        | -1.16    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000271 |\n",
      "| recon_loss  | 0.302    |\n",
      "| samples     | 7.2e+04  |\n",
      "| step        | 2.25e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.46    |\n",
      "| grad_norm   | 6.39     |\n",
      "| loss        | -1.15    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000277 |\n",
      "| recon_loss  | 0.307    |\n",
      "| samples     | 7.24e+04 |\n",
      "| step        | 2.26e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.46    |\n",
      "| grad_norm   | 6.55     |\n",
      "| loss        | -1.17    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000256 |\n",
      "| recon_loss  | 0.3      |\n",
      "| samples     | 7.27e+04 |\n",
      "| step        | 2.27e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.47    |\n",
      "| grad_norm   | 5.85     |\n",
      "| loss        | -1.17    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000283 |\n",
      "| recon_loss  | 0.312    |\n",
      "| samples     | 7.3e+04  |\n",
      "| step        | 2.28e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.48    |\n",
      "| grad_norm   | 5.84     |\n",
      "| loss        | -1.19    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000266 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 7.33e+04 |\n",
      "| step        | 2.29e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.48    |\n",
      "| grad_norm   | 4.03     |\n",
      "| loss        | -1.18    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000229 |\n",
      "| recon_loss  | 0.308    |\n",
      "| samples     | 7.36e+04 |\n",
      "| step        | 2.3e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.49    |\n",
      "| grad_norm   | 5.48     |\n",
      "| loss        | -1.21    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000228 |\n",
      "| recon_loss  | 0.295    |\n",
      "| samples     | 7.4e+04  |\n",
      "| step        | 2.31e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.49    |\n",
      "| grad_norm   | 4.94     |\n",
      "| loss        | -1.22    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00026  |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 7.43e+04 |\n",
      "| step        | 2.32e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.5     |\n",
      "| grad_norm   | 5.33     |\n",
      "| loss        | -1.21    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000248 |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 7.46e+04 |\n",
      "| step        | 2.33e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.5     |\n",
      "| grad_norm   | 5.61     |\n",
      "| loss        | -1.23    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000224 |\n",
      "| recon_loss  | 0.29     |\n",
      "| samples     | 7.49e+04 |\n",
      "| step        | 2.34e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.51    |\n",
      "| grad_norm   | 5.21     |\n",
      "| loss        | -1.24    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000193 |\n",
      "| recon_loss  | 0.289    |\n",
      "| samples     | 7.52e+04 |\n",
      "| step        | 2.35e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.52    |\n",
      "| grad_norm   | 4.98     |\n",
      "| loss        | -1.22    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000252 |\n",
      "| recon_loss  | 0.3      |\n",
      "| samples     | 7.56e+04 |\n",
      "| step        | 2.36e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.52    |\n",
      "| grad_norm   | 5.81     |\n",
      "| loss        | -1.24    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000229 |\n",
      "| recon_loss  | 0.289    |\n",
      "| samples     | 7.59e+04 |\n",
      "| step        | 2.37e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.53    |\n",
      "| grad_norm   | 5.07     |\n",
      "| loss        | -1.25    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000258 |\n",
      "| recon_loss  | 0.297    |\n",
      "| samples     | 7.62e+04 |\n",
      "| step        | 2.38e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.53    |\n",
      "| grad_norm   | 5.27     |\n",
      "| loss        | -1.23    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000256 |\n",
      "| recon_loss  | 0.301    |\n",
      "| samples     | 7.65e+04 |\n",
      "| step        | 2.39e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.54    |\n",
      "| grad_norm   | 6.69     |\n",
      "| loss        | -1.24    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000294 |\n",
      "| recon_loss  | 0.302    |\n",
      "| samples     | 7.68e+04 |\n",
      "| step        | 2.4e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.54    |\n",
      "| grad_norm   | 6.74     |\n",
      "| loss        | -1.27    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000231 |\n",
      "| recon_loss  | 0.284    |\n",
      "| samples     | 7.72e+04 |\n",
      "| step        | 2.41e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.55    |\n",
      "| grad_norm   | 5.38     |\n",
      "| loss        | -1.27    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00024  |\n",
      "| recon_loss  | 0.293    |\n",
      "| samples     | 7.75e+04 |\n",
      "| step        | 2.42e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.56    |\n",
      "| grad_norm   | 6.43     |\n",
      "| loss        | -1.28    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000219 |\n",
      "| recon_loss  | 0.277    |\n",
      "| samples     | 7.78e+04 |\n",
      "| step        | 2.43e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.56    |\n",
      "| grad_norm   | 7.21     |\n",
      "| loss        | -1.29    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000232 |\n",
      "| recon_loss  | 0.291    |\n",
      "| samples     | 7.81e+04 |\n",
      "| step        | 2.44e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.57    |\n",
      "| grad_norm   | 5.81     |\n",
      "| loss        | -1.29    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000224 |\n",
      "| recon_loss  | 0.289    |\n",
      "| samples     | 7.84e+04 |\n",
      "| step        | 2.45e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.57    |\n",
      "| grad_norm   | 5.64     |\n",
      "| loss        | -1.31    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000218 |\n",
      "| recon_loss  | 0.28     |\n",
      "| samples     | 7.88e+04 |\n",
      "| step        | 2.46e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.58    |\n",
      "| grad_norm   | 6.55     |\n",
      "| loss        | -1.3     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000226 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 7.91e+04 |\n",
      "| step        | 2.47e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.58    |\n",
      "| grad_norm   | 6.82     |\n",
      "| loss        | -1.29    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000233 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 7.94e+04 |\n",
      "| step        | 2.48e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.59    |\n",
      "| grad_norm   | 6.73     |\n",
      "| loss        | -1.29    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000233 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 7.97e+04 |\n",
      "| step        | 2.49e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.59    |\n",
      "| grad_norm   | 5.6      |\n",
      "| loss        | -1.31    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000237 |\n",
      "| recon_loss  | 0.289    |\n",
      "| samples     | 8e+04    |\n",
      "| step        | 2.5e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.6     |\n",
      "| grad_norm   | 6.61     |\n",
      "| loss        | -1.33    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000264 |\n",
      "| recon_loss  | 0.288    |\n",
      "| samples     | 8.04e+04 |\n",
      "| step        | 2.51e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.6     |\n",
      "| grad_norm   | 6.76     |\n",
      "| loss        | -1.33    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000193 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 8.07e+04 |\n",
      "| step        | 2.52e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.61    |\n",
      "| grad_norm   | 5.72     |\n",
      "| loss        | -1.32    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00022  |\n",
      "| recon_loss  | 0.288    |\n",
      "| samples     | 8.1e+04  |\n",
      "| step        | 2.53e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.61    |\n",
      "| grad_norm   | 5.89     |\n",
      "| loss        | -1.32    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000217 |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 8.13e+04 |\n",
      "| step        | 2.54e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.62    |\n",
      "| grad_norm   | 7.02     |\n",
      "| loss        | -1.32    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000206 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 8.16e+04 |\n",
      "| step        | 2.55e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.63    |\n",
      "| grad_norm   | 4.29     |\n",
      "| loss        | -1.36    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000213 |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 8.2e+04  |\n",
      "| step        | 2.56e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.63    |\n",
      "| grad_norm   | 4.82     |\n",
      "| loss        | -1.34    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000218 |\n",
      "| recon_loss  | 0.298    |\n",
      "| samples     | 8.23e+04 |\n",
      "| step        | 2.57e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.64    |\n",
      "| grad_norm   | 7.7      |\n",
      "| loss        | -1.32    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000197 |\n",
      "| recon_loss  | 0.316    |\n",
      "| samples     | 8.26e+04 |\n",
      "| step        | 2.58e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.64    |\n",
      "| grad_norm   | 7.22     |\n",
      "| loss        | -1.36    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000218 |\n",
      "| recon_loss  | 0.288    |\n",
      "| samples     | 8.29e+04 |\n",
      "| step        | 2.59e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.65    |\n",
      "| grad_norm   | 8.04     |\n",
      "| loss        | -1.35    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000222 |\n",
      "| recon_loss  | 0.303    |\n",
      "| samples     | 8.32e+04 |\n",
      "| step        | 2.6e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.65    |\n",
      "| grad_norm   | 6.94     |\n",
      "| loss        | -1.35    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00018  |\n",
      "| recon_loss  | 0.292    |\n",
      "| samples     | 8.36e+04 |\n",
      "| step        | 2.61e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.66    |\n",
      "| grad_norm   | 5.3      |\n",
      "| loss        | -1.37    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000204 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 8.39e+04 |\n",
      "| step        | 2.62e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.66    |\n",
      "| grad_norm   | 5.55     |\n",
      "| loss        | -1.37    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000205 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 8.42e+04 |\n",
      "| step        | 2.63e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.67    |\n",
      "| grad_norm   | 6.01     |\n",
      "| loss        | -1.37    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00019  |\n",
      "| recon_loss  | 0.29     |\n",
      "| samples     | 8.45e+04 |\n",
      "| step        | 2.64e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.67    |\n",
      "| grad_norm   | 7.18     |\n",
      "| loss        | -1.38    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000185 |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 8.48e+04 |\n",
      "| step        | 2.65e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.68    |\n",
      "| grad_norm   | 6.46     |\n",
      "| loss        | -1.4     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000229 |\n",
      "| recon_loss  | 0.297    |\n",
      "| samples     | 8.52e+04 |\n",
      "| step        | 2.66e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.68    |\n",
      "| grad_norm   | 4.65     |\n",
      "| loss        | -1.39    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000178 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 8.55e+04 |\n",
      "| step        | 2.67e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.69    |\n",
      "| grad_norm   | 4.96     |\n",
      "| loss        | -1.41    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000183 |\n",
      "| recon_loss  | 0.29     |\n",
      "| samples     | 8.58e+04 |\n",
      "| step        | 2.68e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.69    |\n",
      "| grad_norm   | 6.12     |\n",
      "| loss        | -1.41    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000183 |\n",
      "| recon_loss  | 0.29     |\n",
      "| samples     | 8.61e+04 |\n",
      "| step        | 2.69e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.7     |\n",
      "| grad_norm   | 6.06     |\n",
      "| loss        | -1.42    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00018  |\n",
      "| recon_loss  | 0.288    |\n",
      "| samples     | 8.64e+04 |\n",
      "| step        | 2.7e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.7     |\n",
      "| grad_norm   | 5.9      |\n",
      "| loss        | -1.44    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000179 |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 8.68e+04 |\n",
      "| step        | 2.71e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.71    |\n",
      "| grad_norm   | 6.14     |\n",
      "| loss        | -1.41    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000174 |\n",
      "| recon_loss  | 0.298    |\n",
      "| samples     | 8.71e+04 |\n",
      "| step        | 2.72e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.71    |\n",
      "| grad_norm   | 4.4      |\n",
      "| loss        | -1.44    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000192 |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 8.74e+04 |\n",
      "| step        | 2.73e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.72    |\n",
      "| grad_norm   | 5.16     |\n",
      "| loss        | -1.44    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000202 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 8.77e+04 |\n",
      "| step        | 2.74e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.73    |\n",
      "| grad_norm   | 4.05     |\n",
      "| loss        | -1.48    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000164 |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 8.8e+04  |\n",
      "| step        | 2.75e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.73    |\n",
      "| grad_norm   | 4.75     |\n",
      "| loss        | -1.47    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000176 |\n",
      "| recon_loss  | 0.279    |\n",
      "| samples     | 8.84e+04 |\n",
      "| step        | 2.76e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.74    |\n",
      "| grad_norm   | 6.7      |\n",
      "| loss        | -1.44    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000182 |\n",
      "| recon_loss  | 0.305    |\n",
      "| samples     | 8.87e+04 |\n",
      "| step        | 2.77e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.74    |\n",
      "| grad_norm   | 6.06     |\n",
      "| loss        | -1.47    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000179 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 8.9e+04  |\n",
      "| step        | 2.78e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.74    |\n",
      "| grad_norm   | 5.43     |\n",
      "| loss        | -1.46    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000176 |\n",
      "| recon_loss  | 0.298    |\n",
      "| samples     | 8.93e+04 |\n",
      "| step        | 2.79e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.75    |\n",
      "| grad_norm   | 5.72     |\n",
      "| loss        | -1.45    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000209 |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 8.96e+04 |\n",
      "| step        | 2.8e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.75    |\n",
      "| grad_norm   | 6.46     |\n",
      "| loss        | -1.48    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000171 |\n",
      "| recon_loss  | 0.292    |\n",
      "| samples     | 9e+04    |\n",
      "| step        | 2.81e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.76    |\n",
      "| grad_norm   | 6.61     |\n",
      "| loss        | -1.47    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000157 |\n",
      "| recon_loss  | 0.278    |\n",
      "| samples     | 9.03e+04 |\n",
      "| step        | 2.82e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.76    |\n",
      "| grad_norm   | 7.38     |\n",
      "| loss        | -1.5     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000169 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 9.06e+04 |\n",
      "| step        | 2.83e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.77    |\n",
      "| grad_norm   | 5.66     |\n",
      "| loss        | -1.51    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000204 |\n",
      "| recon_loss  | 0.272    |\n",
      "| samples     | 9.09e+04 |\n",
      "| step        | 2.84e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.77    |\n",
      "| grad_norm   | 5.13     |\n",
      "| loss        | -1.51    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000189 |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 9.12e+04 |\n",
      "| step        | 2.85e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.78    |\n",
      "| grad_norm   | 6.29     |\n",
      "| loss        | -1.5     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00016  |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 9.16e+04 |\n",
      "| step        | 2.86e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.78    |\n",
      "| grad_norm   | 6.85     |\n",
      "| loss        | -1.52    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000187 |\n",
      "| recon_loss  | 0.268    |\n",
      "| samples     | 9.19e+04 |\n",
      "| step        | 2.87e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.79    |\n",
      "| grad_norm   | 5.89     |\n",
      "| loss        | -1.54    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000191 |\n",
      "| recon_loss  | 0.27     |\n",
      "| samples     | 9.22e+04 |\n",
      "| step        | 2.88e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.79    |\n",
      "| grad_norm   | 6.3      |\n",
      "| loss        | -1.52    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000162 |\n",
      "| recon_loss  | 0.272    |\n",
      "| samples     | 9.25e+04 |\n",
      "| step        | 2.89e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.8     |\n",
      "| grad_norm   | 6.88     |\n",
      "| loss        | -1.51    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000171 |\n",
      "| recon_loss  | 0.288    |\n",
      "| samples     | 9.28e+04 |\n",
      "| step        | 2.9e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.8     |\n",
      "| grad_norm   | 7.91     |\n",
      "| loss        | -1.52    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00014  |\n",
      "| recon_loss  | 0.291    |\n",
      "| samples     | 9.32e+04 |\n",
      "| step        | 2.91e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.81    |\n",
      "| grad_norm   | 6.35     |\n",
      "| loss        | -1.53    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000168 |\n",
      "| recon_loss  | 0.28     |\n",
      "| samples     | 9.35e+04 |\n",
      "| step        | 2.92e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.81    |\n",
      "| grad_norm   | 5.31     |\n",
      "| loss        | -1.51    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000152 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 9.38e+04 |\n",
      "| step        | 2.93e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.82    |\n",
      "| grad_norm   | 4.7      |\n",
      "| loss        | -1.52    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00017  |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 9.41e+04 |\n",
      "| step        | 2.94e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.82    |\n",
      "| grad_norm   | 5.85     |\n",
      "| loss        | -1.55    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000143 |\n",
      "| recon_loss  | 0.275    |\n",
      "| samples     | 9.44e+04 |\n",
      "| step        | 2.95e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.83    |\n",
      "| grad_norm   | 5.81     |\n",
      "| loss        | -1.55    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000145 |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 9.48e+04 |\n",
      "| step        | 2.96e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.83    |\n",
      "| grad_norm   | 6.05     |\n",
      "| loss        | -1.56    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000151 |\n",
      "| recon_loss  | 0.28     |\n",
      "| samples     | 9.51e+04 |\n",
      "| step        | 2.97e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.84    |\n",
      "| grad_norm   | 5.16     |\n",
      "| loss        | -1.57    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000165 |\n",
      "| recon_loss  | 0.277    |\n",
      "| samples     | 9.54e+04 |\n",
      "| step        | 2.98e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.84    |\n",
      "| grad_norm   | 4.88     |\n",
      "| loss        | -1.55    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000206 |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 9.57e+04 |\n",
      "| step        | 2.99e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.85    |\n",
      "| grad_norm   | 5.65     |\n",
      "| loss        | -1.57    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000155 |\n",
      "| recon_loss  | 0.278    |\n",
      "| samples     | 9.6e+04  |\n",
      "| step        | 3e+03    |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.85    |\n",
      "| grad_norm   | 6.44     |\n",
      "| loss        | -1.57    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000149 |\n",
      "| recon_loss  | 0.271    |\n",
      "| samples     | 9.64e+04 |\n",
      "| step        | 3.01e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.86    |\n",
      "| grad_norm   | 6.15     |\n",
      "| loss        | -1.56    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000143 |\n",
      "| recon_loss  | 0.283    |\n",
      "| samples     | 9.67e+04 |\n",
      "| step        | 3.02e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.86    |\n",
      "| grad_norm   | 5.05     |\n",
      "| loss        | -1.6     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000163 |\n",
      "| recon_loss  | 0.27     |\n",
      "| samples     | 9.7e+04  |\n",
      "| step        | 3.03e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.87    |\n",
      "| grad_norm   | 6.52     |\n",
      "| loss        | -1.6     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000185 |\n",
      "| recon_loss  | 0.283    |\n",
      "| samples     | 9.73e+04 |\n",
      "| step        | 3.04e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.87    |\n",
      "| grad_norm   | 6.8      |\n",
      "| loss        | -1.6     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000161 |\n",
      "| recon_loss  | 0.281    |\n",
      "| samples     | 9.76e+04 |\n",
      "| step        | 3.05e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.88    |\n",
      "| grad_norm   | 6.07     |\n",
      "| loss        | -1.61    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000153 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 9.8e+04  |\n",
      "| step        | 3.06e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.88    |\n",
      "| grad_norm   | 6.1      |\n",
      "| loss        | -1.59    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000168 |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 9.83e+04 |\n",
      "| step        | 3.07e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.89    |\n",
      "| grad_norm   | 7.55     |\n",
      "| loss        | -1.61    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000144 |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 9.86e+04 |\n",
      "| step        | 3.08e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.89    |\n",
      "| grad_norm   | 6.38     |\n",
      "| loss        | -1.61    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000164 |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 9.89e+04 |\n",
      "| step        | 3.09e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.89    |\n",
      "| grad_norm   | 5.88     |\n",
      "| loss        | -1.62    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000156 |\n",
      "| recon_loss  | 0.269    |\n",
      "| samples     | 9.92e+04 |\n",
      "| step        | 3.1e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.9     |\n",
      "| grad_norm   | 6.33     |\n",
      "| loss        | -1.63    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000139 |\n",
      "| recon_loss  | 0.277    |\n",
      "| samples     | 9.96e+04 |\n",
      "| step        | 3.11e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.9     |\n",
      "| grad_norm   | 7.27     |\n",
      "| loss        | -1.63    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000146 |\n",
      "| recon_loss  | 0.28     |\n",
      "| samples     | 9.99e+04 |\n",
      "| step        | 3.12e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.91    |\n",
      "| grad_norm   | 5.97     |\n",
      "| loss        | -1.64    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000116 |\n",
      "| recon_loss  | 0.266    |\n",
      "| samples     | 1e+05    |\n",
      "| step        | 3.13e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.91    |\n",
      "| grad_norm   | 7.27     |\n",
      "| loss        | -1.63    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000127 |\n",
      "| recon_loss  | 0.277    |\n",
      "| samples     | 1.01e+05 |\n",
      "| step        | 3.14e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.92    |\n",
      "| grad_norm   | 7.02     |\n",
      "| loss        | -1.63    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000171 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 1.01e+05 |\n",
      "| step        | 3.15e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.92    |\n",
      "| grad_norm   | 6.56     |\n",
      "| loss        | -1.64    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000157 |\n",
      "| recon_loss  | 0.289    |\n",
      "| samples     | 1.01e+05 |\n",
      "| step        | 3.16e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.93    |\n",
      "| grad_norm   | 6.36     |\n",
      "| loss        | -1.65    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000152 |\n",
      "| recon_loss  | 0.281    |\n",
      "| samples     | 1.01e+05 |\n",
      "| step        | 3.17e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.93    |\n",
      "| grad_norm   | 4.6      |\n",
      "| loss        | -1.64    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000126 |\n",
      "| recon_loss  | 0.295    |\n",
      "| samples     | 1.02e+05 |\n",
      "| step        | 3.18e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.94    |\n",
      "| grad_norm   | 4.83     |\n",
      "| loss        | -1.67    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000124 |\n",
      "| recon_loss  | 0.27     |\n",
      "| samples     | 1.02e+05 |\n",
      "| step        | 3.19e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.94    |\n",
      "| grad_norm   | 5.56     |\n",
      "| loss        | -1.67    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00013  |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.02e+05 |\n",
      "| step        | 3.2e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.94    |\n",
      "| grad_norm   | 6.37     |\n",
      "| loss        | -1.67    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000144 |\n",
      "| recon_loss  | 0.274    |\n",
      "| samples     | 1.03e+05 |\n",
      "| step        | 3.21e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.95    |\n",
      "| grad_norm   | 6.5      |\n",
      "| loss        | -1.69    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000149 |\n",
      "| recon_loss  | 0.27     |\n",
      "| samples     | 1.03e+05 |\n",
      "| step        | 3.22e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.95    |\n",
      "| grad_norm   | 7.33     |\n",
      "| loss        | -1.69    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000128 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 1.03e+05 |\n",
      "| step        | 3.23e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.96    |\n",
      "| grad_norm   | 7.75     |\n",
      "| loss        | -1.68    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000144 |\n",
      "| recon_loss  | 0.274    |\n",
      "| samples     | 1.04e+05 |\n",
      "| step        | 3.24e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.96    |\n",
      "| grad_norm   | 8.12     |\n",
      "| loss        | -1.66    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000135 |\n",
      "| recon_loss  | 0.284    |\n",
      "| samples     | 1.04e+05 |\n",
      "| step        | 3.25e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.97    |\n",
      "| grad_norm   | 6.82     |\n",
      "| loss        | -1.69    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000122 |\n",
      "| recon_loss  | 0.279    |\n",
      "| samples     | 1.04e+05 |\n",
      "| step        | 3.26e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.97    |\n",
      "| grad_norm   | 5.25     |\n",
      "| loss        | -1.69    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000134 |\n",
      "| recon_loss  | 0.279    |\n",
      "| samples     | 1.05e+05 |\n",
      "| step        | 3.27e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.98    |\n",
      "| grad_norm   | 6.83     |\n",
      "| loss        | -1.7     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000124 |\n",
      "| recon_loss  | 0.278    |\n",
      "| samples     | 1.05e+05 |\n",
      "| step        | 3.28e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.98    |\n",
      "| grad_norm   | 6.71     |\n",
      "| loss        | -1.7     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00012  |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 1.05e+05 |\n",
      "| step        | 3.29e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -1.98    |\n",
      "| grad_norm   | 5.7      |\n",
      "| loss        | -1.72    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000119 |\n",
      "| recon_loss  | 0.26     |\n",
      "| samples     | 1.06e+05 |\n",
      "| step        | 3.3e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -1.99    |\n",
      "| grad_norm   | 5.47     |\n",
      "| loss        | -1.74    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000134 |\n",
      "| recon_loss  | 0.263    |\n",
      "| samples     | 1.06e+05 |\n",
      "| step        | 3.31e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -1.99    |\n",
      "| grad_norm   | 6.11     |\n",
      "| loss        | -1.72    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000112 |\n",
      "| recon_loss  | 0.269    |\n",
      "| samples     | 1.06e+05 |\n",
      "| step        | 3.32e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2       |\n",
      "| grad_norm   | 7.51     |\n",
      "| loss        | -1.71    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000139 |\n",
      "| recon_loss  | 0.3      |\n",
      "| samples     | 1.07e+05 |\n",
      "| step        | 3.33e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2       |\n",
      "| grad_norm   | 6        |\n",
      "| loss        | -1.73    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000132 |\n",
      "| recon_loss  | 0.272    |\n",
      "| samples     | 1.07e+05 |\n",
      "| step        | 3.34e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.01    |\n",
      "| grad_norm   | 4.88     |\n",
      "| loss        | -1.75    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000135 |\n",
      "| recon_loss  | 0.268    |\n",
      "| samples     | 1.07e+05 |\n",
      "| step        | 3.35e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.01    |\n",
      "| grad_norm   | 4.57     |\n",
      "| loss        | -1.76    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000128 |\n",
      "| recon_loss  | 0.264    |\n",
      "| samples     | 1.08e+05 |\n",
      "| step        | 3.36e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.01    |\n",
      "| grad_norm   | 4.2      |\n",
      "| loss        | -1.77    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000116 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.08e+05 |\n",
      "| step        | 3.37e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.02    |\n",
      "| grad_norm   | 4.98     |\n",
      "| loss        | -1.74    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000143 |\n",
      "| recon_loss  | 0.284    |\n",
      "| samples     | 1.08e+05 |\n",
      "| step        | 3.38e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.02    |\n",
      "| grad_norm   | 5.6      |\n",
      "| loss        | -1.76    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00011  |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.09e+05 |\n",
      "| step        | 3.39e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.03    |\n",
      "| grad_norm   | 5.47     |\n",
      "| loss        | -1.77    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000107 |\n",
      "| recon_loss  | 0.25     |\n",
      "| samples     | 1.09e+05 |\n",
      "| step        | 3.4e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.03    |\n",
      "| grad_norm   | 4.94     |\n",
      "| loss        | -1.77    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00011  |\n",
      "| recon_loss  | 0.271    |\n",
      "| samples     | 1.09e+05 |\n",
      "| step        | 3.41e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.03    |\n",
      "| grad_norm   | 4.49     |\n",
      "| loss        | -1.78    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000104 |\n",
      "| recon_loss  | 0.259    |\n",
      "| samples     | 1.09e+05 |\n",
      "| step        | 3.42e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.04    |\n",
      "| grad_norm   | 4.3      |\n",
      "| loss        | -1.78    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000121 |\n",
      "| recon_loss  | 0.261    |\n",
      "| samples     | 1.1e+05  |\n",
      "| step        | 3.43e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.04    |\n",
      "| grad_norm   | 6.77     |\n",
      "| loss        | -1.77    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000115 |\n",
      "| recon_loss  | 0.268    |\n",
      "| samples     | 1.1e+05  |\n",
      "| step        | 3.44e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.05    |\n",
      "| grad_norm   | 7.05     |\n",
      "| loss        | -1.77    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000146 |\n",
      "| recon_loss  | 0.269    |\n",
      "| samples     | 1.1e+05  |\n",
      "| step        | 3.45e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.05    |\n",
      "| grad_norm   | 4.59     |\n",
      "| loss        | -1.78    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000105 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 1.11e+05 |\n",
      "| step        | 3.46e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.06    |\n",
      "| grad_norm   | 4.72     |\n",
      "| loss        | -1.79    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000117 |\n",
      "| recon_loss  | 0.266    |\n",
      "| samples     | 1.11e+05 |\n",
      "| step        | 3.47e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.06    |\n",
      "| grad_norm   | 4.13     |\n",
      "| loss        | -1.79    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000126 |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.11e+05 |\n",
      "| step        | 3.48e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.06    |\n",
      "| grad_norm   | 5.74     |\n",
      "| loss        | -1.79    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000122 |\n",
      "| recon_loss  | 0.279    |\n",
      "| samples     | 1.12e+05 |\n",
      "| step        | 3.49e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.07    |\n",
      "| grad_norm   | 7.05     |\n",
      "| loss        | -1.81    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000109 |\n",
      "| recon_loss  | 0.272    |\n",
      "| samples     | 1.12e+05 |\n",
      "| step        | 3.5e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.07    |\n",
      "| grad_norm   | 6.12     |\n",
      "| loss        | -1.79    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000123 |\n",
      "| recon_loss  | 0.277    |\n",
      "| samples     | 1.12e+05 |\n",
      "| step        | 3.51e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.08    |\n",
      "| grad_norm   | 6.19     |\n",
      "| loss        | -1.83    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000107 |\n",
      "| recon_loss  | 0.252    |\n",
      "| samples     | 1.13e+05 |\n",
      "| step        | 3.52e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.08    |\n",
      "| grad_norm   | 5.18     |\n",
      "| loss        | -1.81    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000114 |\n",
      "| recon_loss  | 0.265    |\n",
      "| samples     | 1.13e+05 |\n",
      "| step        | 3.53e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.08    |\n",
      "| grad_norm   | 6.15     |\n",
      "| loss        | -1.82    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000102 |\n",
      "| recon_loss  | 0.27     |\n",
      "| samples     | 1.13e+05 |\n",
      "| step        | 3.54e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.09    |\n",
      "| grad_norm   | 6.16     |\n",
      "| loss        | -1.81    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00011  |\n",
      "| recon_loss  | 0.272    |\n",
      "| samples     | 1.14e+05 |\n",
      "| step        | 3.55e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.09    |\n",
      "| grad_norm   | 4.27     |\n",
      "| loss        | -1.84    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000119 |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 1.14e+05 |\n",
      "| step        | 3.56e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.1     |\n",
      "| grad_norm   | 4.61     |\n",
      "| loss        | -1.82    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000114 |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 1.14e+05 |\n",
      "| step        | 3.57e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.1     |\n",
      "| grad_norm   | 5.36     |\n",
      "| loss        | -1.84    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.45e-05 |\n",
      "| recon_loss  | 0.261    |\n",
      "| samples     | 1.15e+05 |\n",
      "| step        | 3.58e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.1     |\n",
      "| grad_norm   | 5.54     |\n",
      "| loss        | -1.86    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000115 |\n",
      "| recon_loss  | 0.266    |\n",
      "| samples     | 1.15e+05 |\n",
      "| step        | 3.59e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.11    |\n",
      "| grad_norm   | 7.43     |\n",
      "| loss        | -1.84    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000103 |\n",
      "| recon_loss  | 0.278    |\n",
      "| samples     | 1.15e+05 |\n",
      "| step        | 3.6e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.11    |\n",
      "| grad_norm   | 6.86     |\n",
      "| loss        | -1.83    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00011  |\n",
      "| recon_loss  | 0.269    |\n",
      "| samples     | 1.16e+05 |\n",
      "| step        | 3.61e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.12    |\n",
      "| grad_norm   | 5.26     |\n",
      "| loss        | -1.86    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.78e-05 |\n",
      "| recon_loss  | 0.262    |\n",
      "| samples     | 1.16e+05 |\n",
      "| step        | 3.62e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.12    |\n",
      "| grad_norm   | 6.68     |\n",
      "| loss        | -1.87    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000105 |\n",
      "| recon_loss  | 0.253    |\n",
      "| samples     | 1.16e+05 |\n",
      "| step        | 3.63e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.12    |\n",
      "| grad_norm   | 4.67     |\n",
      "| loss        | -1.85    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.93e-05 |\n",
      "| recon_loss  | 0.274    |\n",
      "| samples     | 1.17e+05 |\n",
      "| step        | 3.64e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.13    |\n",
      "| grad_norm   | 4.55     |\n",
      "| loss        | -1.86    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.86e-05 |\n",
      "| recon_loss  | 0.282    |\n",
      "| samples     | 1.17e+05 |\n",
      "| step        | 3.65e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.13    |\n",
      "| grad_norm   | 5.75     |\n",
      "| loss        | -1.87    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.82e-05 |\n",
      "| recon_loss  | 0.274    |\n",
      "| samples     | 1.17e+05 |\n",
      "| step        | 3.66e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.14    |\n",
      "| grad_norm   | 5.62     |\n",
      "| loss        | -1.87    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000105 |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.17e+05 |\n",
      "| step        | 3.67e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.14    |\n",
      "| grad_norm   | 6.41     |\n",
      "| loss        | -1.88    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.76e-05 |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.18e+05 |\n",
      "| step        | 3.68e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.14    |\n",
      "| grad_norm   | 6.34     |\n",
      "| loss        | -1.89    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000109 |\n",
      "| recon_loss  | 0.265    |\n",
      "| samples     | 1.18e+05 |\n",
      "| step        | 3.69e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.15    |\n",
      "| grad_norm   | 6.25     |\n",
      "| loss        | -1.89    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000102 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.18e+05 |\n",
      "| step        | 3.7e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.15    |\n",
      "| grad_norm   | 5.35     |\n",
      "| loss        | -1.88    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000117 |\n",
      "| recon_loss  | 0.28     |\n",
      "| samples     | 1.19e+05 |\n",
      "| step        | 3.71e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.15    |\n",
      "| grad_norm   | 6.35     |\n",
      "| loss        | -1.9     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000106 |\n",
      "| recon_loss  | 0.268    |\n",
      "| samples     | 1.19e+05 |\n",
      "| step        | 3.72e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.16    |\n",
      "| grad_norm   | 5.25     |\n",
      "| loss        | -1.88    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.46e-05 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 1.19e+05 |\n",
      "| step        | 3.73e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.16    |\n",
      "| grad_norm   | 6.03     |\n",
      "| loss        | -1.9     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.66e-05 |\n",
      "| recon_loss  | 0.264    |\n",
      "| samples     | 1.2e+05  |\n",
      "| step        | 3.74e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.17    |\n",
      "| grad_norm   | 7.75     |\n",
      "| loss        | -1.85    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000104 |\n",
      "| recon_loss  | 0.283    |\n",
      "| samples     | 1.2e+05  |\n",
      "| step        | 3.75e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.17    |\n",
      "| grad_norm   | 5.5      |\n",
      "| loss        | -1.89    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.69e-05 |\n",
      "| recon_loss  | 0.271    |\n",
      "| samples     | 1.2e+05  |\n",
      "| step        | 3.76e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.17    |\n",
      "| grad_norm   | 4.76     |\n",
      "| loss        | -1.92    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.77e-05 |\n",
      "| recon_loss  | 0.26     |\n",
      "| samples     | 1.21e+05 |\n",
      "| step        | 3.77e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.18    |\n",
      "| grad_norm   | 4.12     |\n",
      "| loss        | -1.92    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.7e-05  |\n",
      "| recon_loss  | 0.271    |\n",
      "| samples     | 1.21e+05 |\n",
      "| step        | 3.78e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.18    |\n",
      "| grad_norm   | 4.52     |\n",
      "| loss        | -1.92    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.37e-05 |\n",
      "| recon_loss  | 0.263    |\n",
      "| samples     | 1.21e+05 |\n",
      "| step        | 3.79e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.18    |\n",
      "| grad_norm   | 5.36     |\n",
      "| loss        | -1.92    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.3e-05  |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 1.22e+05 |\n",
      "| step        | 3.8e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.19    |\n",
      "| grad_norm   | 5.45     |\n",
      "| loss        | -1.93    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.35e-05 |\n",
      "| recon_loss  | 0.261    |\n",
      "| samples     | 1.22e+05 |\n",
      "| step        | 3.81e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.19    |\n",
      "| grad_norm   | 5.38     |\n",
      "| loss        | -1.92    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000106 |\n",
      "| recon_loss  | 0.266    |\n",
      "| samples     | 1.22e+05 |\n",
      "| step        | 3.82e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.19    |\n",
      "| grad_norm   | 5.51     |\n",
      "| loss        | -1.93    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.98e-05 |\n",
      "| recon_loss  | 0.262    |\n",
      "| samples     | 1.23e+05 |\n",
      "| step        | 3.83e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.2     |\n",
      "| grad_norm   | 5.73     |\n",
      "| loss        | -1.95    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.13e-05 |\n",
      "| recon_loss  | 0.253    |\n",
      "| samples     | 1.23e+05 |\n",
      "| step        | 3.84e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.2     |\n",
      "| grad_norm   | 4.92     |\n",
      "| loss        | -1.94    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000106 |\n",
      "| recon_loss  | 0.262    |\n",
      "| samples     | 1.23e+05 |\n",
      "| step        | 3.85e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.21    |\n",
      "| grad_norm   | 5.82     |\n",
      "| loss        | -1.95    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 7.93e-05 |\n",
      "| recon_loss  | 0.25     |\n",
      "| samples     | 1.24e+05 |\n",
      "| step        | 3.86e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.21    |\n",
      "| grad_norm   | 5.11     |\n",
      "| loss        | -1.93    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000101 |\n",
      "| recon_loss  | 0.278    |\n",
      "| samples     | 1.24e+05 |\n",
      "| step        | 3.87e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.21    |\n",
      "| grad_norm   | 4.87     |\n",
      "| loss        | -1.95    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000101 |\n",
      "| recon_loss  | 0.266    |\n",
      "| samples     | 1.24e+05 |\n",
      "| step        | 3.88e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.22    |\n",
      "| grad_norm   | 4.64     |\n",
      "| loss        | -1.97    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.07e-05 |\n",
      "| recon_loss  | 0.247    |\n",
      "| samples     | 1.25e+05 |\n",
      "| step        | 3.89e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.22    |\n",
      "| grad_norm   | 5.77     |\n",
      "| loss        | -1.95    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 7.96e-05 |\n",
      "| recon_loss  | 0.259    |\n",
      "| samples     | 1.25e+05 |\n",
      "| step        | 3.9e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.22    |\n",
      "| grad_norm   | 6.09     |\n",
      "| loss        | -1.96    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.74e-05 |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 1.25e+05 |\n",
      "| step        | 3.91e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.23    |\n",
      "| grad_norm   | 4.64     |\n",
      "| loss        | -1.95    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.3e-05  |\n",
      "| recon_loss  | 0.265    |\n",
      "| samples     | 1.25e+05 |\n",
      "| step        | 3.92e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.23    |\n",
      "| grad_norm   | 5.91     |\n",
      "| loss        | -1.96    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.2e-05  |\n",
      "| recon_loss  | 0.257    |\n",
      "| samples     | 1.26e+05 |\n",
      "| step        | 3.93e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.23    |\n",
      "| grad_norm   | 5.65     |\n",
      "| loss        | -1.96    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000106 |\n",
      "| recon_loss  | 0.268    |\n",
      "| samples     | 1.26e+05 |\n",
      "| step        | 3.94e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.24    |\n",
      "| grad_norm   | 5.25     |\n",
      "| loss        | -2       |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 7.81e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.26e+05 |\n",
      "| step        | 3.95e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.24    |\n",
      "| grad_norm   | 6.49     |\n",
      "| loss        | -1.96    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000102 |\n",
      "| recon_loss  | 0.265    |\n",
      "| samples     | 1.27e+05 |\n",
      "| step        | 3.96e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.24    |\n",
      "| grad_norm   | 6.76     |\n",
      "| loss        | -1.98    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 9.59e-05 |\n",
      "| recon_loss  | 0.271    |\n",
      "| samples     | 1.27e+05 |\n",
      "| step        | 3.97e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.25    |\n",
      "| grad_norm   | 6.95     |\n",
      "| loss        | -1.99    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 9.7e-05  |\n",
      "| recon_loss  | 0.262    |\n",
      "| samples     | 1.27e+05 |\n",
      "| step        | 3.98e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.25    |\n",
      "| grad_norm   | 6.3      |\n",
      "| loss        | -1.98    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 9.83e-05 |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.28e+05 |\n",
      "| step        | 3.99e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.25    |\n",
      "| grad_norm   | 5.13     |\n",
      "| loss        | -1.99    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.6e-05  |\n",
      "| recon_loss  | 0.26     |\n",
      "| samples     | 1.28e+05 |\n",
      "| step        | 4e+03    |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.26    |\n",
      "| grad_norm   | 5.55     |\n",
      "| loss        | -2.01    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.65e-05 |\n",
      "| recon_loss  | 0.247    |\n",
      "| samples     | 1.28e+05 |\n",
      "| step        | 4.01e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.26    |\n",
      "| grad_norm   | 4.18     |\n",
      "| loss        | -2.03    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.28e-05 |\n",
      "| recon_loss  | 0.24     |\n",
      "| samples     | 1.29e+05 |\n",
      "| step        | 4.02e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.26    |\n",
      "| grad_norm   | 6.14     |\n",
      "| loss        | -2.01    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.09e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.29e+05 |\n",
      "| step        | 4.03e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.27    |\n",
      "| grad_norm   | 5.82     |\n",
      "| loss        | -2.01    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.47e-05 |\n",
      "| recon_loss  | 0.252    |\n",
      "| samples     | 1.29e+05 |\n",
      "| step        | 4.04e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.27    |\n",
      "| grad_norm   | 4.89     |\n",
      "| loss        | -2.02    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.32e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.3e+05  |\n",
      "| step        | 4.05e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.27    |\n",
      "| grad_norm   | 6.87     |\n",
      "| loss        | -2.04    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.08e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.3e+05  |\n",
      "| step        | 4.06e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.28    |\n",
      "| grad_norm   | 7.49     |\n",
      "| loss        | -2.01    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.11e-05 |\n",
      "| recon_loss  | 0.257    |\n",
      "| samples     | 1.3e+05  |\n",
      "| step        | 4.07e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.28    |\n",
      "| grad_norm   | 7.25     |\n",
      "| loss        | -2       |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.29e-05 |\n",
      "| recon_loss  | 0.26     |\n",
      "| samples     | 1.31e+05 |\n",
      "| step        | 4.08e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.28    |\n",
      "| grad_norm   | 5.83     |\n",
      "| loss        | -2.04    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.61e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.31e+05 |\n",
      "| step        | 4.09e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.29    |\n",
      "| grad_norm   | 5.13     |\n",
      "| loss        | -2.03    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.48e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.31e+05 |\n",
      "| step        | 4.1e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.29    |\n",
      "| grad_norm   | 6.52     |\n",
      "| loss        | -2.04    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.71e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.32e+05 |\n",
      "| step        | 4.11e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.29    |\n",
      "| grad_norm   | 6.35     |\n",
      "| loss        | -2.05    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.75e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.32e+05 |\n",
      "| step        | 4.12e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.3     |\n",
      "| grad_norm   | 7.08     |\n",
      "| loss        | -2.04    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.58e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.32e+05 |\n",
      "| step        | 4.13e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.3     |\n",
      "| grad_norm   | 7.06     |\n",
      "| loss        | -2.04    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.36e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.33e+05 |\n",
      "| step        | 4.14e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.3     |\n",
      "| grad_norm   | 5.59     |\n",
      "| loss        | -2.06    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.51e-05 |\n",
      "| recon_loss  | 0.253    |\n",
      "| samples     | 1.33e+05 |\n",
      "| step        | 4.15e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.31    |\n",
      "| grad_norm   | 6.2      |\n",
      "| loss        | -2.06    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.23e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.33e+05 |\n",
      "| step        | 4.16e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.31    |\n",
      "| grad_norm   | 6.5      |\n",
      "| loss        | -2.03    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 9.75e-05 |\n",
      "| recon_loss  | 0.259    |\n",
      "| samples     | 1.33e+05 |\n",
      "| step        | 4.17e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.31    |\n",
      "| grad_norm   | 6.15     |\n",
      "| loss        | -2.05    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.49e-05 |\n",
      "| recon_loss  | 0.255    |\n",
      "| samples     | 1.34e+05 |\n",
      "| step        | 4.18e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.32    |\n",
      "| grad_norm   | 6.87     |\n",
      "| loss        | -2.06    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.59e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.34e+05 |\n",
      "| step        | 4.19e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.32    |\n",
      "| grad_norm   | 6.71     |\n",
      "| loss        | -2.06    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.88e-05 |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 1.34e+05 |\n",
      "| step        | 4.2e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.32    |\n",
      "| grad_norm   | 6.41     |\n",
      "| loss        | -2.07    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.8e-05  |\n",
      "| recon_loss  | 0.252    |\n",
      "| samples     | 1.35e+05 |\n",
      "| step        | 4.21e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.33    |\n",
      "| grad_norm   | 5.14     |\n",
      "| loss        | -2.07    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.96e-05 |\n",
      "| recon_loss  | 0.25     |\n",
      "| samples     | 1.35e+05 |\n",
      "| step        | 4.22e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.33    |\n",
      "| grad_norm   | 5.28     |\n",
      "| loss        | -2.07    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.06e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.35e+05 |\n",
      "| step        | 4.23e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.33    |\n",
      "| grad_norm   | 4.32     |\n",
      "| loss        | -2.08    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.45e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.36e+05 |\n",
      "| step        | 4.24e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.33    |\n",
      "| grad_norm   | 4.89     |\n",
      "| loss        | -2.09    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.58e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.36e+05 |\n",
      "| step        | 4.25e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.34    |\n",
      "| grad_norm   | 4.37     |\n",
      "| loss        | -2.08    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.6e-05  |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.36e+05 |\n",
      "| step        | 4.26e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.34    |\n",
      "| grad_norm   | 5.34     |\n",
      "| loss        | -2.08    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.21e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.37e+05 |\n",
      "| step        | 4.27e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.34    |\n",
      "| grad_norm   | 5.62     |\n",
      "| loss        | -2.1     |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.7e-05  |\n",
      "| recon_loss  | 0.248    |\n",
      "| samples     | 1.37e+05 |\n",
      "| step        | 4.28e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.35    |\n",
      "| grad_norm   | 5.04     |\n",
      "| loss        | -2.11    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.47e-05 |\n",
      "| recon_loss  | 0.239    |\n",
      "| samples     | 1.37e+05 |\n",
      "| step        | 4.29e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.35    |\n",
      "| grad_norm   | 5.37     |\n",
      "| loss        | -2.09    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 9.99e-05 |\n",
      "| recon_loss  | 0.253    |\n",
      "| samples     | 1.38e+05 |\n",
      "| step        | 4.3e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.35    |\n",
      "| grad_norm   | 4.97     |\n",
      "| loss        | -2.11    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.42e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.38e+05 |\n",
      "| step        | 4.31e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.36    |\n",
      "| grad_norm   | 6.1      |\n",
      "| loss        | -2.12    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.08e-05 |\n",
      "| recon_loss  | 0.245    |\n",
      "| samples     | 1.38e+05 |\n",
      "| step        | 4.32e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.36    |\n",
      "| grad_norm   | 5.99     |\n",
      "| loss        | -2.09    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.46e-05 |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 1.39e+05 |\n",
      "| step        | 4.33e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.36    |\n",
      "| grad_norm   | 4.77     |\n",
      "| loss        | -2.11    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.48e-05 |\n",
      "| recon_loss  | 0.249    |\n",
      "| samples     | 1.39e+05 |\n",
      "| step        | 4.34e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.36    |\n",
      "| grad_norm   | 4        |\n",
      "| loss        | -2.13    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.95e-05 |\n",
      "| recon_loss  | 0.24     |\n",
      "| samples     | 1.39e+05 |\n",
      "| step        | 4.35e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.37    |\n",
      "| grad_norm   | 5.94     |\n",
      "| loss        | -2.13    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.43e-05 |\n",
      "| recon_loss  | 0.239    |\n",
      "| samples     | 1.4e+05  |\n",
      "| step        | 4.36e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.37    |\n",
      "| grad_norm   | 6.61     |\n",
      "| loss        | -2.09    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.9e-05  |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.4e+05  |\n",
      "| step        | 4.37e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.37    |\n",
      "| grad_norm   | 5.09     |\n",
      "| loss        | -2.1     |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.77e-05 |\n",
      "| recon_loss  | 0.265    |\n",
      "| samples     | 1.4e+05  |\n",
      "| step        | 4.38e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.38    |\n",
      "| grad_norm   | 5.32     |\n",
      "| loss        | -2.12    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.36e-05 |\n",
      "| recon_loss  | 0.253    |\n",
      "| samples     | 1.41e+05 |\n",
      "| step        | 4.39e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.38    |\n",
      "| grad_norm   | 4.84     |\n",
      "| loss        | -2.12    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.04e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.41e+05 |\n",
      "| step        | 4.4e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.38    |\n",
      "| grad_norm   | 6.27     |\n",
      "| loss        | -2.12    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.74e-05 |\n",
      "| recon_loss  | 0.248    |\n",
      "| samples     | 1.41e+05 |\n",
      "| step        | 4.41e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.38    |\n",
      "| grad_norm   | 4.59     |\n",
      "| loss        | -2.15    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.36e-05 |\n",
      "| recon_loss  | 0.235    |\n",
      "| samples     | 1.41e+05 |\n",
      "| step        | 4.42e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.39    |\n",
      "| grad_norm   | 4.22     |\n",
      "| loss        | -2.16    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.95e-05 |\n",
      "| recon_loss  | 0.228    |\n",
      "| samples     | 1.42e+05 |\n",
      "| step        | 4.43e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.39    |\n",
      "| grad_norm   | 5.02     |\n",
      "| loss        | -2.14    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.08e-05 |\n",
      "| recon_loss  | 0.238    |\n",
      "| samples     | 1.42e+05 |\n",
      "| step        | 4.44e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.39    |\n",
      "| grad_norm   | 5.76     |\n",
      "| loss        | -2.14    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.77e-05 |\n",
      "| recon_loss  | 0.247    |\n",
      "| samples     | 1.42e+05 |\n",
      "| step        | 4.45e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.4     |\n",
      "| grad_norm   | 4.76     |\n",
      "| loss        | -2.15    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.15e-05 |\n",
      "| recon_loss  | 0.25     |\n",
      "| samples     | 1.43e+05 |\n",
      "| step        | 4.46e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.4     |\n",
      "| grad_norm   | 5.43     |\n",
      "| loss        | -2.17    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.88e-05 |\n",
      "| recon_loss  | 0.231    |\n",
      "| samples     | 1.43e+05 |\n",
      "| step        | 4.47e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.4     |\n",
      "| grad_norm   | 5.24     |\n",
      "| loss        | -2.16    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.43e-05 |\n",
      "| recon_loss  | 0.238    |\n",
      "| samples     | 1.43e+05 |\n",
      "| step        | 4.48e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.4     |\n",
      "| grad_norm   | 4.66     |\n",
      "| loss        | -2.16    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.78e-05 |\n",
      "| recon_loss  | 0.233    |\n",
      "| samples     | 1.44e+05 |\n",
      "| step        | 4.49e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.41    |\n",
      "| grad_norm   | 5.77     |\n",
      "| loss        | -2.15    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.47e-05 |\n",
      "| recon_loss  | 0.252    |\n",
      "| samples     | 1.44e+05 |\n",
      "| step        | 4.5e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.41    |\n",
      "| grad_norm   | 5.01     |\n",
      "| loss        | -2.17    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.67e-05 |\n",
      "| recon_loss  | 0.25     |\n",
      "| samples     | 1.44e+05 |\n",
      "| step        | 4.51e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.41    |\n",
      "| grad_norm   | 5.23     |\n",
      "| loss        | -2.15    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.37e-05 |\n",
      "| recon_loss  | 0.247    |\n",
      "| samples     | 1.45e+05 |\n",
      "| step        | 4.52e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.41    |\n",
      "| grad_norm   | 4.86     |\n",
      "| loss        | -2.17    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.43e-05 |\n",
      "| recon_loss  | 0.238    |\n",
      "| samples     | 1.45e+05 |\n",
      "| step        | 4.53e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.42    |\n",
      "| grad_norm   | 5.12     |\n",
      "| loss        | -2.18    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.03e-05 |\n",
      "| recon_loss  | 0.232    |\n",
      "| samples     | 1.45e+05 |\n",
      "| step        | 4.54e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.42    |\n",
      "| grad_norm   | 5.64     |\n",
      "| loss        | -2.17    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.48e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.46e+05 |\n",
      "| step        | 4.55e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.42    |\n",
      "| grad_norm   | 4.36     |\n",
      "| loss        | -2.18    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.55e-05 |\n",
      "| recon_loss  | 0.248    |\n",
      "| samples     | 1.46e+05 |\n",
      "| step        | 4.56e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.42    |\n",
      "| grad_norm   | 4.92     |\n",
      "| loss        | -2.18    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.88e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.46e+05 |\n",
      "| step        | 4.57e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.43    |\n",
      "| grad_norm   | 7.08     |\n",
      "| loss        | -2.19    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.72e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.47e+05 |\n",
      "| step        | 4.58e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.43    |\n",
      "| grad_norm   | 6.49     |\n",
      "| loss        | -2.18    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.66e-05 |\n",
      "| recon_loss  | 0.241    |\n",
      "| samples     | 1.47e+05 |\n",
      "| step        | 4.59e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.43    |\n",
      "| grad_norm   | 5.41     |\n",
      "| loss        | -2.19    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.56e-05 |\n",
      "| recon_loss  | 0.247    |\n",
      "| samples     | 1.47e+05 |\n",
      "| step        | 4.6e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.44    |\n",
      "| grad_norm   | 4.76     |\n",
      "| loss        | -2.19    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.17e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.48e+05 |\n",
      "| step        | 4.61e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.44    |\n",
      "| grad_norm   | 4.59     |\n",
      "| loss        | -2.19    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.02e-05 |\n",
      "| recon_loss  | 0.255    |\n",
      "| samples     | 1.48e+05 |\n",
      "| step        | 4.62e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.44    |\n",
      "| grad_norm   | 5.28     |\n",
      "| loss        | -2.19    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.34e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.48e+05 |\n",
      "| step        | 4.63e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.44    |\n",
      "| grad_norm   | 5.94     |\n",
      "| loss        | -2.2     |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.42e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.49e+05 |\n",
      "| step        | 4.64e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.45    |\n",
      "| grad_norm   | 6.26     |\n",
      "| loss        | -2.21    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.36e-05 |\n",
      "| recon_loss  | 0.236    |\n",
      "| samples     | 1.49e+05 |\n",
      "| step        | 4.65e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.45    |\n",
      "| grad_norm   | 6.54     |\n",
      "| loss        | -2.22    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.59e-05 |\n",
      "| recon_loss  | 0.24     |\n",
      "| samples     | 1.49e+05 |\n",
      "| step        | 4.66e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.45    |\n",
      "| grad_norm   | 6.6      |\n",
      "| loss        | -2.2     |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.82e-05 |\n",
      "| recon_loss  | 0.238    |\n",
      "| samples     | 1.49e+05 |\n",
      "| step        | 4.67e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.45    |\n",
      "| grad_norm   | 6.28     |\n",
      "| loss        | -2.23    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.79e-05 |\n",
      "| recon_loss  | 0.223    |\n",
      "| samples     | 1.5e+05  |\n",
      "| step        | 4.68e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.46    |\n",
      "| grad_norm   | 6.73     |\n",
      "| loss        | -2.21    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.35e-05 |\n",
      "| recon_loss  | 0.244    |\n",
      "| samples     | 1.5e+05  |\n",
      "| step        | 4.69e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.46    |\n",
      "| grad_norm   | 6.44     |\n",
      "| loss        | -2.21    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.72e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.5e+05  |\n",
      "| step        | 4.7e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.46    |\n",
      "| grad_norm   | 6.2      |\n",
      "| loss        | -2.23    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.68e-05 |\n",
      "| recon_loss  | 0.232    |\n",
      "| samples     | 1.51e+05 |\n",
      "| step        | 4.71e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.46    |\n",
      "| grad_norm   | 6.36     |\n",
      "| loss        | -2.23    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.33e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.51e+05 |\n",
      "| step        | 4.72e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.47    |\n",
      "| grad_norm   | 6.75     |\n",
      "| loss        | -2.22    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.01e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.51e+05 |\n",
      "| step        | 4.73e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.47    |\n",
      "| grad_norm   | 7.31     |\n",
      "| loss        | -2.22    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.12e-05 |\n",
      "| recon_loss  | 0.241    |\n",
      "| samples     | 1.52e+05 |\n",
      "| step        | 4.74e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.47    |\n",
      "| grad_norm   | 5.87     |\n",
      "| loss        | -2.23    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.71e-05 |\n",
      "| recon_loss  | 0.239    |\n",
      "| samples     | 1.52e+05 |\n",
      "| step        | 4.75e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.47    |\n",
      "| grad_norm   | 6.06     |\n",
      "| loss        | -2.22    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.92e-05 |\n",
      "| recon_loss  | 0.242    |\n",
      "| samples     | 1.52e+05 |\n",
      "| step        | 4.76e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.48    |\n",
      "| grad_norm   | 4.4      |\n",
      "| loss        | -2.23    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.84e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.53e+05 |\n",
      "| step        | 4.77e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.48    |\n",
      "| grad_norm   | 5.65     |\n",
      "| loss        | -2.25    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.74e-05 |\n",
      "| recon_loss  | 0.226    |\n",
      "| samples     | 1.53e+05 |\n",
      "| step        | 4.78e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.48    |\n",
      "| grad_norm   | 5.16     |\n",
      "| loss        | -2.25    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.75e-05 |\n",
      "| recon_loss  | 0.24     |\n",
      "| samples     | 1.53e+05 |\n",
      "| step        | 4.79e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n"
     ]
    }
   ],
   "source": [
    "!python train.py --cuda_devices 0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './results/progress.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/train.py:98\u001b[0m\n\u001b[1;32m     94\u001b[0m         init_processes(dataset, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, cfg)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/train.py:74\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m num_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args\u001b[38;5;241m.\u001b[39mcuda_devices\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     73\u001b[0m cfg \u001b[38;5;241m=\u001b[39m get_config_from_file(args\u001b[38;5;241m.\u001b[39mconfig, args\u001b[38;5;241m.\u001b[39mphase)\n\u001b[0;32m---> 74\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading dataset ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m dataset \u001b[38;5;241m=\u001b[39m build_dataset(cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/scripts/logger.py:467\u001b[0m, in \u001b[0;36mconfigure\u001b[0;34m(dir, format_strs, comm, log_suffix)\u001b[0m\n\u001b[1;32m    465\u001b[0m         format_strs \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_LOG_FORMAT_MPI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m format_strs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, format_strs)\n\u001b[0;32m--> 467\u001b[0m output_formats \u001b[38;5;241m=\u001b[39m [make_output_format(f, \u001b[38;5;28mdir\u001b[39m, log_suffix) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m format_strs]\n\u001b[1;32m    469\u001b[0m Logger\u001b[38;5;241m.\u001b[39mCURRENT \u001b[38;5;241m=\u001b[39m Logger(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdir\u001b[39m, output_formats\u001b[38;5;241m=\u001b[39moutput_formats, comm\u001b[38;5;241m=\u001b[39mcomm)\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_formats:\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/scripts/logger.py:467\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    465\u001b[0m         format_strs \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_LOG_FORMAT_MPI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m format_strs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, format_strs)\n\u001b[0;32m--> 467\u001b[0m output_formats \u001b[38;5;241m=\u001b[39m [\u001b[43mmake_output_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_suffix\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m format_strs]\n\u001b[1;32m    469\u001b[0m Logger\u001b[38;5;241m.\u001b[39mCURRENT \u001b[38;5;241m=\u001b[39m Logger(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdir\u001b[39m, output_formats\u001b[38;5;241m=\u001b[39moutput_formats, comm\u001b[38;5;241m=\u001b[39mcomm)\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_formats:\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/scripts/logger.py:200\u001b[0m, in \u001b[0;36mmake_output_format\u001b[0;34m(format, ev_dir, log_suffix)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JSONOutputFormat(osp\u001b[38;5;241m.\u001b[39mjoin(ev_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprogress\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m log_suffix))\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCSVOutputFormat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mosp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mev_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprogress\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlog_suffix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TensorBoardOutputFormat(osp\u001b[38;5;241m.\u001b[39mjoin(ev_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtb\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m log_suffix))\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/scripts/logger.py:115\u001b[0m, in \u001b[0;36mCSVOutputFormat.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './results/progress.csv'"
     ]
    }
   ],
   "source": [
    "%run train.py --cuda_devices 0,1,2,3 --phase detection --config configs/train_detection_conf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
