{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.detectors.zid_rcnn import ZidRCNN\n",
    "\n",
    "def build_detector(model_cfg):\n",
    "    model_cfg_ = model_cfg.copy()\n",
    "\n",
    "    model_type = model_cfg_.pop('type') \n",
    "    assert model_type == 'ZidRCNN', f'{model_type} is not implemented yet.'\n",
    "    return ZidRCNN(**model_cfg_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.builder import build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "def get_config_from_file(filename, mode):\n",
    "    spec = importlib.util.spec_from_file_location(mode, filename)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "    # Create a dictionary from module attributes\n",
    "    config_dict = {key: getattr(module, key) for key in dir(module) if not key.startswith('__')}\n",
    "    return config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhnh/python_venv/cv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/minhnh/python_venv/cv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from: torchvision://resnet50\n",
      "This is Phase 1, Voxel Reconstruction Training Phase\n",
      "Loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9600/9600 [00:01<00:00, 5598.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos: 9600\n",
      "Loading object size from existing path (we will first crop then resize the image for recon)\n"
     ]
    }
   ],
   "source": [
    "cfg = get_config_from_file('configs/train_reconstruction_conf.py', 'reconstruction')\n",
    "model = build_detector(cfg.get('model'))\n",
    "dataset = build_dataset(cfg.get('data')['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from models.utils.data_container import collate\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "num_workers=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=True,\n",
    "                collate_fn=partial(collate, samples_per_gpu=batch_size),\n",
    "                # sampler=self.train_sampler,\n",
    "                drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rgb': tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), 'traj': tensor([[[[ 1.0000e+00,  9.1633e-08, -5.8942e-08,  0.0000e+00],\n",
      "          [ 9.1633e-08,  1.0000e+00,  8.9407e-08,  0.0000e+00],\n",
      "          [-5.8942e-08,  8.9407e-08,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -6.4889e-02,  1.4234e-01,  0.0000e+00],\n",
      "          [ 6.4889e-02,  9.9788e-01,  4.6470e-03,  0.0000e+00],\n",
      "          [-1.4234e-01,  4.6467e-03,  9.8981e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.5106e-01, -1.2818e-01,  2.8118e-01,  0.0000e+00],\n",
      "          [ 1.2818e-01,  9.9158e-01,  1.8473e-02,  0.0000e+00],\n",
      "          [-2.8118e-01,  1.8472e-02,  9.5948e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0902e-01,  3.9450e-01, -8.6538e-01,  0.0000e+00],\n",
      "          [-3.9450e-01,  8.8111e-01,  2.6080e-01,  0.0000e+00],\n",
      "          [ 8.6538e-01,  2.6080e-01,  4.2791e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-9.8769e-01,  6.4889e-02, -1.4234e-01,  0.0000e+00],\n",
      "          [-6.4889e-02,  6.5800e-01,  7.5022e-01,  0.0000e+00],\n",
      "          [ 1.4234e-01,  7.5022e-01, -6.4569e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 8.0902e-01, -2.4381e-01,  5.3483e-01,  0.0000e+00],\n",
      "          [ 2.4381e-01,  9.6714e-01,  7.2083e-02,  0.0000e+00],\n",
      "          [-5.3483e-01,  7.2083e-02,  8.4188e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000e+00, -2.3206e-08,  1.9280e-08,  0.0000e+00],\n",
      "          [-2.3206e-08,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 1.9280e-08,  0.0000e+00,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -6.4603e-02,  1.4247e-01,  0.0000e+00],\n",
      "          [ 6.4603e-02,  9.9790e-01,  4.6302e-03,  0.0000e+00],\n",
      "          [-1.4247e-01,  4.6309e-03,  9.8979e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 8.9101e-01, -1.8749e-01,  4.1347e-01,  0.0000e+00],\n",
      "          [ 1.8749e-01,  9.8141e-01,  4.0994e-02,  0.0000e+00],\n",
      "          [-4.1347e-01,  4.0994e-02,  9.0960e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5399e-01,  3.6796e-01, -8.1148e-01,  0.0000e+00],\n",
      "          [-3.6796e-01,  9.0688e-01,  2.0536e-01,  0.0000e+00],\n",
      "          [ 8.1148e-01,  2.0536e-01,  5.4711e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-9.5106e-01, -1.2762e-01,  2.8143e-01,  0.0000e+00],\n",
      "          [ 1.2762e-01,  6.6725e-01,  7.3382e-01,  0.0000e+00],\n",
      "          [-2.8143e-01,  7.3382e-01, -6.1831e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -6.4603e-02,  1.4247e-01,  0.0000e+00],\n",
      "          [ 6.4603e-02,  9.9790e-01,  4.6303e-03,  0.0000e+00],\n",
      "          [-1.4247e-01,  4.6309e-03,  9.8979e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000e+00,  1.7342e-08, -2.3771e-08,  0.0000e+00],\n",
      "          [ 1.7342e-08,  1.0000e+00,  5.9605e-08,  0.0000e+00],\n",
      "          [-2.3771e-08,  5.9605e-08,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.5106e-01, -1.1865e-01,  2.8533e-01,  0.0000e+00],\n",
      "          [ 1.1865e-01,  9.9278e-01,  1.7352e-02,  0.0000e+00],\n",
      "          [-2.8533e-01,  1.7353e-02,  9.5827e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 8.9101e-01, -1.7432e-01,  4.1919e-01,  0.0000e+00],\n",
      "          [ 1.7432e-01,  9.8393e-01,  3.8642e-02,  0.0000e+00],\n",
      "          [-4.1919e-01,  3.8642e-02,  9.0708e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5399e-01,  3.4212e-01, -8.2271e-01,  0.0000e+00],\n",
      "          [-3.4212e-01,  9.1950e-01,  1.9358e-01,  0.0000e+00],\n",
      "          [ 8.2271e-01,  1.9358e-01,  5.3449e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-3.5763e-07,  3.8397e-01, -9.2335e-01,  0.0000e+00],\n",
      "          [-3.8397e-01,  8.5257e-01,  3.5454e-01,  0.0000e+00],\n",
      "          [ 9.2335e-01,  3.5454e-01,  1.4743e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-1.5643e-01, -3.7924e-01,  9.1198e-01,  0.0000e+00],\n",
      "          [ 3.7924e-01,  8.2950e-01,  4.1000e-01,  0.0000e+00],\n",
      "          [-9.1198e-01,  4.1000e-01,  1.4063e-02,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0000e+00, -2.2192e-08,  2.2680e-08,  0.0000e+00],\n",
      "          [-2.2192e-08,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 2.2680e-08,  0.0000e+00,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -7.5596e-02,  1.3696e-01,  0.0000e+00],\n",
      "          [ 7.5596e-02,  9.9712e-01,  5.2088e-03,  0.0000e+00],\n",
      "          [-1.3696e-01,  5.2088e-03,  9.9056e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.5106e-01, -1.4933e-01,  2.7054e-01,  0.0000e+00],\n",
      "          [ 1.4933e-01,  9.8857e-01,  2.0707e-02,  0.0000e+00],\n",
      "          [-2.7054e-01,  2.0707e-02,  9.6249e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.9101e-01, -2.1939e-01,  3.9746e-01,  0.0000e+00],\n",
      "          [ 2.1939e-01,  5.5840e-01,  8.0004e-01,  0.0000e+00],\n",
      "          [-3.9746e-01,  8.0004e-01, -4.4941e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-4.5399e-01, -4.3057e-01,  7.8006e-01,  0.0000e+00],\n",
      "          [ 4.3057e-01,  6.6046e-01,  6.1515e-01,  0.0000e+00],\n",
      "          [-7.8006e-01,  6.1515e-01, -1.1445e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-1.5643e-01, -4.7730e-01,  8.6471e-01,  0.0000e+00],\n",
      "          [ 4.7730e-01,  7.2994e-01,  4.8926e-01,  0.0000e+00],\n",
      "          [-8.6471e-01,  4.8926e-01,  1.1362e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000e+00, -1.7223e-08, -3.8344e-09,  0.0000e+00],\n",
      "          [-1.7223e-08,  1.0000e+00,  2.9802e-08,  0.0000e+00],\n",
      "          [-3.8344e-09,  2.9802e-08,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -8.8267e-02,  1.2915e-01,  0.0000e+00],\n",
      "          [ 8.8267e-02,  9.9608e-01,  5.7350e-03,  0.0000e+00],\n",
      "          [-1.2915e-01,  5.7357e-03,  9.9161e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.5106e-01, -1.7436e-01,  2.5513e-01,  0.0000e+00],\n",
      "          [ 1.7436e-01,  9.8442e-01,  2.2800e-02,  0.0000e+00],\n",
      "          [-2.5513e-01,  2.2800e-02,  9.6664e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0902e-01,  5.3663e-01, -7.8520e-01,  0.0000e+00],\n",
      "          [-5.3663e-01,  5.8325e-01,  6.0980e-01,  0.0000e+00],\n",
      "          [ 7.8520e-01,  6.0980e-01,  1.0774e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-9.5106e-01, -1.7436e-01,  2.5513e-01,  0.0000e+00],\n",
      "          [ 1.7436e-01,  3.7884e-01,  9.0889e-01,  0.0000e+00],\n",
      "          [-2.5513e-01,  9.0889e-01, -3.2990e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 5.8779e-01, -4.5648e-01,  6.6793e-01,  0.0000e+00],\n",
      "          [ 4.5648e-01,  8.6876e-01,  1.9203e-01,  0.0000e+00],\n",
      "          [-6.6793e-01,  1.9203e-01,  7.1902e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000e+00,  7.6595e-10, -1.9264e-08,  0.0000e+00],\n",
      "          [ 7.6595e-10,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [-1.9264e-08,  0.0000e+00,  1.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8769e-01, -5.9871e-02,  1.4452e-01,  0.0000e+00],\n",
      "          [ 5.9871e-02,  9.9820e-01,  4.3526e-03,  0.0000e+00],\n",
      "          [-1.4452e-01,  4.3538e-03,  9.8949e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.5106e-01, -1.1827e-01,  2.8549e-01,  0.0000e+00],\n",
      "          [ 1.1827e-01,  9.9283e-01,  1.7305e-02,  0.0000e+00],\n",
      "          [-2.8549e-01,  1.7306e-02,  9.5823e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.8769e-01, -5.9871e-02,  1.4452e-01,  0.0000e+00],\n",
      "          [ 5.9871e-02,  7.0885e-01,  7.0281e-01,  0.0000e+00],\n",
      "          [-1.4452e-01,  7.0281e-01, -6.9654e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-3.0902e-01, -3.6399e-01,  8.7865e-01,  0.0000e+00],\n",
      "          [ 3.6399e-01,  8.0826e-01,  4.6285e-01,  0.0000e+00],\n",
      "          [-8.7865e-01,  4.6285e-01, -1.1728e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 8.0902e-01, -2.2496e-01,  5.4303e-01,  0.0000e+00],\n",
      "          [ 2.2496e-01,  9.7203e-01,  6.7529e-02,  0.0000e+00],\n",
      "          [-5.4303e-01,  6.7528e-02,  8.3699e-01,  0.0000e+00]]]])}\n"
     ]
    }
   ],
   "source": [
    "for x in data:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdab425fa30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x['rgb'][7][34].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'ep01', '100000']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"_ep01_100000\".split(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ep01'[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./results\n",
      "Loading dataset ...\n",
      "This is Phase 1, Voxel Reconstruction Training Phase\n",
      "Loading images...\n",
      "100%|█████████████████████████████████████| 9600/9600 [00:01<00:00, 5592.22it/s]\n",
      "Videos: 9600\n",
      "Loading object size from existing path (we will first crop then resize the image for recon)\n",
      "training...\n",
      "Training on 4 GPUs: 0,1,2,3\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "load model from: torchvision://resnet50\n",
      "load model from: torchvision://resnet50\n",
      "load model from: torchvision://resnet50\n",
      "load model from: torchvision://resnet50\n",
      "Rank: 3 - Device: cuda:3 3\n",
      "Rank: 0 - Device: cuda:0 0\n",
      "Rank: 1 - Device: cuda:1 1\n",
      "Rank: 2 - Device: cuda:2 2\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4377: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4377: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4377: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4377: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/tungnt/.local/lib/python3.8/site-packages/torch/nn/functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | 0.00229  |\n",
      "| grad_norm   | 10.5     |\n",
      "| loss        | 2.32     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.175    |\n",
      "| recon_loss  | 2.22     |\n",
      "| samples     | 32       |\n",
      "| step        | 0        |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0317  |\n",
      "| grad_norm   | 7.69     |\n",
      "| loss        | 2.22     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.124    |\n",
      "| recon_loss  | 2.1      |\n",
      "| samples     | 352      |\n",
      "| step        | 10       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0538  |\n",
      "| grad_norm   | 4.06     |\n",
      "| loss        | 1.83     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0725   |\n",
      "| recon_loss  | 1.77     |\n",
      "| samples     | 672      |\n",
      "| step        | 20       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0647  |\n",
      "| grad_norm   | 3.02     |\n",
      "| loss        | 1.46     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0466   |\n",
      "| recon_loss  | 1.52     |\n",
      "| samples     | 992      |\n",
      "| step        | 30       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0709  |\n",
      "| grad_norm   | 2.62     |\n",
      "| loss        | 1.62     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0384   |\n",
      "| recon_loss  | 1.58     |\n",
      "| samples     | 1.31e+03 |\n",
      "| step        | 40       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0768  |\n",
      "| grad_norm   | 2.71     |\n",
      "| loss        | 1.41     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.035    |\n",
      "| recon_loss  | 1.47     |\n",
      "| samples     | 1.63e+03 |\n",
      "| step        | 50       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0699  |\n",
      "| grad_norm   | 4.14     |\n",
      "| loss        | 1.32     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0388   |\n",
      "| recon_loss  | 1.32     |\n",
      "| samples     | 1.95e+03 |\n",
      "| step        | 60       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.065   |\n",
      "| grad_norm   | 6.85     |\n",
      "| loss        | 1.04     |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0377   |\n",
      "| recon_loss  | 1.07     |\n",
      "| samples     | 2.27e+03 |\n",
      "| step        | 70       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0741  |\n",
      "| grad_norm   | 6.33     |\n",
      "| loss        | 0.925    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0326   |\n",
      "| recon_loss  | 0.963    |\n",
      "| samples     | 2.59e+03 |\n",
      "| step        | 80       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.063   |\n",
      "| grad_norm   | 7.05     |\n",
      "| loss        | 0.888    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0271   |\n",
      "| recon_loss  | 0.942    |\n",
      "| samples     | 2.91e+03 |\n",
      "| step        | 90       |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.0821  |\n",
      "| grad_norm   | 8.73     |\n",
      "| loss        | 0.818    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0234   |\n",
      "| recon_loss  | 0.886    |\n",
      "| samples     | 3.23e+03 |\n",
      "| step        | 100      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.094   |\n",
      "| grad_norm   | 6.58     |\n",
      "| loss        | 0.723    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0189   |\n",
      "| recon_loss  | 0.853    |\n",
      "| samples     | 3.55e+03 |\n",
      "| step        | 110      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.1     |\n",
      "| grad_norm   | 7.12     |\n",
      "| loss        | 0.645    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0166   |\n",
      "| recon_loss  | 0.749    |\n",
      "| samples     | 3.87e+03 |\n",
      "| step        | 120      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.106   |\n",
      "| grad_norm   | 7.61     |\n",
      "| loss        | 0.633    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0155   |\n",
      "| recon_loss  | 0.745    |\n",
      "| samples     | 4.19e+03 |\n",
      "| step        | 130      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.112   |\n",
      "| grad_norm   | 7.69     |\n",
      "| loss        | 0.583    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0138   |\n",
      "| recon_loss  | 0.707    |\n",
      "| samples     | 4.51e+03 |\n",
      "| step        | 140      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.118   |\n",
      "| grad_norm   | 10.3     |\n",
      "| loss        | 0.598    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0132   |\n",
      "| recon_loss  | 0.731    |\n",
      "| samples     | 4.83e+03 |\n",
      "| step        | 150      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.123   |\n",
      "| grad_norm   | 9.06     |\n",
      "| loss        | 0.559    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0126   |\n",
      "| recon_loss  | 0.698    |\n",
      "| samples     | 5.15e+03 |\n",
      "| step        | 160      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.129   |\n",
      "| grad_norm   | 11.5     |\n",
      "| loss        | 0.553    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0117   |\n",
      "| recon_loss  | 0.674    |\n",
      "| samples     | 5.47e+03 |\n",
      "| step        | 170      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.135   |\n",
      "| grad_norm   | 6.11     |\n",
      "| loss        | 0.568    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0114   |\n",
      "| recon_loss  | 0.69     |\n",
      "| samples     | 5.79e+03 |\n",
      "| step        | 180      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.141   |\n",
      "| grad_norm   | 8.21     |\n",
      "| loss        | 0.506    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0106   |\n",
      "| recon_loss  | 0.639    |\n",
      "| samples     | 6.11e+03 |\n",
      "| step        | 190      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.146   |\n",
      "| grad_norm   | 7.63     |\n",
      "| loss        | 0.467    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.0105   |\n",
      "| recon_loss  | 0.622    |\n",
      "| samples     | 6.43e+03 |\n",
      "| step        | 200      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.153   |\n",
      "| grad_norm   | 9.95     |\n",
      "| loss        | 0.486    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00953  |\n",
      "| recon_loss  | 0.614    |\n",
      "| samples     | 6.75e+03 |\n",
      "| step        | 210      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.159   |\n",
      "| grad_norm   | 8.63     |\n",
      "| loss        | 0.466    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00965  |\n",
      "| recon_loss  | 0.643    |\n",
      "| samples     | 7.07e+03 |\n",
      "| step        | 220      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.164   |\n",
      "| grad_norm   | 8.06     |\n",
      "| loss        | 0.438    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00902  |\n",
      "| recon_loss  | 0.608    |\n",
      "| samples     | 7.39e+03 |\n",
      "| step        | 230      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.171   |\n",
      "| grad_norm   | 9.85     |\n",
      "| loss        | 0.453    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00836  |\n",
      "| recon_loss  | 0.621    |\n",
      "| samples     | 7.71e+03 |\n",
      "| step        | 240      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.177   |\n",
      "| grad_norm   | 10.1     |\n",
      "| loss        | 0.418    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00836  |\n",
      "| recon_loss  | 0.588    |\n",
      "| samples     | 8.03e+03 |\n",
      "| step        | 250      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.183   |\n",
      "| grad_norm   | 8.04     |\n",
      "| loss        | 0.401    |\n",
      "| param_norm  | 153      |\n",
      "| percep_loss | 0.00801  |\n",
      "| recon_loss  | 0.579    |\n",
      "| samples     | 8.35e+03 |\n",
      "| step        | 260      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.19    |\n",
      "| grad_norm   | 10.2     |\n",
      "| loss        | 0.375    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00747  |\n",
      "| recon_loss  | 0.56     |\n",
      "| samples     | 8.67e+03 |\n",
      "| step        | 270      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.196   |\n",
      "| grad_norm   | 6.18     |\n",
      "| loss        | 0.347    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00759  |\n",
      "| recon_loss  | 0.545    |\n",
      "| samples     | 8.99e+03 |\n",
      "| step        | 280      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 1        |\n",
      "| gan_loss    | -0.203   |\n",
      "| grad_norm   | 6.3      |\n",
      "| loss        | 0.323    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00702  |\n",
      "| recon_loss  | 0.529    |\n",
      "| samples     | 9.31e+03 |\n",
      "| step        | 290      |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.209   |\n",
      "| grad_norm   | 10.4     |\n",
      "| loss        | 0.324    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00646  |\n",
      "| recon_loss  | 0.524    |\n",
      "| samples     | 9.63e+03 |\n",
      "| step        | 300      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.215   |\n",
      "| grad_norm   | 8.61     |\n",
      "| loss        | 0.317    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00656  |\n",
      "| recon_loss  | 0.541    |\n",
      "| samples     | 9.95e+03 |\n",
      "| step        | 310      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.222   |\n",
      "| grad_norm   | 7.67     |\n",
      "| loss        | 0.309    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0064   |\n",
      "| recon_loss  | 0.522    |\n",
      "| samples     | 1.03e+04 |\n",
      "| step        | 320      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.228   |\n",
      "| grad_norm   | 7.44     |\n",
      "| loss        | 0.281    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00607  |\n",
      "| recon_loss  | 0.512    |\n",
      "| samples     | 1.06e+04 |\n",
      "| step        | 330      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.235   |\n",
      "| grad_norm   | 10       |\n",
      "| loss        | 0.314    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00568  |\n",
      "| recon_loss  | 0.528    |\n",
      "| samples     | 1.09e+04 |\n",
      "| step        | 340      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.242   |\n",
      "| grad_norm   | 8.25     |\n",
      "| loss        | 0.274    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00559  |\n",
      "| recon_loss  | 0.509    |\n",
      "| samples     | 1.12e+04 |\n",
      "| step        | 350      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.248   |\n",
      "| grad_norm   | 5.68     |\n",
      "| loss        | 0.225    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00555  |\n",
      "| recon_loss  | 0.473    |\n",
      "| samples     | 1.16e+04 |\n",
      "| step        | 360      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.255   |\n",
      "| grad_norm   | 7.4      |\n",
      "| loss        | 0.249    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0055   |\n",
      "| recon_loss  | 0.511    |\n",
      "| samples     | 1.19e+04 |\n",
      "| step        | 370      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.261   |\n",
      "| grad_norm   | 8.21     |\n",
      "| loss        | 0.252    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00541  |\n",
      "| recon_loss  | 0.501    |\n",
      "| samples     | 1.22e+04 |\n",
      "| step        | 380      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.268   |\n",
      "| grad_norm   | 10.1     |\n",
      "| loss        | 0.263    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00523  |\n",
      "| recon_loss  | 0.508    |\n",
      "| samples     | 1.25e+04 |\n",
      "| step        | 390      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.274   |\n",
      "| grad_norm   | 10.2     |\n",
      "| loss        | 0.227    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00486  |\n",
      "| recon_loss  | 0.49     |\n",
      "| samples     | 1.28e+04 |\n",
      "| step        | 400      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.281   |\n",
      "| grad_norm   | 8.09     |\n",
      "| loss        | 0.221    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00475  |\n",
      "| recon_loss  | 0.485    |\n",
      "| samples     | 1.32e+04 |\n",
      "| step        | 410      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.288   |\n",
      "| grad_norm   | 9.31     |\n",
      "| loss        | 0.224    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00487  |\n",
      "| recon_loss  | 0.497    |\n",
      "| samples     | 1.35e+04 |\n",
      "| step        | 420      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.294   |\n",
      "| grad_norm   | 10.9     |\n",
      "| loss        | 0.222    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00442  |\n",
      "| recon_loss  | 0.497    |\n",
      "| samples     | 1.38e+04 |\n",
      "| step        | 430      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.301   |\n",
      "| grad_norm   | 7.99     |\n",
      "| loss        | 0.191    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00459  |\n",
      "| recon_loss  | 0.488    |\n",
      "| samples     | 1.41e+04 |\n",
      "| step        | 440      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.308   |\n",
      "| grad_norm   | 5.73     |\n",
      "| loss        | 0.15     |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0043   |\n",
      "| recon_loss  | 0.476    |\n",
      "| samples     | 1.44e+04 |\n",
      "| step        | 450      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.314   |\n",
      "| grad_norm   | 9.11     |\n",
      "| loss        | 0.178    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00423  |\n",
      "| recon_loss  | 0.481    |\n",
      "| samples     | 1.48e+04 |\n",
      "| step        | 460      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.321   |\n",
      "| grad_norm   | 7.41     |\n",
      "| loss        | 0.196    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00423  |\n",
      "| recon_loss  | 0.493    |\n",
      "| samples     | 1.51e+04 |\n",
      "| step        | 470      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.328   |\n",
      "| grad_norm   | 6.55     |\n",
      "| loss        | 0.124    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00397  |\n",
      "| recon_loss  | 0.457    |\n",
      "| samples     | 1.54e+04 |\n",
      "| step        | 480      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.334   |\n",
      "| grad_norm   | 7.63     |\n",
      "| loss        | 0.115    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00402  |\n",
      "| recon_loss  | 0.453    |\n",
      "| samples     | 1.57e+04 |\n",
      "| step        | 490      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.341   |\n",
      "| grad_norm   | 6.6      |\n",
      "| loss        | 0.104    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0037   |\n",
      "| recon_loss  | 0.443    |\n",
      "| samples     | 1.6e+04  |\n",
      "| step        | 500      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.347   |\n",
      "| grad_norm   | 8.07     |\n",
      "| loss        | 0.118    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00387  |\n",
      "| recon_loss  | 0.474    |\n",
      "| samples     | 1.64e+04 |\n",
      "| step        | 510      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.353   |\n",
      "| grad_norm   | 8.61     |\n",
      "| loss        | 0.104    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00364  |\n",
      "| recon_loss  | 0.435    |\n",
      "| samples     | 1.67e+04 |\n",
      "| step        | 520      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.36    |\n",
      "| grad_norm   | 8.07     |\n",
      "| loss        | 0.0721   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00345  |\n",
      "| recon_loss  | 0.432    |\n",
      "| samples     | 1.7e+04  |\n",
      "| step        | 530      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.367   |\n",
      "| grad_norm   | 7.11     |\n",
      "| loss        | 0.0781   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00347  |\n",
      "| recon_loss  | 0.444    |\n",
      "| samples     | 1.73e+04 |\n",
      "| step        | 540      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.373   |\n",
      "| grad_norm   | 8.76     |\n",
      "| loss        | 0.0721   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00331  |\n",
      "| recon_loss  | 0.441    |\n",
      "| samples     | 1.76e+04 |\n",
      "| step        | 550      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.38    |\n",
      "| grad_norm   | 7.85     |\n",
      "| loss        | 0.0634   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00322  |\n",
      "| recon_loss  | 0.434    |\n",
      "| samples     | 1.8e+04  |\n",
      "| step        | 560      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.387   |\n",
      "| grad_norm   | 8.15     |\n",
      "| loss        | 0.068    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00317  |\n",
      "| recon_loss  | 0.437    |\n",
      "| samples     | 1.83e+04 |\n",
      "| step        | 570      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.393   |\n",
      "| grad_norm   | 7.75     |\n",
      "| loss        | 0.0342   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00299  |\n",
      "| recon_loss  | 0.43     |\n",
      "| samples     | 1.86e+04 |\n",
      "| step        | 580      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 2        |\n",
      "| gan_loss    | -0.399   |\n",
      "| grad_norm   | 5.69     |\n",
      "| loss        | 0.0127   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00298  |\n",
      "| recon_loss  | 0.425    |\n",
      "| samples     | 1.89e+04 |\n",
      "| step        | 590      |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.406   |\n",
      "| grad_norm   | 5.29     |\n",
      "| loss        | 0.0123   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00282  |\n",
      "| recon_loss  | 0.418    |\n",
      "| samples     | 1.92e+04 |\n",
      "| step        | 600      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.413   |\n",
      "| grad_norm   | 6.62     |\n",
      "| loss        | -0.015   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00277  |\n",
      "| recon_loss  | 0.406    |\n",
      "| samples     | 1.96e+04 |\n",
      "| step        | 610      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.42    |\n",
      "| grad_norm   | 7.61     |\n",
      "| loss        | 0.00554  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00282  |\n",
      "| recon_loss  | 0.418    |\n",
      "| samples     | 1.99e+04 |\n",
      "| step        | 620      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.426   |\n",
      "| grad_norm   | 7.64     |\n",
      "| loss        | 0.00805  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00283  |\n",
      "| recon_loss  | 0.44     |\n",
      "| samples     | 2.02e+04 |\n",
      "| step        | 630      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.433   |\n",
      "| grad_norm   | 4.71     |\n",
      "| loss        | -0.0246  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00278  |\n",
      "| recon_loss  | 0.422    |\n",
      "| samples     | 2.05e+04 |\n",
      "| step        | 640      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.439   |\n",
      "| grad_norm   | 4.68     |\n",
      "| loss        | -0.0429  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00258  |\n",
      "| recon_loss  | 0.406    |\n",
      "| samples     | 2.08e+04 |\n",
      "| step        | 650      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.446   |\n",
      "| grad_norm   | 6.69     |\n",
      "| loss        | -0.0508  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00252  |\n",
      "| recon_loss  | 0.418    |\n",
      "| samples     | 2.12e+04 |\n",
      "| step        | 660      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.452   |\n",
      "| grad_norm   | 4.67     |\n",
      "| loss        | -0.0408  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00248  |\n",
      "| recon_loss  | 0.403    |\n",
      "| samples     | 2.15e+04 |\n",
      "| step        | 670      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.459   |\n",
      "| grad_norm   | 6.75     |\n",
      "| loss        | -0.0679  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00241  |\n",
      "| recon_loss  | 0.405    |\n",
      "| samples     | 2.18e+04 |\n",
      "| step        | 680      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.466   |\n",
      "| grad_norm   | 5.69     |\n",
      "| loss        | -0.0877  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0025   |\n",
      "| recon_loss  | 0.389    |\n",
      "| samples     | 2.21e+04 |\n",
      "| step        | 690      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.472   |\n",
      "| grad_norm   | 5.95     |\n",
      "| loss        | -0.0691  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00238  |\n",
      "| recon_loss  | 0.413    |\n",
      "| samples     | 2.24e+04 |\n",
      "| step        | 700      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.479   |\n",
      "| grad_norm   | 6.01     |\n",
      "| loss        | -0.059   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0023   |\n",
      "| recon_loss  | 0.419    |\n",
      "| samples     | 2.28e+04 |\n",
      "| step        | 710      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.485   |\n",
      "| grad_norm   | 7.09     |\n",
      "| loss        | -0.0887  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00222  |\n",
      "| recon_loss  | 0.411    |\n",
      "| samples     | 2.31e+04 |\n",
      "| step        | 720      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.492   |\n",
      "| grad_norm   | 8.56     |\n",
      "| loss        | -0.092   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00204  |\n",
      "| recon_loss  | 0.41     |\n",
      "| samples     | 2.34e+04 |\n",
      "| step        | 730      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.499   |\n",
      "| grad_norm   | 6.3      |\n",
      "| loss        | -0.105   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00217  |\n",
      "| recon_loss  | 0.412    |\n",
      "| samples     | 2.37e+04 |\n",
      "| step        | 740      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.505   |\n",
      "| grad_norm   | 8.37     |\n",
      "| loss        | -0.0815  |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0021   |\n",
      "| recon_loss  | 0.415    |\n",
      "| samples     | 2.4e+04  |\n",
      "| step        | 750      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.51    |\n",
      "| grad_norm   | 6.76     |\n",
      "| loss        | -0.123   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00208  |\n",
      "| recon_loss  | 0.394    |\n",
      "| samples     | 2.44e+04 |\n",
      "| step        | 760      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.518   |\n",
      "| grad_norm   | 4.98     |\n",
      "| loss        | -0.126   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00199  |\n",
      "| recon_loss  | 0.402    |\n",
      "| samples     | 2.47e+04 |\n",
      "| step        | 770      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.524   |\n",
      "| grad_norm   | 5.81     |\n",
      "| loss        | -0.122   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.002    |\n",
      "| recon_loss  | 0.416    |\n",
      "| samples     | 2.5e+04  |\n",
      "| step        | 780      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.531   |\n",
      "| grad_norm   | 6.17     |\n",
      "| loss        | -0.126   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00201  |\n",
      "| recon_loss  | 0.396    |\n",
      "| samples     | 2.53e+04 |\n",
      "| step        | 790      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.538   |\n",
      "| grad_norm   | 5.39     |\n",
      "| loss        | -0.168   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00183  |\n",
      "| recon_loss  | 0.382    |\n",
      "| samples     | 2.56e+04 |\n",
      "| step        | 800      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.544   |\n",
      "| grad_norm   | 6.79     |\n",
      "| loss        | -0.164   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00179  |\n",
      "| recon_loss  | 0.382    |\n",
      "| samples     | 2.6e+04  |\n",
      "| step        | 810      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.551   |\n",
      "| grad_norm   | 5.67     |\n",
      "| loss        | -0.18    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0018   |\n",
      "| recon_loss  | 0.39     |\n",
      "| samples     | 2.63e+04 |\n",
      "| step        | 820      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.557   |\n",
      "| grad_norm   | 7.12     |\n",
      "| loss        | -0.158   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00179  |\n",
      "| recon_loss  | 0.405    |\n",
      "| samples     | 2.66e+04 |\n",
      "| step        | 830      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.564   |\n",
      "| grad_norm   | 6.98     |\n",
      "| loss        | -0.196   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00177  |\n",
      "| recon_loss  | 0.373    |\n",
      "| samples     | 2.69e+04 |\n",
      "| step        | 840      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.571   |\n",
      "| grad_norm   | 5.71     |\n",
      "| loss        | -0.191   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00173  |\n",
      "| recon_loss  | 0.371    |\n",
      "| samples     | 2.72e+04 |\n",
      "| step        | 850      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.577   |\n",
      "| grad_norm   | 6.13     |\n",
      "| loss        | -0.186   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0017   |\n",
      "| recon_loss  | 0.39     |\n",
      "| samples     | 2.76e+04 |\n",
      "| step        | 860      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.584   |\n",
      "| grad_norm   | 8.5      |\n",
      "| loss        | -0.208   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00155  |\n",
      "| recon_loss  | 0.374    |\n",
      "| samples     | 2.79e+04 |\n",
      "| step        | 870      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.59    |\n",
      "| grad_norm   | 7.91     |\n",
      "| loss        | -0.183   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00176  |\n",
      "| recon_loss  | 0.408    |\n",
      "| samples     | 2.82e+04 |\n",
      "| step        | 880      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 3        |\n",
      "| gan_loss    | -0.597   |\n",
      "| grad_norm   | 7.02     |\n",
      "| loss        | -0.195   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00161  |\n",
      "| recon_loss  | 0.384    |\n",
      "| samples     | 2.85e+04 |\n",
      "| step        | 890      |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.604   |\n",
      "| grad_norm   | 8.32     |\n",
      "| loss        | -0.239   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00147  |\n",
      "| recon_loss  | 0.373    |\n",
      "| samples     | 2.88e+04 |\n",
      "| step        | 900      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.61    |\n",
      "| grad_norm   | 9.14     |\n",
      "| loss        | -0.227   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00155  |\n",
      "| recon_loss  | 0.39     |\n",
      "| samples     | 2.92e+04 |\n",
      "| step        | 910      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.616   |\n",
      "| grad_norm   | 8.26     |\n",
      "| loss        | -0.221   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00144  |\n",
      "| recon_loss  | 0.381    |\n",
      "| samples     | 2.95e+04 |\n",
      "| step        | 920      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.623   |\n",
      "| grad_norm   | 7.06     |\n",
      "| loss        | -0.26    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00143  |\n",
      "| recon_loss  | 0.375    |\n",
      "| samples     | 2.98e+04 |\n",
      "| step        | 930      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.629   |\n",
      "| grad_norm   | 7.74     |\n",
      "| loss        | -0.261   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00146  |\n",
      "| recon_loss  | 0.387    |\n",
      "| samples     | 3.01e+04 |\n",
      "| step        | 940      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.636   |\n",
      "| grad_norm   | 7.15     |\n",
      "| loss        | -0.253   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00136  |\n",
      "| recon_loss  | 0.385    |\n",
      "| samples     | 3.04e+04 |\n",
      "| step        | 950      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.643   |\n",
      "| grad_norm   | 6.02     |\n",
      "| loss        | -0.272   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0014   |\n",
      "| recon_loss  | 0.378    |\n",
      "| samples     | 3.08e+04 |\n",
      "| step        | 960      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.65    |\n",
      "| grad_norm   | 6.81     |\n",
      "| loss        | -0.296   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0012   |\n",
      "| recon_loss  | 0.363    |\n",
      "| samples     | 3.11e+04 |\n",
      "| step        | 970      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.656   |\n",
      "| grad_norm   | 7.2      |\n",
      "| loss        | -0.274   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00137  |\n",
      "| recon_loss  | 0.38     |\n",
      "| samples     | 3.14e+04 |\n",
      "| step        | 980      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.663   |\n",
      "| grad_norm   | 6.99     |\n",
      "| loss        | -0.262   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00136  |\n",
      "| recon_loss  | 0.388    |\n",
      "| samples     | 3.17e+04 |\n",
      "| step        | 990      |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.67    |\n",
      "| grad_norm   | 5.57     |\n",
      "| loss        | -0.298   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00117  |\n",
      "| recon_loss  | 0.374    |\n",
      "| samples     | 3.2e+04  |\n",
      "| step        | 1e+03    |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.676   |\n",
      "| grad_norm   | 5.44     |\n",
      "| loss        | -0.321   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00126  |\n",
      "| recon_loss  | 0.374    |\n",
      "| samples     | 3.24e+04 |\n",
      "| step        | 1.01e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.683   |\n",
      "| grad_norm   | 6.43     |\n",
      "| loss        | -0.318   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00129  |\n",
      "| recon_loss  | 0.384    |\n",
      "| samples     | 3.27e+04 |\n",
      "| step        | 1.02e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.689   |\n",
      "| grad_norm   | 8.24     |\n",
      "| loss        | -0.296   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00125  |\n",
      "| recon_loss  | 0.392    |\n",
      "| samples     | 3.3e+04  |\n",
      "| step        | 1.03e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.696   |\n",
      "| grad_norm   | 7.46     |\n",
      "| loss        | -0.314   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00122  |\n",
      "| recon_loss  | 0.38     |\n",
      "| samples     | 3.33e+04 |\n",
      "| step        | 1.04e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.702   |\n",
      "| grad_norm   | 6.33     |\n",
      "| loss        | -0.333   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00112  |\n",
      "| recon_loss  | 0.376    |\n",
      "| samples     | 3.36e+04 |\n",
      "| step        | 1.05e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.709   |\n",
      "| grad_norm   | 5.87     |\n",
      "| loss        | -0.347   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00111  |\n",
      "| recon_loss  | 0.367    |\n",
      "| samples     | 3.4e+04  |\n",
      "| step        | 1.06e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.716   |\n",
      "| grad_norm   | 5.69     |\n",
      "| loss        | -0.358   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00111  |\n",
      "| recon_loss  | 0.358    |\n",
      "| samples     | 3.43e+04 |\n",
      "| step        | 1.07e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.722   |\n",
      "| grad_norm   | 5.56     |\n",
      "| loss        | -0.374   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00102  |\n",
      "| recon_loss  | 0.342    |\n",
      "| samples     | 3.46e+04 |\n",
      "| step        | 1.08e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.729   |\n",
      "| grad_norm   | 5.84     |\n",
      "| loss        | -0.344   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00109  |\n",
      "| recon_loss  | 0.392    |\n",
      "| samples     | 3.49e+04 |\n",
      "| step        | 1.09e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.735   |\n",
      "| grad_norm   | 6.7      |\n",
      "| loss        | -0.379   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00107  |\n",
      "| recon_loss  | 0.374    |\n",
      "| samples     | 3.52e+04 |\n",
      "| step        | 1.1e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.742   |\n",
      "| grad_norm   | 7.05     |\n",
      "| loss        | -0.405   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.00107  |\n",
      "| recon_loss  | 0.355    |\n",
      "| samples     | 3.56e+04 |\n",
      "| step        | 1.11e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.748   |\n",
      "| grad_norm   | 6.04     |\n",
      "| loss        | -0.393   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000995 |\n",
      "| recon_loss  | 0.356    |\n",
      "| samples     | 3.59e+04 |\n",
      "| step        | 1.12e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.755   |\n",
      "| grad_norm   | 6.42     |\n",
      "| loss        | -0.41    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000967 |\n",
      "| recon_loss  | 0.348    |\n",
      "| samples     | 3.62e+04 |\n",
      "| step        | 1.13e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.761   |\n",
      "| grad_norm   | 5.6      |\n",
      "| loss        | -0.44    |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000912 |\n",
      "| recon_loss  | 0.335    |\n",
      "| samples     | 3.65e+04 |\n",
      "| step        | 1.14e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.768   |\n",
      "| grad_norm   | 5.91     |\n",
      "| loss        | -0.433   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.0009   |\n",
      "| recon_loss  | 0.338    |\n",
      "| samples     | 3.68e+04 |\n",
      "| step        | 1.15e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.774   |\n",
      "| grad_norm   | 6.01     |\n",
      "| loss        | -0.401   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000944 |\n",
      "| recon_loss  | 0.37     |\n",
      "| samples     | 3.72e+04 |\n",
      "| step        | 1.16e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.781   |\n",
      "| grad_norm   | 5.87     |\n",
      "| loss        | -0.452   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000897 |\n",
      "| recon_loss  | 0.339    |\n",
      "| samples     | 3.75e+04 |\n",
      "| step        | 1.17e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.788   |\n",
      "| grad_norm   | 7.06     |\n",
      "| loss        | -0.423   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000969 |\n",
      "| recon_loss  | 0.357    |\n",
      "| samples     | 3.78e+04 |\n",
      "| step        | 1.18e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 4        |\n",
      "| gan_loss    | -0.794   |\n",
      "| grad_norm   | 7.07     |\n",
      "| loss        | -0.431   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000928 |\n",
      "| recon_loss  | 0.367    |\n",
      "| samples     | 3.81e+04 |\n",
      "| step        | 1.19e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.801   |\n",
      "| grad_norm   | 6.44     |\n",
      "| loss        | -0.447   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000851 |\n",
      "| recon_loss  | 0.362    |\n",
      "| samples     | 3.84e+04 |\n",
      "| step        | 1.2e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.807   |\n",
      "| grad_norm   | 6.17     |\n",
      "| loss        | -0.469   |\n",
      "| param_norm  | 154      |\n",
      "| percep_loss | 0.000901 |\n",
      "| recon_loss  | 0.355    |\n",
      "| samples     | 3.88e+04 |\n",
      "| step        | 1.21e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.814   |\n",
      "| grad_norm   | 4.66     |\n",
      "| loss        | -0.482   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00085  |\n",
      "| recon_loss  | 0.344    |\n",
      "| samples     | 3.91e+04 |\n",
      "| step        | 1.22e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.82    |\n",
      "| grad_norm   | 5.62     |\n",
      "| loss        | -0.474   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000875 |\n",
      "| recon_loss  | 0.354    |\n",
      "| samples     | 3.94e+04 |\n",
      "| step        | 1.23e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.826   |\n",
      "| grad_norm   | 5.73     |\n",
      "| loss        | -0.501   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000748 |\n",
      "| recon_loss  | 0.33     |\n",
      "| samples     | 3.97e+04 |\n",
      "| step        | 1.24e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.833   |\n",
      "| grad_norm   | 7.04     |\n",
      "| loss        | -0.496   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000826 |\n",
      "| recon_loss  | 0.355    |\n",
      "| samples     | 4e+04    |\n",
      "| step        | 1.25e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.84    |\n",
      "| grad_norm   | 6.53     |\n",
      "| loss        | -0.477   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000946 |\n",
      "| recon_loss  | 0.376    |\n",
      "| samples     | 4.04e+04 |\n",
      "| step        | 1.26e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.846   |\n",
      "| grad_norm   | 6.92     |\n",
      "| loss        | -0.508   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000773 |\n",
      "| recon_loss  | 0.34     |\n",
      "| samples     | 4.07e+04 |\n",
      "| step        | 1.27e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.853   |\n",
      "| grad_norm   | 5.63     |\n",
      "| loss        | -0.494   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000817 |\n",
      "| recon_loss  | 0.359    |\n",
      "| samples     | 4.1e+04  |\n",
      "| step        | 1.28e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.86    |\n",
      "| grad_norm   | 5.38     |\n",
      "| loss        | -0.523   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000749 |\n",
      "| recon_loss  | 0.34     |\n",
      "| samples     | 4.13e+04 |\n",
      "| step        | 1.29e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.866   |\n",
      "| grad_norm   | 6.04     |\n",
      "| loss        | -0.527   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000707 |\n",
      "| recon_loss  | 0.348    |\n",
      "| samples     | 4.16e+04 |\n",
      "| step        | 1.3e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.872   |\n",
      "| grad_norm   | 6.78     |\n",
      "| loss        | -0.525   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000738 |\n",
      "| recon_loss  | 0.354    |\n",
      "| samples     | 4.2e+04  |\n",
      "| step        | 1.31e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.878   |\n",
      "| grad_norm   | 5.89     |\n",
      "| loss        | -0.552   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000702 |\n",
      "| recon_loss  | 0.333    |\n",
      "| samples     | 4.23e+04 |\n",
      "| step        | 1.32e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.885   |\n",
      "| grad_norm   | 6.76     |\n",
      "| loss        | -0.526   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000742 |\n",
      "| recon_loss  | 0.356    |\n",
      "| samples     | 4.26e+04 |\n",
      "| step        | 1.33e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.892   |\n",
      "| grad_norm   | 6.92     |\n",
      "| loss        | -0.546   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000713 |\n",
      "| recon_loss  | 0.346    |\n",
      "| samples     | 4.29e+04 |\n",
      "| step        | 1.34e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.898   |\n",
      "| grad_norm   | 6.31     |\n",
      "| loss        | -0.562   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000709 |\n",
      "| recon_loss  | 0.335    |\n",
      "| samples     | 4.32e+04 |\n",
      "| step        | 1.35e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.904   |\n",
      "| grad_norm   | 6.34     |\n",
      "| loss        | -0.577   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000686 |\n",
      "| recon_loss  | 0.337    |\n",
      "| samples     | 4.36e+04 |\n",
      "| step        | 1.36e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.911   |\n",
      "| grad_norm   | 5.82     |\n",
      "| loss        | -0.585   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000686 |\n",
      "| recon_loss  | 0.331    |\n",
      "| samples     | 4.39e+04 |\n",
      "| step        | 1.37e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.917   |\n",
      "| grad_norm   | 4.47     |\n",
      "| loss        | -0.569   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000691 |\n",
      "| recon_loss  | 0.353    |\n",
      "| samples     | 4.42e+04 |\n",
      "| step        | 1.38e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.924   |\n",
      "| grad_norm   | 6.08     |\n",
      "| loss        | -0.595   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000706 |\n",
      "| recon_loss  | 0.36     |\n",
      "| samples     | 4.45e+04 |\n",
      "| step        | 1.39e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.93    |\n",
      "| grad_norm   | 8.27     |\n",
      "| loss        | -0.547   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000666 |\n",
      "| recon_loss  | 0.381    |\n",
      "| samples     | 4.48e+04 |\n",
      "| step        | 1.4e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.937   |\n",
      "| grad_norm   | 5.89     |\n",
      "| loss        | -0.601   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000594 |\n",
      "| recon_loss  | 0.335    |\n",
      "| samples     | 4.52e+04 |\n",
      "| step        | 1.41e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.943   |\n",
      "| grad_norm   | 6.93     |\n",
      "| loss        | -0.579   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000626 |\n",
      "| recon_loss  | 0.361    |\n",
      "| samples     | 4.55e+04 |\n",
      "| step        | 1.42e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.949   |\n",
      "| grad_norm   | 6.05     |\n",
      "| loss        | -0.616   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000641 |\n",
      "| recon_loss  | 0.348    |\n",
      "| samples     | 4.58e+04 |\n",
      "| step        | 1.43e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.956   |\n",
      "| grad_norm   | 6.37     |\n",
      "| loss        | -0.609   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000624 |\n",
      "| recon_loss  | 0.341    |\n",
      "| samples     | 4.61e+04 |\n",
      "| step        | 1.44e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.963   |\n",
      "| grad_norm   | 4.85     |\n",
      "| loss        | -0.637   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000682 |\n",
      "| recon_loss  | 0.331    |\n",
      "| samples     | 4.64e+04 |\n",
      "| step        | 1.45e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.969   |\n",
      "| grad_norm   | 6.03     |\n",
      "| loss        | -0.627   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000621 |\n",
      "| recon_loss  | 0.346    |\n",
      "| samples     | 4.68e+04 |\n",
      "| step        | 1.46e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.975   |\n",
      "| grad_norm   | 8.03     |\n",
      "| loss        | -0.624   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000624 |\n",
      "| recon_loss  | 0.348    |\n",
      "| samples     | 4.71e+04 |\n",
      "| step        | 1.47e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.982   |\n",
      "| grad_norm   | 6.78     |\n",
      "| loss        | -0.65    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000554 |\n",
      "| recon_loss  | 0.343    |\n",
      "| samples     | 4.74e+04 |\n",
      "| step        | 1.48e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 5        |\n",
      "| gan_loss    | -0.988   |\n",
      "| grad_norm   | 6.5      |\n",
      "| loss        | -0.677   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000546 |\n",
      "| recon_loss  | 0.322    |\n",
      "| samples     | 4.77e+04 |\n",
      "| step        | 1.49e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -0.995   |\n",
      "| grad_norm   | 6.52     |\n",
      "| loss        | -0.651   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000526 |\n",
      "| recon_loss  | 0.343    |\n",
      "| samples     | 4.8e+04  |\n",
      "| step        | 1.5e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1       |\n",
      "| grad_norm   | 4.59     |\n",
      "| loss        | -0.694   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000564 |\n",
      "| recon_loss  | 0.335    |\n",
      "| samples     | 4.84e+04 |\n",
      "| step        | 1.51e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.01    |\n",
      "| grad_norm   | 5.86     |\n",
      "| loss        | -0.715   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000494 |\n",
      "| recon_loss  | 0.313    |\n",
      "| samples     | 4.87e+04 |\n",
      "| step        | 1.52e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.01    |\n",
      "| grad_norm   | 5.1      |\n",
      "| loss        | -0.696   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00051  |\n",
      "| recon_loss  | 0.326    |\n",
      "| samples     | 4.9e+04  |\n",
      "| step        | 1.53e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.02    |\n",
      "| grad_norm   | 6.08     |\n",
      "| loss        | -0.697   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000558 |\n",
      "| recon_loss  | 0.324    |\n",
      "| samples     | 4.93e+04 |\n",
      "| step        | 1.54e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.03    |\n",
      "| grad_norm   | 6.62     |\n",
      "| loss        | -0.708   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000567 |\n",
      "| recon_loss  | 0.333    |\n",
      "| samples     | 4.96e+04 |\n",
      "| step        | 1.55e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.03    |\n",
      "| grad_norm   | 6.77     |\n",
      "| loss        | -0.714   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000548 |\n",
      "| recon_loss  | 0.314    |\n",
      "| samples     | 5e+04    |\n",
      "| step        | 1.56e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.04    |\n",
      "| grad_norm   | 6.39     |\n",
      "| loss        | -0.735   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000537 |\n",
      "| recon_loss  | 0.319    |\n",
      "| samples     | 5.03e+04 |\n",
      "| step        | 1.57e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.05    |\n",
      "| grad_norm   | 7.31     |\n",
      "| loss        | -0.731   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000622 |\n",
      "| recon_loss  | 0.323    |\n",
      "| samples     | 5.06e+04 |\n",
      "| step        | 1.58e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.05    |\n",
      "| grad_norm   | 6.7      |\n",
      "| loss        | -0.713   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000498 |\n",
      "| recon_loss  | 0.344    |\n",
      "| samples     | 5.09e+04 |\n",
      "| step        | 1.59e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.06    |\n",
      "| grad_norm   | 6.31     |\n",
      "| loss        | -0.723   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000514 |\n",
      "| recon_loss  | 0.324    |\n",
      "| samples     | 5.12e+04 |\n",
      "| step        | 1.6e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.07    |\n",
      "| grad_norm   | 7.87     |\n",
      "| loss        | -0.737   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000511 |\n",
      "| recon_loss  | 0.342    |\n",
      "| samples     | 5.16e+04 |\n",
      "| step        | 1.61e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.07    |\n",
      "| grad_norm   | 8.83     |\n",
      "| loss        | -0.732   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000505 |\n",
      "| recon_loss  | 0.337    |\n",
      "| samples     | 5.19e+04 |\n",
      "| step        | 1.62e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.08    |\n",
      "| grad_norm   | 6.91     |\n",
      "| loss        | -0.748   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000475 |\n",
      "| recon_loss  | 0.319    |\n",
      "| samples     | 5.22e+04 |\n",
      "| step        | 1.63e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.08    |\n",
      "| grad_norm   | 7.55     |\n",
      "| loss        | -0.753   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000448 |\n",
      "| recon_loss  | 0.332    |\n",
      "| samples     | 5.25e+04 |\n",
      "| step        | 1.64e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.09    |\n",
      "| grad_norm   | 5.96     |\n",
      "| loss        | -0.797   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000487 |\n",
      "| recon_loss  | 0.315    |\n",
      "| samples     | 5.28e+04 |\n",
      "| step        | 1.65e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.1     |\n",
      "| grad_norm   | 7.18     |\n",
      "| loss        | -0.766   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000511 |\n",
      "| recon_loss  | 0.335    |\n",
      "| samples     | 5.32e+04 |\n",
      "| step        | 1.66e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.1     |\n",
      "| grad_norm   | 5.75     |\n",
      "| loss        | -0.79    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00048  |\n",
      "| recon_loss  | 0.326    |\n",
      "| samples     | 5.35e+04 |\n",
      "| step        | 1.67e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.11    |\n",
      "| grad_norm   | 6.37     |\n",
      "| loss        | -0.79    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000424 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 5.38e+04 |\n",
      "| step        | 1.68e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.12    |\n",
      "| grad_norm   | 5.43     |\n",
      "| loss        | -0.782   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000456 |\n",
      "| recon_loss  | 0.329    |\n",
      "| samples     | 5.41e+04 |\n",
      "| step        | 1.69e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.12    |\n",
      "| grad_norm   | 5.22     |\n",
      "| loss        | -0.806   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000416 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 5.44e+04 |\n",
      "| step        | 1.7e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.13    |\n",
      "| grad_norm   | 5.4      |\n",
      "| loss        | -0.792   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000516 |\n",
      "| recon_loss  | 0.332    |\n",
      "| samples     | 5.48e+04 |\n",
      "| step        | 1.71e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.13    |\n",
      "| grad_norm   | 5.57     |\n",
      "| loss        | -0.822   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000408 |\n",
      "| recon_loss  | 0.315    |\n",
      "| samples     | 5.51e+04 |\n",
      "| step        | 1.72e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.14    |\n",
      "| grad_norm   | 4.89     |\n",
      "| loss        | -0.832   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000371 |\n",
      "| recon_loss  | 0.315    |\n",
      "| samples     | 5.54e+04 |\n",
      "| step        | 1.73e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.15    |\n",
      "| grad_norm   | 6.4      |\n",
      "| loss        | -0.841   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000455 |\n",
      "| recon_loss  | 0.321    |\n",
      "| samples     | 5.57e+04 |\n",
      "| step        | 1.74e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.15    |\n",
      "| grad_norm   | 6.48     |\n",
      "| loss        | -0.812   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000478 |\n",
      "| recon_loss  | 0.347    |\n",
      "| samples     | 5.6e+04  |\n",
      "| step        | 1.75e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.16    |\n",
      "| grad_norm   | 7.98     |\n",
      "| loss        | -0.819   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000398 |\n",
      "| recon_loss  | 0.33     |\n",
      "| samples     | 5.64e+04 |\n",
      "| step        | 1.76e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.17    |\n",
      "| grad_norm   | 6.05     |\n",
      "| loss        | -0.832   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000398 |\n",
      "| recon_loss  | 0.327    |\n",
      "| samples     | 5.67e+04 |\n",
      "| step        | 1.77e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.17    |\n",
      "| grad_norm   | 6.03     |\n",
      "| loss        | -0.839   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000398 |\n",
      "| recon_loss  | 0.328    |\n",
      "| samples     | 5.7e+04  |\n",
      "| step        | 1.78e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 6        |\n",
      "| gan_loss    | -1.18    |\n",
      "| grad_norm   | 4.3      |\n",
      "| loss        | -0.865   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000399 |\n",
      "| recon_loss  | 0.322    |\n",
      "| samples     | 5.73e+04 |\n",
      "| step        | 1.79e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.18    |\n",
      "| grad_norm   | 6.72     |\n",
      "| loss        | -0.879   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00042  |\n",
      "| recon_loss  | 0.329    |\n",
      "| samples     | 5.76e+04 |\n",
      "| step        | 1.8e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.19    |\n",
      "| grad_norm   | 5.3      |\n",
      "| loss        | -0.893   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000391 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 5.8e+04  |\n",
      "| step        | 1.81e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.2     |\n",
      "| grad_norm   | 4.45     |\n",
      "| loss        | -0.915   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000434 |\n",
      "| recon_loss  | 0.307    |\n",
      "| samples     | 5.83e+04 |\n",
      "| step        | 1.82e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.2     |\n",
      "| grad_norm   | 6.03     |\n",
      "| loss        | -0.892   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000419 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 5.86e+04 |\n",
      "| step        | 1.83e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.21    |\n",
      "| grad_norm   | 8.85     |\n",
      "| loss        | -0.896   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000381 |\n",
      "| recon_loss  | 0.314    |\n",
      "| samples     | 5.89e+04 |\n",
      "| step        | 1.84e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.22    |\n",
      "| grad_norm   | 7.15     |\n",
      "| loss        | -0.908   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000401 |\n",
      "| recon_loss  | 0.31     |\n",
      "| samples     | 5.92e+04 |\n",
      "| step        | 1.85e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.22    |\n",
      "| grad_norm   | 7.2      |\n",
      "| loss        | -0.926   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000374 |\n",
      "| recon_loss  | 0.297    |\n",
      "| samples     | 5.96e+04 |\n",
      "| step        | 1.86e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.23    |\n",
      "| grad_norm   | 6.36     |\n",
      "| loss        | -0.915   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000373 |\n",
      "| recon_loss  | 0.316    |\n",
      "| samples     | 5.99e+04 |\n",
      "| step        | 1.87e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.23    |\n",
      "| grad_norm   | 5.55     |\n",
      "| loss        | -0.933   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000357 |\n",
      "| recon_loss  | 0.31     |\n",
      "| samples     | 6.02e+04 |\n",
      "| step        | 1.88e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.24    |\n",
      "| grad_norm   | 6.73     |\n",
      "| loss        | -0.938   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00035  |\n",
      "| recon_loss  | 0.305    |\n",
      "| samples     | 6.05e+04 |\n",
      "| step        | 1.89e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.25    |\n",
      "| grad_norm   | 5.75     |\n",
      "| loss        | -0.952   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000388 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 6.08e+04 |\n",
      "| step        | 1.9e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.25    |\n",
      "| grad_norm   | 6.27     |\n",
      "| loss        | -0.922   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000369 |\n",
      "| recon_loss  | 0.334    |\n",
      "| samples     | 6.12e+04 |\n",
      "| step        | 1.91e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.26    |\n",
      "| grad_norm   | 7.48     |\n",
      "| loss        | -0.933   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000347 |\n",
      "| recon_loss  | 0.328    |\n",
      "| samples     | 6.15e+04 |\n",
      "| step        | 1.92e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.26    |\n",
      "| grad_norm   | 5.52     |\n",
      "| loss        | -0.955   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000412 |\n",
      "| recon_loss  | 0.316    |\n",
      "| samples     | 6.18e+04 |\n",
      "| step        | 1.93e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.27    |\n",
      "| grad_norm   | 5.41     |\n",
      "| loss        | -0.978   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00031  |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 6.21e+04 |\n",
      "| step        | 1.94e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.28    |\n",
      "| grad_norm   | 7.26     |\n",
      "| loss        | -0.978   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00035  |\n",
      "| recon_loss  | 0.312    |\n",
      "| samples     | 6.24e+04 |\n",
      "| step        | 1.95e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.28    |\n",
      "| grad_norm   | 6.01     |\n",
      "| loss        | -0.978   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000349 |\n",
      "| recon_loss  | 0.322    |\n",
      "| samples     | 6.28e+04 |\n",
      "| step        | 1.96e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.29    |\n",
      "| grad_norm   | 6.4      |\n",
      "| loss        | -0.994   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00031  |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 6.31e+04 |\n",
      "| step        | 1.97e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.29    |\n",
      "| grad_norm   | 7.53     |\n",
      "| loss        | -0.976   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000357 |\n",
      "| recon_loss  | 0.321    |\n",
      "| samples     | 6.34e+04 |\n",
      "| step        | 1.98e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.3     |\n",
      "| grad_norm   | 6.24     |\n",
      "| loss        | -0.965   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000313 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 6.37e+04 |\n",
      "| step        | 1.99e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.31    |\n",
      "| grad_norm   | 6.37     |\n",
      "| loss        | -0.976   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000322 |\n",
      "| recon_loss  | 0.331    |\n",
      "| samples     | 6.4e+04  |\n",
      "| step        | 2e+03    |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.31    |\n",
      "| grad_norm   | 6.4      |\n",
      "| loss        | -0.985   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000348 |\n",
      "| recon_loss  | 0.319    |\n",
      "| samples     | 6.44e+04 |\n",
      "| step        | 2.01e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.32    |\n",
      "| grad_norm   | 6.23     |\n",
      "| loss        | -0.999   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00039  |\n",
      "| recon_loss  | 0.325    |\n",
      "| samples     | 6.47e+04 |\n",
      "| step        | 2.02e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.32    |\n",
      "| grad_norm   | 6.1      |\n",
      "| loss        | -0.992   |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000328 |\n",
      "| recon_loss  | 0.327    |\n",
      "| samples     | 6.5e+04  |\n",
      "| step        | 2.03e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.33    |\n",
      "| grad_norm   | 6.52     |\n",
      "| loss        | -1.03    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000305 |\n",
      "| recon_loss  | 0.313    |\n",
      "| samples     | 6.53e+04 |\n",
      "| step        | 2.04e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.34    |\n",
      "| grad_norm   | 7.37     |\n",
      "| loss        | -1.02    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000303 |\n",
      "| recon_loss  | 0.315    |\n",
      "| samples     | 6.56e+04 |\n",
      "| step        | 2.05e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.34    |\n",
      "| grad_norm   | 7.37     |\n",
      "| loss        | -1.02    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000296 |\n",
      "| recon_loss  | 0.305    |\n",
      "| samples     | 6.6e+04  |\n",
      "| step        | 2.06e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.35    |\n",
      "| grad_norm   | 7.1      |\n",
      "| loss        | -1.05    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000318 |\n",
      "| recon_loss  | 0.309    |\n",
      "| samples     | 6.63e+04 |\n",
      "| step        | 2.07e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.35    |\n",
      "| grad_norm   | 6.79     |\n",
      "| loss        | -1.06    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000263 |\n",
      "| recon_loss  | 0.296    |\n",
      "| samples     | 6.66e+04 |\n",
      "| step        | 2.08e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 7        |\n",
      "| gan_loss    | -1.36    |\n",
      "| grad_norm   | 5.69     |\n",
      "| loss        | -1.05    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000301 |\n",
      "| recon_loss  | 0.315    |\n",
      "| samples     | 6.69e+04 |\n",
      "| step        | 2.09e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.37    |\n",
      "| grad_norm   | 5.78     |\n",
      "| loss        | -1.07    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000307 |\n",
      "| recon_loss  | 0.311    |\n",
      "| samples     | 6.72e+04 |\n",
      "| step        | 2.1e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.37    |\n",
      "| grad_norm   | 6.96     |\n",
      "| loss        | -1.06    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000299 |\n",
      "| recon_loss  | 0.305    |\n",
      "| samples     | 6.76e+04 |\n",
      "| step        | 2.11e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.38    |\n",
      "| grad_norm   | 6.98     |\n",
      "| loss        | -1.08    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000298 |\n",
      "| recon_loss  | 0.317    |\n",
      "| samples     | 6.79e+04 |\n",
      "| step        | 2.12e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.38    |\n",
      "| grad_norm   | 6.43     |\n",
      "| loss        | -1.09    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000326 |\n",
      "| recon_loss  | 0.321    |\n",
      "| samples     | 6.82e+04 |\n",
      "| step        | 2.13e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.39    |\n",
      "| grad_norm   | 6.31     |\n",
      "| loss        | -1.09    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000311 |\n",
      "| recon_loss  | 0.311    |\n",
      "| samples     | 6.85e+04 |\n",
      "| step        | 2.14e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.4     |\n",
      "| grad_norm   | 6.92     |\n",
      "| loss        | -1.11    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000259 |\n",
      "| recon_loss  | 0.307    |\n",
      "| samples     | 6.88e+04 |\n",
      "| step        | 2.15e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.4     |\n",
      "| grad_norm   | 7.85     |\n",
      "| loss        | -1.08    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000295 |\n",
      "| recon_loss  | 0.321    |\n",
      "| samples     | 6.92e+04 |\n",
      "| step        | 2.16e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.41    |\n",
      "| grad_norm   | 6.89     |\n",
      "| loss        | -1.1     |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000276 |\n",
      "| recon_loss  | 0.311    |\n",
      "| samples     | 6.95e+04 |\n",
      "| step        | 2.17e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.41    |\n",
      "| grad_norm   | 4.63     |\n",
      "| loss        | -1.12    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000273 |\n",
      "| recon_loss  | 0.304    |\n",
      "| samples     | 6.98e+04 |\n",
      "| step        | 2.18e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.42    |\n",
      "| grad_norm   | 5.41     |\n",
      "| loss        | -1.14    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000277 |\n",
      "| recon_loss  | 0.295    |\n",
      "| samples     | 7.01e+04 |\n",
      "| step        | 2.19e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.42    |\n",
      "| grad_norm   | 5.43     |\n",
      "| loss        | -1.12    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000292 |\n",
      "| recon_loss  | 0.314    |\n",
      "| samples     | 7.04e+04 |\n",
      "| step        | 2.2e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.43    |\n",
      "| grad_norm   | 5.76     |\n",
      "| loss        | -1.14    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000258 |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 7.08e+04 |\n",
      "| step        | 2.21e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.44    |\n",
      "| grad_norm   | 6.33     |\n",
      "| loss        | -1.13    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000274 |\n",
      "| recon_loss  | 0.318    |\n",
      "| samples     | 7.11e+04 |\n",
      "| step        | 2.22e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.44    |\n",
      "| grad_norm   | 5.07     |\n",
      "| loss        | -1.14    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00029  |\n",
      "| recon_loss  | 0.306    |\n",
      "| samples     | 7.14e+04 |\n",
      "| step        | 2.23e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.45    |\n",
      "| grad_norm   | 5.21     |\n",
      "| loss        | -1.17    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000271 |\n",
      "| recon_loss  | 0.296    |\n",
      "| samples     | 7.17e+04 |\n",
      "| step        | 2.24e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.45    |\n",
      "| grad_norm   | 5.74     |\n",
      "| loss        | -1.16    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000271 |\n",
      "| recon_loss  | 0.302    |\n",
      "| samples     | 7.2e+04  |\n",
      "| step        | 2.25e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.46    |\n",
      "| grad_norm   | 6.39     |\n",
      "| loss        | -1.15    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000277 |\n",
      "| recon_loss  | 0.307    |\n",
      "| samples     | 7.24e+04 |\n",
      "| step        | 2.26e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.46    |\n",
      "| grad_norm   | 6.55     |\n",
      "| loss        | -1.17    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000256 |\n",
      "| recon_loss  | 0.3      |\n",
      "| samples     | 7.27e+04 |\n",
      "| step        | 2.27e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.47    |\n",
      "| grad_norm   | 5.85     |\n",
      "| loss        | -1.17    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000283 |\n",
      "| recon_loss  | 0.312    |\n",
      "| samples     | 7.3e+04  |\n",
      "| step        | 2.28e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.48    |\n",
      "| grad_norm   | 5.84     |\n",
      "| loss        | -1.19    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000266 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 7.33e+04 |\n",
      "| step        | 2.29e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.48    |\n",
      "| grad_norm   | 4.03     |\n",
      "| loss        | -1.18    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000229 |\n",
      "| recon_loss  | 0.308    |\n",
      "| samples     | 7.36e+04 |\n",
      "| step        | 2.3e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.49    |\n",
      "| grad_norm   | 5.48     |\n",
      "| loss        | -1.21    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000228 |\n",
      "| recon_loss  | 0.295    |\n",
      "| samples     | 7.4e+04  |\n",
      "| step        | 2.31e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.49    |\n",
      "| grad_norm   | 4.94     |\n",
      "| loss        | -1.22    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00026  |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 7.43e+04 |\n",
      "| step        | 2.32e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.5     |\n",
      "| grad_norm   | 5.33     |\n",
      "| loss        | -1.21    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000248 |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 7.46e+04 |\n",
      "| step        | 2.33e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.5     |\n",
      "| grad_norm   | 5.61     |\n",
      "| loss        | -1.23    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000224 |\n",
      "| recon_loss  | 0.29     |\n",
      "| samples     | 7.49e+04 |\n",
      "| step        | 2.34e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.51    |\n",
      "| grad_norm   | 5.21     |\n",
      "| loss        | -1.24    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000193 |\n",
      "| recon_loss  | 0.289    |\n",
      "| samples     | 7.52e+04 |\n",
      "| step        | 2.35e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.52    |\n",
      "| grad_norm   | 4.98     |\n",
      "| loss        | -1.22    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000252 |\n",
      "| recon_loss  | 0.3      |\n",
      "| samples     | 7.56e+04 |\n",
      "| step        | 2.36e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.52    |\n",
      "| grad_norm   | 5.81     |\n",
      "| loss        | -1.24    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000229 |\n",
      "| recon_loss  | 0.289    |\n",
      "| samples     | 7.59e+04 |\n",
      "| step        | 2.37e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.53    |\n",
      "| grad_norm   | 5.07     |\n",
      "| loss        | -1.25    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000258 |\n",
      "| recon_loss  | 0.297    |\n",
      "| samples     | 7.62e+04 |\n",
      "| step        | 2.38e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 8        |\n",
      "| gan_loss    | -1.53    |\n",
      "| grad_norm   | 5.27     |\n",
      "| loss        | -1.23    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000256 |\n",
      "| recon_loss  | 0.301    |\n",
      "| samples     | 7.65e+04 |\n",
      "| step        | 2.39e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.54    |\n",
      "| grad_norm   | 6.69     |\n",
      "| loss        | -1.24    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000294 |\n",
      "| recon_loss  | 0.302    |\n",
      "| samples     | 7.68e+04 |\n",
      "| step        | 2.4e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.54    |\n",
      "| grad_norm   | 6.74     |\n",
      "| loss        | -1.27    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000231 |\n",
      "| recon_loss  | 0.284    |\n",
      "| samples     | 7.72e+04 |\n",
      "| step        | 2.41e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.55    |\n",
      "| grad_norm   | 5.38     |\n",
      "| loss        | -1.27    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.00024  |\n",
      "| recon_loss  | 0.293    |\n",
      "| samples     | 7.75e+04 |\n",
      "| step        | 2.42e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.56    |\n",
      "| grad_norm   | 6.43     |\n",
      "| loss        | -1.28    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000219 |\n",
      "| recon_loss  | 0.277    |\n",
      "| samples     | 7.78e+04 |\n",
      "| step        | 2.43e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.56    |\n",
      "| grad_norm   | 7.21     |\n",
      "| loss        | -1.29    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000232 |\n",
      "| recon_loss  | 0.291    |\n",
      "| samples     | 7.81e+04 |\n",
      "| step        | 2.44e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.57    |\n",
      "| grad_norm   | 5.81     |\n",
      "| loss        | -1.29    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000224 |\n",
      "| recon_loss  | 0.289    |\n",
      "| samples     | 7.84e+04 |\n",
      "| step        | 2.45e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.57    |\n",
      "| grad_norm   | 5.64     |\n",
      "| loss        | -1.31    |\n",
      "| param_norm  | 155      |\n",
      "| percep_loss | 0.000218 |\n",
      "| recon_loss  | 0.28     |\n",
      "| samples     | 7.88e+04 |\n",
      "| step        | 2.46e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.58    |\n",
      "| grad_norm   | 6.55     |\n",
      "| loss        | -1.3     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000226 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 7.91e+04 |\n",
      "| step        | 2.47e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.58    |\n",
      "| grad_norm   | 6.82     |\n",
      "| loss        | -1.29    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000233 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 7.94e+04 |\n",
      "| step        | 2.48e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.59    |\n",
      "| grad_norm   | 6.73     |\n",
      "| loss        | -1.29    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000233 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 7.97e+04 |\n",
      "| step        | 2.49e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.59    |\n",
      "| grad_norm   | 5.6      |\n",
      "| loss        | -1.31    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000237 |\n",
      "| recon_loss  | 0.289    |\n",
      "| samples     | 8e+04    |\n",
      "| step        | 2.5e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.6     |\n",
      "| grad_norm   | 6.61     |\n",
      "| loss        | -1.33    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000264 |\n",
      "| recon_loss  | 0.288    |\n",
      "| samples     | 8.04e+04 |\n",
      "| step        | 2.51e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.6     |\n",
      "| grad_norm   | 6.76     |\n",
      "| loss        | -1.33    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000193 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 8.07e+04 |\n",
      "| step        | 2.52e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.61    |\n",
      "| grad_norm   | 5.72     |\n",
      "| loss        | -1.32    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00022  |\n",
      "| recon_loss  | 0.288    |\n",
      "| samples     | 8.1e+04  |\n",
      "| step        | 2.53e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.61    |\n",
      "| grad_norm   | 5.89     |\n",
      "| loss        | -1.32    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000217 |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 8.13e+04 |\n",
      "| step        | 2.54e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.62    |\n",
      "| grad_norm   | 7.02     |\n",
      "| loss        | -1.32    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000206 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 8.16e+04 |\n",
      "| step        | 2.55e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.63    |\n",
      "| grad_norm   | 4.29     |\n",
      "| loss        | -1.36    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000213 |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 8.2e+04  |\n",
      "| step        | 2.56e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.63    |\n",
      "| grad_norm   | 4.82     |\n",
      "| loss        | -1.34    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000218 |\n",
      "| recon_loss  | 0.298    |\n",
      "| samples     | 8.23e+04 |\n",
      "| step        | 2.57e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.64    |\n",
      "| grad_norm   | 7.7      |\n",
      "| loss        | -1.32    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000197 |\n",
      "| recon_loss  | 0.316    |\n",
      "| samples     | 8.26e+04 |\n",
      "| step        | 2.58e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.64    |\n",
      "| grad_norm   | 7.22     |\n",
      "| loss        | -1.36    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000218 |\n",
      "| recon_loss  | 0.288    |\n",
      "| samples     | 8.29e+04 |\n",
      "| step        | 2.59e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.65    |\n",
      "| grad_norm   | 8.04     |\n",
      "| loss        | -1.35    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000222 |\n",
      "| recon_loss  | 0.303    |\n",
      "| samples     | 8.32e+04 |\n",
      "| step        | 2.6e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.65    |\n",
      "| grad_norm   | 6.94     |\n",
      "| loss        | -1.35    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00018  |\n",
      "| recon_loss  | 0.292    |\n",
      "| samples     | 8.36e+04 |\n",
      "| step        | 2.61e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.66    |\n",
      "| grad_norm   | 5.3      |\n",
      "| loss        | -1.37    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000204 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 8.39e+04 |\n",
      "| step        | 2.62e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.66    |\n",
      "| grad_norm   | 5.55     |\n",
      "| loss        | -1.37    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000205 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 8.42e+04 |\n",
      "| step        | 2.63e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.67    |\n",
      "| grad_norm   | 6.01     |\n",
      "| loss        | -1.37    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00019  |\n",
      "| recon_loss  | 0.29     |\n",
      "| samples     | 8.45e+04 |\n",
      "| step        | 2.64e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.67    |\n",
      "| grad_norm   | 7.18     |\n",
      "| loss        | -1.38    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000185 |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 8.48e+04 |\n",
      "| step        | 2.65e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.68    |\n",
      "| grad_norm   | 6.46     |\n",
      "| loss        | -1.4     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000229 |\n",
      "| recon_loss  | 0.297    |\n",
      "| samples     | 8.52e+04 |\n",
      "| step        | 2.66e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.68    |\n",
      "| grad_norm   | 4.65     |\n",
      "| loss        | -1.39    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000178 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 8.55e+04 |\n",
      "| step        | 2.67e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.69    |\n",
      "| grad_norm   | 4.96     |\n",
      "| loss        | -1.41    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000183 |\n",
      "| recon_loss  | 0.29     |\n",
      "| samples     | 8.58e+04 |\n",
      "| step        | 2.68e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 9        |\n",
      "| gan_loss    | -1.69    |\n",
      "| grad_norm   | 6.12     |\n",
      "| loss        | -1.41    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000183 |\n",
      "| recon_loss  | 0.29     |\n",
      "| samples     | 8.61e+04 |\n",
      "| step        | 2.69e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.7     |\n",
      "| grad_norm   | 6.06     |\n",
      "| loss        | -1.42    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00018  |\n",
      "| recon_loss  | 0.288    |\n",
      "| samples     | 8.64e+04 |\n",
      "| step        | 2.7e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.7     |\n",
      "| grad_norm   | 5.9      |\n",
      "| loss        | -1.44    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000179 |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 8.68e+04 |\n",
      "| step        | 2.71e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.71    |\n",
      "| grad_norm   | 6.14     |\n",
      "| loss        | -1.41    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000174 |\n",
      "| recon_loss  | 0.298    |\n",
      "| samples     | 8.71e+04 |\n",
      "| step        | 2.72e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.71    |\n",
      "| grad_norm   | 4.4      |\n",
      "| loss        | -1.44    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000192 |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 8.74e+04 |\n",
      "| step        | 2.73e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.72    |\n",
      "| grad_norm   | 5.16     |\n",
      "| loss        | -1.44    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000202 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 8.77e+04 |\n",
      "| step        | 2.74e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.73    |\n",
      "| grad_norm   | 4.05     |\n",
      "| loss        | -1.48    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000164 |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 8.8e+04  |\n",
      "| step        | 2.75e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.73    |\n",
      "| grad_norm   | 4.75     |\n",
      "| loss        | -1.47    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000176 |\n",
      "| recon_loss  | 0.279    |\n",
      "| samples     | 8.84e+04 |\n",
      "| step        | 2.76e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.74    |\n",
      "| grad_norm   | 6.7      |\n",
      "| loss        | -1.44    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000182 |\n",
      "| recon_loss  | 0.305    |\n",
      "| samples     | 8.87e+04 |\n",
      "| step        | 2.77e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.74    |\n",
      "| grad_norm   | 6.06     |\n",
      "| loss        | -1.47    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000179 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 8.9e+04  |\n",
      "| step        | 2.78e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.74    |\n",
      "| grad_norm   | 5.43     |\n",
      "| loss        | -1.46    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000176 |\n",
      "| recon_loss  | 0.298    |\n",
      "| samples     | 8.93e+04 |\n",
      "| step        | 2.79e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.75    |\n",
      "| grad_norm   | 5.72     |\n",
      "| loss        | -1.45    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000209 |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 8.96e+04 |\n",
      "| step        | 2.8e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.75    |\n",
      "| grad_norm   | 6.46     |\n",
      "| loss        | -1.48    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000171 |\n",
      "| recon_loss  | 0.292    |\n",
      "| samples     | 9e+04    |\n",
      "| step        | 2.81e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.76    |\n",
      "| grad_norm   | 6.61     |\n",
      "| loss        | -1.47    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000157 |\n",
      "| recon_loss  | 0.278    |\n",
      "| samples     | 9.03e+04 |\n",
      "| step        | 2.82e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.76    |\n",
      "| grad_norm   | 7.38     |\n",
      "| loss        | -1.5     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000169 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 9.06e+04 |\n",
      "| step        | 2.83e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.77    |\n",
      "| grad_norm   | 5.66     |\n",
      "| loss        | -1.51    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000204 |\n",
      "| recon_loss  | 0.272    |\n",
      "| samples     | 9.09e+04 |\n",
      "| step        | 2.84e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.77    |\n",
      "| grad_norm   | 5.13     |\n",
      "| loss        | -1.51    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000189 |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 9.12e+04 |\n",
      "| step        | 2.85e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.78    |\n",
      "| grad_norm   | 6.29     |\n",
      "| loss        | -1.5     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00016  |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 9.16e+04 |\n",
      "| step        | 2.86e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.78    |\n",
      "| grad_norm   | 6.85     |\n",
      "| loss        | -1.52    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000187 |\n",
      "| recon_loss  | 0.268    |\n",
      "| samples     | 9.19e+04 |\n",
      "| step        | 2.87e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.79    |\n",
      "| grad_norm   | 5.89     |\n",
      "| loss        | -1.54    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000191 |\n",
      "| recon_loss  | 0.27     |\n",
      "| samples     | 9.22e+04 |\n",
      "| step        | 2.88e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.79    |\n",
      "| grad_norm   | 6.3      |\n",
      "| loss        | -1.52    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000162 |\n",
      "| recon_loss  | 0.272    |\n",
      "| samples     | 9.25e+04 |\n",
      "| step        | 2.89e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.8     |\n",
      "| grad_norm   | 6.88     |\n",
      "| loss        | -1.51    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000171 |\n",
      "| recon_loss  | 0.288    |\n",
      "| samples     | 9.28e+04 |\n",
      "| step        | 2.9e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.8     |\n",
      "| grad_norm   | 7.91     |\n",
      "| loss        | -1.52    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00014  |\n",
      "| recon_loss  | 0.291    |\n",
      "| samples     | 9.32e+04 |\n",
      "| step        | 2.91e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.81    |\n",
      "| grad_norm   | 6.35     |\n",
      "| loss        | -1.53    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000168 |\n",
      "| recon_loss  | 0.28     |\n",
      "| samples     | 9.35e+04 |\n",
      "| step        | 2.92e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.81    |\n",
      "| grad_norm   | 5.31     |\n",
      "| loss        | -1.51    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000152 |\n",
      "| recon_loss  | 0.299    |\n",
      "| samples     | 9.38e+04 |\n",
      "| step        | 2.93e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.82    |\n",
      "| grad_norm   | 4.7      |\n",
      "| loss        | -1.52    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00017  |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 9.41e+04 |\n",
      "| step        | 2.94e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.82    |\n",
      "| grad_norm   | 5.85     |\n",
      "| loss        | -1.55    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000143 |\n",
      "| recon_loss  | 0.275    |\n",
      "| samples     | 9.44e+04 |\n",
      "| step        | 2.95e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.83    |\n",
      "| grad_norm   | 5.81     |\n",
      "| loss        | -1.55    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000145 |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 9.48e+04 |\n",
      "| step        | 2.96e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.83    |\n",
      "| grad_norm   | 6.05     |\n",
      "| loss        | -1.56    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000151 |\n",
      "| recon_loss  | 0.28     |\n",
      "| samples     | 9.51e+04 |\n",
      "| step        | 2.97e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.84    |\n",
      "| grad_norm   | 5.16     |\n",
      "| loss        | -1.57    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000165 |\n",
      "| recon_loss  | 0.277    |\n",
      "| samples     | 9.54e+04 |\n",
      "| step        | 2.98e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 10       |\n",
      "| gan_loss    | -1.84    |\n",
      "| grad_norm   | 4.88     |\n",
      "| loss        | -1.55    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000206 |\n",
      "| recon_loss  | 0.285    |\n",
      "| samples     | 9.57e+04 |\n",
      "| step        | 2.99e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.85    |\n",
      "| grad_norm   | 5.65     |\n",
      "| loss        | -1.57    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000155 |\n",
      "| recon_loss  | 0.278    |\n",
      "| samples     | 9.6e+04  |\n",
      "| step        | 3e+03    |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.85    |\n",
      "| grad_norm   | 6.44     |\n",
      "| loss        | -1.57    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000149 |\n",
      "| recon_loss  | 0.271    |\n",
      "| samples     | 9.64e+04 |\n",
      "| step        | 3.01e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.86    |\n",
      "| grad_norm   | 6.15     |\n",
      "| loss        | -1.56    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000143 |\n",
      "| recon_loss  | 0.283    |\n",
      "| samples     | 9.67e+04 |\n",
      "| step        | 3.02e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.86    |\n",
      "| grad_norm   | 5.05     |\n",
      "| loss        | -1.6     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000163 |\n",
      "| recon_loss  | 0.27     |\n",
      "| samples     | 9.7e+04  |\n",
      "| step        | 3.03e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.87    |\n",
      "| grad_norm   | 6.52     |\n",
      "| loss        | -1.6     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000185 |\n",
      "| recon_loss  | 0.283    |\n",
      "| samples     | 9.73e+04 |\n",
      "| step        | 3.04e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.87    |\n",
      "| grad_norm   | 6.8      |\n",
      "| loss        | -1.6     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000161 |\n",
      "| recon_loss  | 0.281    |\n",
      "| samples     | 9.76e+04 |\n",
      "| step        | 3.05e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.88    |\n",
      "| grad_norm   | 6.07     |\n",
      "| loss        | -1.61    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000153 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 9.8e+04  |\n",
      "| step        | 3.06e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.88    |\n",
      "| grad_norm   | 6.1      |\n",
      "| loss        | -1.59    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000168 |\n",
      "| recon_loss  | 0.294    |\n",
      "| samples     | 9.83e+04 |\n",
      "| step        | 3.07e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.89    |\n",
      "| grad_norm   | 7.55     |\n",
      "| loss        | -1.61    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000144 |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 9.86e+04 |\n",
      "| step        | 3.08e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.89    |\n",
      "| grad_norm   | 6.38     |\n",
      "| loss        | -1.61    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000164 |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 9.89e+04 |\n",
      "| step        | 3.09e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.89    |\n",
      "| grad_norm   | 5.88     |\n",
      "| loss        | -1.62    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000156 |\n",
      "| recon_loss  | 0.269    |\n",
      "| samples     | 9.92e+04 |\n",
      "| step        | 3.1e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.9     |\n",
      "| grad_norm   | 6.33     |\n",
      "| loss        | -1.63    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000139 |\n",
      "| recon_loss  | 0.277    |\n",
      "| samples     | 9.96e+04 |\n",
      "| step        | 3.11e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.9     |\n",
      "| grad_norm   | 7.27     |\n",
      "| loss        | -1.63    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000146 |\n",
      "| recon_loss  | 0.28     |\n",
      "| samples     | 9.99e+04 |\n",
      "| step        | 3.12e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.91    |\n",
      "| grad_norm   | 5.97     |\n",
      "| loss        | -1.64    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000116 |\n",
      "| recon_loss  | 0.266    |\n",
      "| samples     | 1e+05    |\n",
      "| step        | 3.13e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.91    |\n",
      "| grad_norm   | 7.27     |\n",
      "| loss        | -1.63    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000127 |\n",
      "| recon_loss  | 0.277    |\n",
      "| samples     | 1.01e+05 |\n",
      "| step        | 3.14e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.92    |\n",
      "| grad_norm   | 7.02     |\n",
      "| loss        | -1.63    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000171 |\n",
      "| recon_loss  | 0.287    |\n",
      "| samples     | 1.01e+05 |\n",
      "| step        | 3.15e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.92    |\n",
      "| grad_norm   | 6.56     |\n",
      "| loss        | -1.64    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000157 |\n",
      "| recon_loss  | 0.289    |\n",
      "| samples     | 1.01e+05 |\n",
      "| step        | 3.16e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.93    |\n",
      "| grad_norm   | 6.36     |\n",
      "| loss        | -1.65    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000152 |\n",
      "| recon_loss  | 0.281    |\n",
      "| samples     | 1.01e+05 |\n",
      "| step        | 3.17e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.93    |\n",
      "| grad_norm   | 4.6      |\n",
      "| loss        | -1.64    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000126 |\n",
      "| recon_loss  | 0.295    |\n",
      "| samples     | 1.02e+05 |\n",
      "| step        | 3.18e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.94    |\n",
      "| grad_norm   | 4.83     |\n",
      "| loss        | -1.67    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000124 |\n",
      "| recon_loss  | 0.27     |\n",
      "| samples     | 1.02e+05 |\n",
      "| step        | 3.19e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.94    |\n",
      "| grad_norm   | 5.56     |\n",
      "| loss        | -1.67    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00013  |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.02e+05 |\n",
      "| step        | 3.2e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.94    |\n",
      "| grad_norm   | 6.37     |\n",
      "| loss        | -1.67    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000144 |\n",
      "| recon_loss  | 0.274    |\n",
      "| samples     | 1.03e+05 |\n",
      "| step        | 3.21e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.95    |\n",
      "| grad_norm   | 6.5      |\n",
      "| loss        | -1.69    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000149 |\n",
      "| recon_loss  | 0.27     |\n",
      "| samples     | 1.03e+05 |\n",
      "| step        | 3.22e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.95    |\n",
      "| grad_norm   | 7.33     |\n",
      "| loss        | -1.69    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000128 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 1.03e+05 |\n",
      "| step        | 3.23e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.96    |\n",
      "| grad_norm   | 7.75     |\n",
      "| loss        | -1.68    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000144 |\n",
      "| recon_loss  | 0.274    |\n",
      "| samples     | 1.04e+05 |\n",
      "| step        | 3.24e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.96    |\n",
      "| grad_norm   | 8.12     |\n",
      "| loss        | -1.66    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000135 |\n",
      "| recon_loss  | 0.284    |\n",
      "| samples     | 1.04e+05 |\n",
      "| step        | 3.25e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.97    |\n",
      "| grad_norm   | 6.82     |\n",
      "| loss        | -1.69    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000122 |\n",
      "| recon_loss  | 0.279    |\n",
      "| samples     | 1.04e+05 |\n",
      "| step        | 3.26e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.97    |\n",
      "| grad_norm   | 5.25     |\n",
      "| loss        | -1.69    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000134 |\n",
      "| recon_loss  | 0.279    |\n",
      "| samples     | 1.05e+05 |\n",
      "| step        | 3.27e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.98    |\n",
      "| grad_norm   | 6.83     |\n",
      "| loss        | -1.7     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000124 |\n",
      "| recon_loss  | 0.278    |\n",
      "| samples     | 1.05e+05 |\n",
      "| step        | 3.28e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 11       |\n",
      "| gan_loss    | -1.98    |\n",
      "| grad_norm   | 6.71     |\n",
      "| loss        | -1.7     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00012  |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 1.05e+05 |\n",
      "| step        | 3.29e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -1.98    |\n",
      "| grad_norm   | 5.7      |\n",
      "| loss        | -1.72    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000119 |\n",
      "| recon_loss  | 0.26     |\n",
      "| samples     | 1.06e+05 |\n",
      "| step        | 3.3e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -1.99    |\n",
      "| grad_norm   | 5.47     |\n",
      "| loss        | -1.74    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000134 |\n",
      "| recon_loss  | 0.263    |\n",
      "| samples     | 1.06e+05 |\n",
      "| step        | 3.31e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -1.99    |\n",
      "| grad_norm   | 6.11     |\n",
      "| loss        | -1.72    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000112 |\n",
      "| recon_loss  | 0.269    |\n",
      "| samples     | 1.06e+05 |\n",
      "| step        | 3.32e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2       |\n",
      "| grad_norm   | 7.51     |\n",
      "| loss        | -1.71    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000139 |\n",
      "| recon_loss  | 0.3      |\n",
      "| samples     | 1.07e+05 |\n",
      "| step        | 3.33e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2       |\n",
      "| grad_norm   | 6        |\n",
      "| loss        | -1.73    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000132 |\n",
      "| recon_loss  | 0.272    |\n",
      "| samples     | 1.07e+05 |\n",
      "| step        | 3.34e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.01    |\n",
      "| grad_norm   | 4.88     |\n",
      "| loss        | -1.75    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000135 |\n",
      "| recon_loss  | 0.268    |\n",
      "| samples     | 1.07e+05 |\n",
      "| step        | 3.35e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.01    |\n",
      "| grad_norm   | 4.57     |\n",
      "| loss        | -1.76    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000128 |\n",
      "| recon_loss  | 0.264    |\n",
      "| samples     | 1.08e+05 |\n",
      "| step        | 3.36e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.01    |\n",
      "| grad_norm   | 4.2      |\n",
      "| loss        | -1.77    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000116 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.08e+05 |\n",
      "| step        | 3.37e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.02    |\n",
      "| grad_norm   | 4.98     |\n",
      "| loss        | -1.74    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000143 |\n",
      "| recon_loss  | 0.284    |\n",
      "| samples     | 1.08e+05 |\n",
      "| step        | 3.38e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.02    |\n",
      "| grad_norm   | 5.6      |\n",
      "| loss        | -1.76    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00011  |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.09e+05 |\n",
      "| step        | 3.39e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.03    |\n",
      "| grad_norm   | 5.47     |\n",
      "| loss        | -1.77    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000107 |\n",
      "| recon_loss  | 0.25     |\n",
      "| samples     | 1.09e+05 |\n",
      "| step        | 3.4e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.03    |\n",
      "| grad_norm   | 4.94     |\n",
      "| loss        | -1.77    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00011  |\n",
      "| recon_loss  | 0.271    |\n",
      "| samples     | 1.09e+05 |\n",
      "| step        | 3.41e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.03    |\n",
      "| grad_norm   | 4.49     |\n",
      "| loss        | -1.78    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000104 |\n",
      "| recon_loss  | 0.259    |\n",
      "| samples     | 1.09e+05 |\n",
      "| step        | 3.42e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.04    |\n",
      "| grad_norm   | 4.3      |\n",
      "| loss        | -1.78    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000121 |\n",
      "| recon_loss  | 0.261    |\n",
      "| samples     | 1.1e+05  |\n",
      "| step        | 3.43e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.04    |\n",
      "| grad_norm   | 6.77     |\n",
      "| loss        | -1.77    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000115 |\n",
      "| recon_loss  | 0.268    |\n",
      "| samples     | 1.1e+05  |\n",
      "| step        | 3.44e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.05    |\n",
      "| grad_norm   | 7.05     |\n",
      "| loss        | -1.77    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000146 |\n",
      "| recon_loss  | 0.269    |\n",
      "| samples     | 1.1e+05  |\n",
      "| step        | 3.45e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.05    |\n",
      "| grad_norm   | 4.59     |\n",
      "| loss        | -1.78    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000105 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 1.11e+05 |\n",
      "| step        | 3.46e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.06    |\n",
      "| grad_norm   | 4.72     |\n",
      "| loss        | -1.79    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000117 |\n",
      "| recon_loss  | 0.266    |\n",
      "| samples     | 1.11e+05 |\n",
      "| step        | 3.47e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.06    |\n",
      "| grad_norm   | 4.13     |\n",
      "| loss        | -1.79    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000126 |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.11e+05 |\n",
      "| step        | 3.48e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.06    |\n",
      "| grad_norm   | 5.74     |\n",
      "| loss        | -1.79    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000122 |\n",
      "| recon_loss  | 0.279    |\n",
      "| samples     | 1.12e+05 |\n",
      "| step        | 3.49e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.07    |\n",
      "| grad_norm   | 7.05     |\n",
      "| loss        | -1.81    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000109 |\n",
      "| recon_loss  | 0.272    |\n",
      "| samples     | 1.12e+05 |\n",
      "| step        | 3.5e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.07    |\n",
      "| grad_norm   | 6.12     |\n",
      "| loss        | -1.79    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000123 |\n",
      "| recon_loss  | 0.277    |\n",
      "| samples     | 1.12e+05 |\n",
      "| step        | 3.51e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.08    |\n",
      "| grad_norm   | 6.19     |\n",
      "| loss        | -1.83    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000107 |\n",
      "| recon_loss  | 0.252    |\n",
      "| samples     | 1.13e+05 |\n",
      "| step        | 3.52e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.08    |\n",
      "| grad_norm   | 5.18     |\n",
      "| loss        | -1.81    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000114 |\n",
      "| recon_loss  | 0.265    |\n",
      "| samples     | 1.13e+05 |\n",
      "| step        | 3.53e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.08    |\n",
      "| grad_norm   | 6.15     |\n",
      "| loss        | -1.82    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000102 |\n",
      "| recon_loss  | 0.27     |\n",
      "| samples     | 1.13e+05 |\n",
      "| step        | 3.54e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.09    |\n",
      "| grad_norm   | 6.16     |\n",
      "| loss        | -1.81    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00011  |\n",
      "| recon_loss  | 0.272    |\n",
      "| samples     | 1.14e+05 |\n",
      "| step        | 3.55e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.09    |\n",
      "| grad_norm   | 4.27     |\n",
      "| loss        | -1.84    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000119 |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 1.14e+05 |\n",
      "| step        | 3.56e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.1     |\n",
      "| grad_norm   | 4.61     |\n",
      "| loss        | -1.82    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000114 |\n",
      "| recon_loss  | 0.276    |\n",
      "| samples     | 1.14e+05 |\n",
      "| step        | 3.57e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.1     |\n",
      "| grad_norm   | 5.36     |\n",
      "| loss        | -1.84    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.45e-05 |\n",
      "| recon_loss  | 0.261    |\n",
      "| samples     | 1.15e+05 |\n",
      "| step        | 3.58e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 12       |\n",
      "| gan_loss    | -2.1     |\n",
      "| grad_norm   | 5.54     |\n",
      "| loss        | -1.86    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000115 |\n",
      "| recon_loss  | 0.266    |\n",
      "| samples     | 1.15e+05 |\n",
      "| step        | 3.59e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.11    |\n",
      "| grad_norm   | 7.43     |\n",
      "| loss        | -1.84    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000103 |\n",
      "| recon_loss  | 0.278    |\n",
      "| samples     | 1.15e+05 |\n",
      "| step        | 3.6e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.11    |\n",
      "| grad_norm   | 6.86     |\n",
      "| loss        | -1.83    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.00011  |\n",
      "| recon_loss  | 0.269    |\n",
      "| samples     | 1.16e+05 |\n",
      "| step        | 3.61e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.12    |\n",
      "| grad_norm   | 5.26     |\n",
      "| loss        | -1.86    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.78e-05 |\n",
      "| recon_loss  | 0.262    |\n",
      "| samples     | 1.16e+05 |\n",
      "| step        | 3.62e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.12    |\n",
      "| grad_norm   | 6.68     |\n",
      "| loss        | -1.87    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000105 |\n",
      "| recon_loss  | 0.253    |\n",
      "| samples     | 1.16e+05 |\n",
      "| step        | 3.63e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.12    |\n",
      "| grad_norm   | 4.67     |\n",
      "| loss        | -1.85    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.93e-05 |\n",
      "| recon_loss  | 0.274    |\n",
      "| samples     | 1.17e+05 |\n",
      "| step        | 3.64e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.13    |\n",
      "| grad_norm   | 4.55     |\n",
      "| loss        | -1.86    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.86e-05 |\n",
      "| recon_loss  | 0.282    |\n",
      "| samples     | 1.17e+05 |\n",
      "| step        | 3.65e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.13    |\n",
      "| grad_norm   | 5.75     |\n",
      "| loss        | -1.87    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.82e-05 |\n",
      "| recon_loss  | 0.274    |\n",
      "| samples     | 1.17e+05 |\n",
      "| step        | 3.66e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.14    |\n",
      "| grad_norm   | 5.62     |\n",
      "| loss        | -1.87    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000105 |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.17e+05 |\n",
      "| step        | 3.67e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.14    |\n",
      "| grad_norm   | 6.41     |\n",
      "| loss        | -1.88    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.76e-05 |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.18e+05 |\n",
      "| step        | 3.68e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.14    |\n",
      "| grad_norm   | 6.34     |\n",
      "| loss        | -1.89    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000109 |\n",
      "| recon_loss  | 0.265    |\n",
      "| samples     | 1.18e+05 |\n",
      "| step        | 3.69e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.15    |\n",
      "| grad_norm   | 6.25     |\n",
      "| loss        | -1.89    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000102 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.18e+05 |\n",
      "| step        | 3.7e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.15    |\n",
      "| grad_norm   | 5.35     |\n",
      "| loss        | -1.88    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000117 |\n",
      "| recon_loss  | 0.28     |\n",
      "| samples     | 1.19e+05 |\n",
      "| step        | 3.71e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.15    |\n",
      "| grad_norm   | 6.35     |\n",
      "| loss        | -1.9     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000106 |\n",
      "| recon_loss  | 0.268    |\n",
      "| samples     | 1.19e+05 |\n",
      "| step        | 3.72e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.16    |\n",
      "| grad_norm   | 5.25     |\n",
      "| loss        | -1.88    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.46e-05 |\n",
      "| recon_loss  | 0.273    |\n",
      "| samples     | 1.19e+05 |\n",
      "| step        | 3.73e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.16    |\n",
      "| grad_norm   | 6.03     |\n",
      "| loss        | -1.9     |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.66e-05 |\n",
      "| recon_loss  | 0.264    |\n",
      "| samples     | 1.2e+05  |\n",
      "| step        | 3.74e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.17    |\n",
      "| grad_norm   | 7.75     |\n",
      "| loss        | -1.85    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000104 |\n",
      "| recon_loss  | 0.283    |\n",
      "| samples     | 1.2e+05  |\n",
      "| step        | 3.75e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.17    |\n",
      "| grad_norm   | 5.5      |\n",
      "| loss        | -1.89    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.69e-05 |\n",
      "| recon_loss  | 0.271    |\n",
      "| samples     | 1.2e+05  |\n",
      "| step        | 3.76e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.17    |\n",
      "| grad_norm   | 4.76     |\n",
      "| loss        | -1.92    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.77e-05 |\n",
      "| recon_loss  | 0.26     |\n",
      "| samples     | 1.21e+05 |\n",
      "| step        | 3.77e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.18    |\n",
      "| grad_norm   | 4.12     |\n",
      "| loss        | -1.92    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.7e-05  |\n",
      "| recon_loss  | 0.271    |\n",
      "| samples     | 1.21e+05 |\n",
      "| step        | 3.78e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.18    |\n",
      "| grad_norm   | 4.52     |\n",
      "| loss        | -1.92    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.37e-05 |\n",
      "| recon_loss  | 0.263    |\n",
      "| samples     | 1.21e+05 |\n",
      "| step        | 3.79e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.18    |\n",
      "| grad_norm   | 5.36     |\n",
      "| loss        | -1.92    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.3e-05  |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 1.22e+05 |\n",
      "| step        | 3.8e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.19    |\n",
      "| grad_norm   | 5.45     |\n",
      "| loss        | -1.93    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.35e-05 |\n",
      "| recon_loss  | 0.261    |\n",
      "| samples     | 1.22e+05 |\n",
      "| step        | 3.81e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.19    |\n",
      "| grad_norm   | 5.38     |\n",
      "| loss        | -1.92    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000106 |\n",
      "| recon_loss  | 0.266    |\n",
      "| samples     | 1.22e+05 |\n",
      "| step        | 3.82e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.19    |\n",
      "| grad_norm   | 5.51     |\n",
      "| loss        | -1.93    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.98e-05 |\n",
      "| recon_loss  | 0.262    |\n",
      "| samples     | 1.23e+05 |\n",
      "| step        | 3.83e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.2     |\n",
      "| grad_norm   | 5.73     |\n",
      "| loss        | -1.95    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.13e-05 |\n",
      "| recon_loss  | 0.253    |\n",
      "| samples     | 1.23e+05 |\n",
      "| step        | 3.84e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.2     |\n",
      "| grad_norm   | 4.92     |\n",
      "| loss        | -1.94    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000106 |\n",
      "| recon_loss  | 0.262    |\n",
      "| samples     | 1.23e+05 |\n",
      "| step        | 3.85e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.21    |\n",
      "| grad_norm   | 5.82     |\n",
      "| loss        | -1.95    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 7.93e-05 |\n",
      "| recon_loss  | 0.25     |\n",
      "| samples     | 1.24e+05 |\n",
      "| step        | 3.86e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.21    |\n",
      "| grad_norm   | 5.11     |\n",
      "| loss        | -1.93    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000101 |\n",
      "| recon_loss  | 0.278    |\n",
      "| samples     | 1.24e+05 |\n",
      "| step        | 3.87e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.21    |\n",
      "| grad_norm   | 4.87     |\n",
      "| loss        | -1.95    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000101 |\n",
      "| recon_loss  | 0.266    |\n",
      "| samples     | 1.24e+05 |\n",
      "| step        | 3.88e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 13       |\n",
      "| gan_loss    | -2.22    |\n",
      "| grad_norm   | 4.64     |\n",
      "| loss        | -1.97    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.07e-05 |\n",
      "| recon_loss  | 0.247    |\n",
      "| samples     | 1.25e+05 |\n",
      "| step        | 3.89e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.22    |\n",
      "| grad_norm   | 5.77     |\n",
      "| loss        | -1.95    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 7.96e-05 |\n",
      "| recon_loss  | 0.259    |\n",
      "| samples     | 1.25e+05 |\n",
      "| step        | 3.9e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.22    |\n",
      "| grad_norm   | 6.09     |\n",
      "| loss        | -1.96    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.74e-05 |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 1.25e+05 |\n",
      "| step        | 3.91e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.23    |\n",
      "| grad_norm   | 4.64     |\n",
      "| loss        | -1.95    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 9.3e-05  |\n",
      "| recon_loss  | 0.265    |\n",
      "| samples     | 1.25e+05 |\n",
      "| step        | 3.92e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.23    |\n",
      "| grad_norm   | 5.91     |\n",
      "| loss        | -1.96    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 8.2e-05  |\n",
      "| recon_loss  | 0.257    |\n",
      "| samples     | 1.26e+05 |\n",
      "| step        | 3.93e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.23    |\n",
      "| grad_norm   | 5.65     |\n",
      "| loss        | -1.96    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000106 |\n",
      "| recon_loss  | 0.268    |\n",
      "| samples     | 1.26e+05 |\n",
      "| step        | 3.94e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.24    |\n",
      "| grad_norm   | 5.25     |\n",
      "| loss        | -2       |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 7.81e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.26e+05 |\n",
      "| step        | 3.95e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.24    |\n",
      "| grad_norm   | 6.49     |\n",
      "| loss        | -1.96    |\n",
      "| param_norm  | 156      |\n",
      "| percep_loss | 0.000102 |\n",
      "| recon_loss  | 0.265    |\n",
      "| samples     | 1.27e+05 |\n",
      "| step        | 3.96e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.24    |\n",
      "| grad_norm   | 6.76     |\n",
      "| loss        | -1.98    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 9.59e-05 |\n",
      "| recon_loss  | 0.271    |\n",
      "| samples     | 1.27e+05 |\n",
      "| step        | 3.97e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.25    |\n",
      "| grad_norm   | 6.95     |\n",
      "| loss        | -1.99    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 9.7e-05  |\n",
      "| recon_loss  | 0.262    |\n",
      "| samples     | 1.27e+05 |\n",
      "| step        | 3.98e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.25    |\n",
      "| grad_norm   | 6.3      |\n",
      "| loss        | -1.98    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 9.83e-05 |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.28e+05 |\n",
      "| step        | 3.99e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.25    |\n",
      "| grad_norm   | 5.13     |\n",
      "| loss        | -1.99    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.6e-05  |\n",
      "| recon_loss  | 0.26     |\n",
      "| samples     | 1.28e+05 |\n",
      "| step        | 4e+03    |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.26    |\n",
      "| grad_norm   | 5.55     |\n",
      "| loss        | -2.01    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.65e-05 |\n",
      "| recon_loss  | 0.247    |\n",
      "| samples     | 1.28e+05 |\n",
      "| step        | 4.01e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.26    |\n",
      "| grad_norm   | 4.18     |\n",
      "| loss        | -2.03    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.28e-05 |\n",
      "| recon_loss  | 0.24     |\n",
      "| samples     | 1.29e+05 |\n",
      "| step        | 4.02e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.26    |\n",
      "| grad_norm   | 6.14     |\n",
      "| loss        | -2.01    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.09e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.29e+05 |\n",
      "| step        | 4.03e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.27    |\n",
      "| grad_norm   | 5.82     |\n",
      "| loss        | -2.01    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.47e-05 |\n",
      "| recon_loss  | 0.252    |\n",
      "| samples     | 1.29e+05 |\n",
      "| step        | 4.04e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.27    |\n",
      "| grad_norm   | 4.89     |\n",
      "| loss        | -2.02    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.32e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.3e+05  |\n",
      "| step        | 4.05e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.27    |\n",
      "| grad_norm   | 6.87     |\n",
      "| loss        | -2.04    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.08e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.3e+05  |\n",
      "| step        | 4.06e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.28    |\n",
      "| grad_norm   | 7.49     |\n",
      "| loss        | -2.01    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.11e-05 |\n",
      "| recon_loss  | 0.257    |\n",
      "| samples     | 1.3e+05  |\n",
      "| step        | 4.07e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.28    |\n",
      "| grad_norm   | 7.25     |\n",
      "| loss        | -2       |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.29e-05 |\n",
      "| recon_loss  | 0.26     |\n",
      "| samples     | 1.31e+05 |\n",
      "| step        | 4.08e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.28    |\n",
      "| grad_norm   | 5.83     |\n",
      "| loss        | -2.04    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.61e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.31e+05 |\n",
      "| step        | 4.09e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.29    |\n",
      "| grad_norm   | 5.13     |\n",
      "| loss        | -2.03    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.48e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.31e+05 |\n",
      "| step        | 4.1e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.29    |\n",
      "| grad_norm   | 6.52     |\n",
      "| loss        | -2.04    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.71e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.32e+05 |\n",
      "| step        | 4.11e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.29    |\n",
      "| grad_norm   | 6.35     |\n",
      "| loss        | -2.05    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.75e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.32e+05 |\n",
      "| step        | 4.12e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.3     |\n",
      "| grad_norm   | 7.08     |\n",
      "| loss        | -2.04    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.58e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.32e+05 |\n",
      "| step        | 4.13e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.3     |\n",
      "| grad_norm   | 7.06     |\n",
      "| loss        | -2.04    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.36e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.33e+05 |\n",
      "| step        | 4.14e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.3     |\n",
      "| grad_norm   | 5.59     |\n",
      "| loss        | -2.06    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.51e-05 |\n",
      "| recon_loss  | 0.253    |\n",
      "| samples     | 1.33e+05 |\n",
      "| step        | 4.15e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.31    |\n",
      "| grad_norm   | 6.2      |\n",
      "| loss        | -2.06    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.23e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.33e+05 |\n",
      "| step        | 4.16e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.31    |\n",
      "| grad_norm   | 6.5      |\n",
      "| loss        | -2.03    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 9.75e-05 |\n",
      "| recon_loss  | 0.259    |\n",
      "| samples     | 1.33e+05 |\n",
      "| step        | 4.17e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.31    |\n",
      "| grad_norm   | 6.15     |\n",
      "| loss        | -2.05    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.49e-05 |\n",
      "| recon_loss  | 0.255    |\n",
      "| samples     | 1.34e+05 |\n",
      "| step        | 4.18e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 14       |\n",
      "| gan_loss    | -2.32    |\n",
      "| grad_norm   | 6.87     |\n",
      "| loss        | -2.06    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.59e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.34e+05 |\n",
      "| step        | 4.19e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.32    |\n",
      "| grad_norm   | 6.71     |\n",
      "| loss        | -2.06    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.88e-05 |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 1.34e+05 |\n",
      "| step        | 4.2e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.32    |\n",
      "| grad_norm   | 6.41     |\n",
      "| loss        | -2.07    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.8e-05  |\n",
      "| recon_loss  | 0.252    |\n",
      "| samples     | 1.35e+05 |\n",
      "| step        | 4.21e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.33    |\n",
      "| grad_norm   | 5.14     |\n",
      "| loss        | -2.07    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.96e-05 |\n",
      "| recon_loss  | 0.25     |\n",
      "| samples     | 1.35e+05 |\n",
      "| step        | 4.22e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.33    |\n",
      "| grad_norm   | 5.28     |\n",
      "| loss        | -2.07    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.06e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.35e+05 |\n",
      "| step        | 4.23e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.33    |\n",
      "| grad_norm   | 4.32     |\n",
      "| loss        | -2.08    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.45e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.36e+05 |\n",
      "| step        | 4.24e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.33    |\n",
      "| grad_norm   | 4.89     |\n",
      "| loss        | -2.09    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.58e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.36e+05 |\n",
      "| step        | 4.25e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.34    |\n",
      "| grad_norm   | 4.37     |\n",
      "| loss        | -2.08    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.6e-05  |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.36e+05 |\n",
      "| step        | 4.26e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.34    |\n",
      "| grad_norm   | 5.34     |\n",
      "| loss        | -2.08    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.21e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.37e+05 |\n",
      "| step        | 4.27e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.34    |\n",
      "| grad_norm   | 5.62     |\n",
      "| loss        | -2.1     |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.7e-05  |\n",
      "| recon_loss  | 0.248    |\n",
      "| samples     | 1.37e+05 |\n",
      "| step        | 4.28e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.35    |\n",
      "| grad_norm   | 5.04     |\n",
      "| loss        | -2.11    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.47e-05 |\n",
      "| recon_loss  | 0.239    |\n",
      "| samples     | 1.37e+05 |\n",
      "| step        | 4.29e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.35    |\n",
      "| grad_norm   | 5.37     |\n",
      "| loss        | -2.09    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 9.99e-05 |\n",
      "| recon_loss  | 0.253    |\n",
      "| samples     | 1.38e+05 |\n",
      "| step        | 4.3e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.35    |\n",
      "| grad_norm   | 4.97     |\n",
      "| loss        | -2.11    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.42e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.38e+05 |\n",
      "| step        | 4.31e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.36    |\n",
      "| grad_norm   | 6.1      |\n",
      "| loss        | -2.12    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.08e-05 |\n",
      "| recon_loss  | 0.245    |\n",
      "| samples     | 1.38e+05 |\n",
      "| step        | 4.32e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.36    |\n",
      "| grad_norm   | 5.99     |\n",
      "| loss        | -2.09    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.46e-05 |\n",
      "| recon_loss  | 0.258    |\n",
      "| samples     | 1.39e+05 |\n",
      "| step        | 4.33e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.36    |\n",
      "| grad_norm   | 4.77     |\n",
      "| loss        | -2.11    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.48e-05 |\n",
      "| recon_loss  | 0.249    |\n",
      "| samples     | 1.39e+05 |\n",
      "| step        | 4.34e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.36    |\n",
      "| grad_norm   | 4        |\n",
      "| loss        | -2.13    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.95e-05 |\n",
      "| recon_loss  | 0.24     |\n",
      "| samples     | 1.39e+05 |\n",
      "| step        | 4.35e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.37    |\n",
      "| grad_norm   | 5.94     |\n",
      "| loss        | -2.13    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.43e-05 |\n",
      "| recon_loss  | 0.239    |\n",
      "| samples     | 1.4e+05  |\n",
      "| step        | 4.36e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.37    |\n",
      "| grad_norm   | 6.61     |\n",
      "| loss        | -2.09    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.9e-05  |\n",
      "| recon_loss  | 0.267    |\n",
      "| samples     | 1.4e+05  |\n",
      "| step        | 4.37e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.37    |\n",
      "| grad_norm   | 5.09     |\n",
      "| loss        | -2.1     |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.77e-05 |\n",
      "| recon_loss  | 0.265    |\n",
      "| samples     | 1.4e+05  |\n",
      "| step        | 4.38e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.38    |\n",
      "| grad_norm   | 5.32     |\n",
      "| loss        | -2.12    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.36e-05 |\n",
      "| recon_loss  | 0.253    |\n",
      "| samples     | 1.41e+05 |\n",
      "| step        | 4.39e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.38    |\n",
      "| grad_norm   | 4.84     |\n",
      "| loss        | -2.12    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 7.04e-05 |\n",
      "| recon_loss  | 0.256    |\n",
      "| samples     | 1.41e+05 |\n",
      "| step        | 4.4e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.38    |\n",
      "| grad_norm   | 6.27     |\n",
      "| loss        | -2.12    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.74e-05 |\n",
      "| recon_loss  | 0.248    |\n",
      "| samples     | 1.41e+05 |\n",
      "| step        | 4.41e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.38    |\n",
      "| grad_norm   | 4.59     |\n",
      "| loss        | -2.15    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.36e-05 |\n",
      "| recon_loss  | 0.235    |\n",
      "| samples     | 1.41e+05 |\n",
      "| step        | 4.42e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.39    |\n",
      "| grad_norm   | 4.22     |\n",
      "| loss        | -2.16    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.95e-05 |\n",
      "| recon_loss  | 0.228    |\n",
      "| samples     | 1.42e+05 |\n",
      "| step        | 4.43e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.39    |\n",
      "| grad_norm   | 5.02     |\n",
      "| loss        | -2.14    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.08e-05 |\n",
      "| recon_loss  | 0.238    |\n",
      "| samples     | 1.42e+05 |\n",
      "| step        | 4.44e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.39    |\n",
      "| grad_norm   | 5.76     |\n",
      "| loss        | -2.14    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.77e-05 |\n",
      "| recon_loss  | 0.247    |\n",
      "| samples     | 1.42e+05 |\n",
      "| step        | 4.45e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.4     |\n",
      "| grad_norm   | 4.76     |\n",
      "| loss        | -2.15    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.15e-05 |\n",
      "| recon_loss  | 0.25     |\n",
      "| samples     | 1.43e+05 |\n",
      "| step        | 4.46e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.4     |\n",
      "| grad_norm   | 5.43     |\n",
      "| loss        | -2.17    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.88e-05 |\n",
      "| recon_loss  | 0.231    |\n",
      "| samples     | 1.43e+05 |\n",
      "| step        | 4.47e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.4     |\n",
      "| grad_norm   | 5.24     |\n",
      "| loss        | -2.16    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.43e-05 |\n",
      "| recon_loss  | 0.238    |\n",
      "| samples     | 1.43e+05 |\n",
      "| step        | 4.48e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 15       |\n",
      "| gan_loss    | -2.4     |\n",
      "| grad_norm   | 4.66     |\n",
      "| loss        | -2.16    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.78e-05 |\n",
      "| recon_loss  | 0.233    |\n",
      "| samples     | 1.44e+05 |\n",
      "| step        | 4.49e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.41    |\n",
      "| grad_norm   | 5.77     |\n",
      "| loss        | -2.15    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.47e-05 |\n",
      "| recon_loss  | 0.252    |\n",
      "| samples     | 1.44e+05 |\n",
      "| step        | 4.5e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.41    |\n",
      "| grad_norm   | 5.01     |\n",
      "| loss        | -2.17    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.67e-05 |\n",
      "| recon_loss  | 0.25     |\n",
      "| samples     | 1.44e+05 |\n",
      "| step        | 4.51e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.41    |\n",
      "| grad_norm   | 5.23     |\n",
      "| loss        | -2.15    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 8.37e-05 |\n",
      "| recon_loss  | 0.247    |\n",
      "| samples     | 1.45e+05 |\n",
      "| step        | 4.52e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.41    |\n",
      "| grad_norm   | 4.86     |\n",
      "| loss        | -2.17    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.43e-05 |\n",
      "| recon_loss  | 0.238    |\n",
      "| samples     | 1.45e+05 |\n",
      "| step        | 4.53e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.42    |\n",
      "| grad_norm   | 5.12     |\n",
      "| loss        | -2.18    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.03e-05 |\n",
      "| recon_loss  | 0.232    |\n",
      "| samples     | 1.45e+05 |\n",
      "| step        | 4.54e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.42    |\n",
      "| grad_norm   | 5.64     |\n",
      "| loss        | -2.17    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.48e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.46e+05 |\n",
      "| step        | 4.55e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.42    |\n",
      "| grad_norm   | 4.36     |\n",
      "| loss        | -2.18    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.55e-05 |\n",
      "| recon_loss  | 0.248    |\n",
      "| samples     | 1.46e+05 |\n",
      "| step        | 4.56e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.42    |\n",
      "| grad_norm   | 4.92     |\n",
      "| loss        | -2.18    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.88e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.46e+05 |\n",
      "| step        | 4.57e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.43    |\n",
      "| grad_norm   | 7.08     |\n",
      "| loss        | -2.19    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.72e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.47e+05 |\n",
      "| step        | 4.58e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.43    |\n",
      "| grad_norm   | 6.49     |\n",
      "| loss        | -2.18    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.66e-05 |\n",
      "| recon_loss  | 0.241    |\n",
      "| samples     | 1.47e+05 |\n",
      "| step        | 4.59e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.43    |\n",
      "| grad_norm   | 5.41     |\n",
      "| loss        | -2.19    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.56e-05 |\n",
      "| recon_loss  | 0.247    |\n",
      "| samples     | 1.47e+05 |\n",
      "| step        | 4.6e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.44    |\n",
      "| grad_norm   | 4.76     |\n",
      "| loss        | -2.19    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.17e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.48e+05 |\n",
      "| step        | 4.61e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.44    |\n",
      "| grad_norm   | 4.59     |\n",
      "| loss        | -2.19    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.02e-05 |\n",
      "| recon_loss  | 0.255    |\n",
      "| samples     | 1.48e+05 |\n",
      "| step        | 4.62e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.44    |\n",
      "| grad_norm   | 5.28     |\n",
      "| loss        | -2.19    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.34e-05 |\n",
      "| recon_loss  | 0.251    |\n",
      "| samples     | 1.48e+05 |\n",
      "| step        | 4.63e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.44    |\n",
      "| grad_norm   | 5.94     |\n",
      "| loss        | -2.2     |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.42e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.49e+05 |\n",
      "| step        | 4.64e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.45    |\n",
      "| grad_norm   | 6.26     |\n",
      "| loss        | -2.21    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.36e-05 |\n",
      "| recon_loss  | 0.236    |\n",
      "| samples     | 1.49e+05 |\n",
      "| step        | 4.65e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.45    |\n",
      "| grad_norm   | 6.54     |\n",
      "| loss        | -2.22    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.59e-05 |\n",
      "| recon_loss  | 0.24     |\n",
      "| samples     | 1.49e+05 |\n",
      "| step        | 4.66e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.45    |\n",
      "| grad_norm   | 6.6      |\n",
      "| loss        | -2.2     |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.82e-05 |\n",
      "| recon_loss  | 0.238    |\n",
      "| samples     | 1.49e+05 |\n",
      "| step        | 4.67e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.45    |\n",
      "| grad_norm   | 6.28     |\n",
      "| loss        | -2.23    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.79e-05 |\n",
      "| recon_loss  | 0.223    |\n",
      "| samples     | 1.5e+05  |\n",
      "| step        | 4.68e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.46    |\n",
      "| grad_norm   | 6.73     |\n",
      "| loss        | -2.21    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.35e-05 |\n",
      "| recon_loss  | 0.244    |\n",
      "| samples     | 1.5e+05  |\n",
      "| step        | 4.69e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.46    |\n",
      "| grad_norm   | 6.44     |\n",
      "| loss        | -2.21    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.72e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.5e+05  |\n",
      "| step        | 4.7e+03  |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.46    |\n",
      "| grad_norm   | 6.2      |\n",
      "| loss        | -2.23    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.68e-05 |\n",
      "| recon_loss  | 0.232    |\n",
      "| samples     | 1.51e+05 |\n",
      "| step        | 4.71e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.46    |\n",
      "| grad_norm   | 6.36     |\n",
      "| loss        | -2.23    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.33e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.51e+05 |\n",
      "| step        | 4.72e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.47    |\n",
      "| grad_norm   | 6.75     |\n",
      "| loss        | -2.22    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.01e-05 |\n",
      "| recon_loss  | 0.243    |\n",
      "| samples     | 1.51e+05 |\n",
      "| step        | 4.73e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.47    |\n",
      "| grad_norm   | 7.31     |\n",
      "| loss        | -2.22    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.12e-05 |\n",
      "| recon_loss  | 0.241    |\n",
      "| samples     | 1.52e+05 |\n",
      "| step        | 4.74e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.47    |\n",
      "| grad_norm   | 5.87     |\n",
      "| loss        | -2.23    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 6.71e-05 |\n",
      "| recon_loss  | 0.239    |\n",
      "| samples     | 1.52e+05 |\n",
      "| step        | 4.75e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.47    |\n",
      "| grad_norm   | 6.06     |\n",
      "| loss        | -2.22    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.92e-05 |\n",
      "| recon_loss  | 0.242    |\n",
      "| samples     | 1.52e+05 |\n",
      "| step        | 4.76e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.48    |\n",
      "| grad_norm   | 4.4      |\n",
      "| loss        | -2.23    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.84e-05 |\n",
      "| recon_loss  | 0.246    |\n",
      "| samples     | 1.53e+05 |\n",
      "| step        | 4.77e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.48    |\n",
      "| grad_norm   | 5.65     |\n",
      "| loss        | -2.25    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 4.74e-05 |\n",
      "| recon_loss  | 0.226    |\n",
      "| samples     | 1.53e+05 |\n",
      "| step        | 4.78e+03 |\n",
      "--------------------------\n",
      "--------------------------\n",
      "| epoch       | 16       |\n",
      "| gan_loss    | -2.48    |\n",
      "| grad_norm   | 5.16     |\n",
      "| loss        | -2.25    |\n",
      "| param_norm  | 157      |\n",
      "| percep_loss | 5.75e-05 |\n",
      "| recon_loss  | 0.24     |\n",
      "| samples     | 1.53e+05 |\n",
      "| step        | 4.79e+03 |\n",
      "--------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n"
     ]
    }
   ],
   "source": [
    "!python train.py --cuda_devices 0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhnh/python_venv/cv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./results\n",
      "Loading dataset ...\n",
      "loading annotations into memory...\n",
      "Done (t=30.48s)\n",
      "creating index...\n",
      "index created!\n",
      "Dataset scale (before filtering):\n",
      " Images:55000\n",
      " Instances:180000\n",
      "training...\n",
      "Training on sigle GPU\n",
      "load model from: torchvision://resnet50\n",
      "LOAD Backbone ResNET50 torchvision://resnet50\n",
      "LOAD DeIT\n",
      "Rank: 0 - Device: cuda:0 0\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.0610, -0.0041, -0.0149, -0.0175],\n",
      "        [ 0.0091, -0.0062, -0.0146,  0.0214],\n",
      "        [ 0.0223, -0.0311, -0.0223, -0.0179],\n",
      "        ...,\n",
      "        [ 0.0303, -0.0199, -0.0035, -0.0007],\n",
      "        [ 0.0330, -0.0045, -0.0096, -0.0127],\n",
      "        [ 0.0459, -0.0380, -0.0144,  0.0220]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "------------------------------\n",
      "| epoch           | 1        |\n",
      "| grad_norm       | 1.49     |\n",
      "| loss            | 0.727    |\n",
      "| loss_bbox       | 0.00309  |\n",
      "| loss_bbox_score | 0.0144   |\n",
      "| loss_cls        | 0.0274   |\n",
      "| loss_contra     | 0        |\n",
      "| loss_rpn_bbox   | 0.269    |\n",
      "| loss_rpn_cls    | 0        |\n",
      "| loss_rpn_obj    | 0.413    |\n",
      "| lr              | 2e-05    |\n",
      "| param_norm      | 372      |\n",
      "| samples         | 8        |\n",
      "| step            | 0        |\n",
      "------------------------------\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.0425, -0.0080,  0.0090,  0.0170],\n",
      "        [ 0.0253, -0.0129, -0.0045, -0.0384],\n",
      "        [ 0.0296, -0.0201, -0.0197, -0.0573],\n",
      "        ...,\n",
      "        [ 0.0260, -0.0172, -0.0117,  0.0105],\n",
      "        [ 0.0306, -0.0421,  0.0003,  0.0204],\n",
      "        [-0.0055,  0.0036,  0.0131,  0.0314]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 1.5111e-02, -1.2256e-02, -1.2542e-02, -9.8598e-03],\n",
      "        [ 4.2349e-02,  6.1875e-03,  2.4503e-03, -5.0924e-02],\n",
      "        [ 5.5123e-02,  2.0846e-02,  1.1047e-02, -8.5653e-04],\n",
      "        ...,\n",
      "        [ 3.1706e-02, -2.1687e-03,  4.5849e-02, -5.7562e-03],\n",
      "        [-4.7702e-06,  3.8993e-06, -2.4877e-06,  9.5851e-07],\n",
      "        [ 2.7598e-02, -5.0774e-02, -5.3909e-03, -3.3093e-03]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 7.0260e-02, -1.8729e-02,  2.3051e-02, -2.1825e-02],\n",
      "        [ 3.7811e-02, -3.8907e-03,  1.9035e-02, -3.3333e-02],\n",
      "        [ 3.7923e-02,  3.7190e-03,  3.4108e-02, -2.5516e-02],\n",
      "        ...,\n",
      "        [-1.3857e-05,  1.0157e-05, -6.9897e-06,  2.9425e-06],\n",
      "        [ 1.0150e-01,  1.5024e-02,  1.1153e-03, -1.4521e-02],\n",
      "        [ 2.3045e-02, -2.5925e-02,  4.0719e-02,  3.6416e-02]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 3.0138e-02,  6.2478e-03, -7.8540e-03, -2.5682e-02],\n",
      "        [ 3.2245e-02, -1.0347e-02,  8.8307e-03,  9.1477e-04],\n",
      "        [ 1.9374e-02, -9.0715e-03,  4.7625e-03, -9.4761e-03],\n",
      "        ...,\n",
      "        [ 2.6814e-03,  8.6807e-03,  1.4720e-02,  3.1649e-02],\n",
      "        [ 2.5717e-02,  1.1049e-02,  1.3595e-02,  4.0682e-02],\n",
      "        [-2.9199e-05,  1.9613e-05, -1.5327e-05,  8.3800e-06]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-8.4424e-03, -1.3499e-02,  1.4099e-02,  5.5056e-04],\n",
      "        [ 2.7246e-02,  3.4498e-02,  9.6820e-03, -3.5061e-02],\n",
      "        [-1.1198e-02, -1.0929e-02, -2.4999e-03, -7.2175e-03],\n",
      "        ...,\n",
      "        [-1.0925e-02, -3.9393e-03,  7.4553e-03,  1.3511e-02],\n",
      "        [-5.1697e-05,  3.2487e-05, -2.6555e-05,  1.6429e-05],\n",
      "        [-5.1697e-05,  3.2487e-05, -2.6555e-05,  1.6429e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-1.0051e-02,  6.0624e-03, -4.5553e-03,  2.9039e-02],\n",
      "        [-1.1881e-02,  4.7637e-03, -1.5016e-02,  2.3490e-02],\n",
      "        [-7.4906e-04,  1.4119e-02, -2.2236e-02, -1.3392e-03],\n",
      "        ...,\n",
      "        [-7.8699e-05,  4.7829e-05, -3.7940e-05,  2.6034e-05],\n",
      "        [-7.8699e-05,  4.7829e-05, -3.7940e-05,  2.6034e-05],\n",
      "        [-7.8699e-05,  4.7829e-05, -3.7940e-05,  2.6034e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-1.5504e-02,  5.2349e-03, -5.7670e-03, -3.8510e-03],\n",
      "        [-8.1709e-03,  2.9012e-02, -3.9931e-04,  1.2413e-02],\n",
      "        [-2.7751e-02, -1.6076e-02, -2.7862e-02,  1.4556e-02],\n",
      "        ...,\n",
      "        [-1.0793e-04,  6.1357e-05, -4.8273e-05,  3.4728e-05],\n",
      "        [-1.0793e-04,  6.1357e-05, -4.8273e-05,  3.4728e-05],\n",
      "        [-1.0793e-04,  6.1357e-05, -4.8273e-05,  3.4728e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-1.4905e-02,  3.2907e-02, -2.3969e-03, -1.4827e-03],\n",
      "        [ 1.1533e-02,  3.5707e-02,  9.9615e-03,  1.4804e-03],\n",
      "        [-3.8648e-02,  3.5781e-02, -6.7210e-03, -2.6587e-03],\n",
      "        ...,\n",
      "        [-1.3301e-04,  6.9257e-05, -5.4320e-05,  4.0535e-05],\n",
      "        [-4.6556e-02,  1.4823e-02,  1.9252e-02,  2.2292e-03],\n",
      "        [-1.3301e-04,  6.9257e-05, -5.4320e-05,  4.0535e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-3.8924e-02,  1.2515e-02, -1.0728e-02,  1.3297e-03],\n",
      "        [ 1.2622e-03, -4.5797e-05, -2.4420e-02,  3.7792e-02],\n",
      "        [-6.6570e-02,  1.5563e-02, -1.8792e-02,  2.6302e-02],\n",
      "        ...,\n",
      "        [-1.4980e-04,  7.0512e-05, -5.4679e-05,  4.4966e-05],\n",
      "        [-2.3686e-02, -9.4135e-03, -3.2638e-02,  5.2730e-03],\n",
      "        [-3.5382e-02,  1.9350e-02, -4.5124e-03,  1.8168e-02]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0663,  0.0521, -0.0071, -0.0178],\n",
      "        [-0.0486, -0.0004, -0.0305,  0.0042],\n",
      "        [-0.0473,  0.0017, -0.0103, -0.0011],\n",
      "        ...,\n",
      "        [-0.0020, -0.0047, -0.0210, -0.0060],\n",
      "        [-0.0511,  0.0011,  0.0185,  0.0244],\n",
      "        [-0.0492, -0.0130,  0.0035, -0.0113]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "------------------------------\n",
      "| epoch           | 1        |\n",
      "| grad_norm       | 1.13     |\n",
      "| loss            | 0.635    |\n",
      "| loss_bbox       | 0.00269  |\n",
      "| loss_bbox_score | 0.0152   |\n",
      "| loss_cls        | 0.0262   |\n",
      "| loss_contra     | 0        |\n",
      "| loss_rpn_bbox   | 0.171    |\n",
      "| loss_rpn_cls    | 0        |\n",
      "| loss_rpn_obj    | 0.42     |\n",
      "| lr              | 0.00042  |\n",
      "| param_norm      | 372      |\n",
      "| samples         | 88       |\n",
      "| step            | 10       |\n",
      "------------------------------\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0215, -0.0074,  0.0044, -0.0085],\n",
      "        [-0.0491,  0.0030, -0.0039,  0.0295],\n",
      "        [-0.0218,  0.0111,  0.0112,  0.0210],\n",
      "        ...,\n",
      "        [-0.0073, -0.0002, -0.0058,  0.0036],\n",
      "        [-0.0294,  0.0034, -0.0108, -0.0211],\n",
      "        [-0.0499,  0.0098, -0.0024, -0.0160]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-1.6046e-02, -2.5909e-02,  3.2954e-02,  1.3803e-02],\n",
      "        [-9.9205e-03,  6.4591e-03,  7.8938e-03, -2.2141e-02],\n",
      "        [-3.7551e-02,  1.4121e-02,  2.2735e-02, -6.4607e-03],\n",
      "        ...,\n",
      "        [-1.2172e-04,  3.2537e-05, -8.5171e-06,  9.4258e-06],\n",
      "        [-1.7282e-02,  1.1200e-02,  2.5070e-02, -1.9575e-02],\n",
      "        [-1.6735e-02, -3.6587e-02,  2.2193e-02, -2.6306e-02]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 1.7622e-02, -1.3603e-02,  5.8079e-02, -2.1320e-02],\n",
      "        [ 8.7843e-03,  2.5464e-02, -5.9641e-03, -7.5537e-03],\n",
      "        [ 7.0492e-03, -2.2880e-02,  1.0456e-02,  1.5936e-02],\n",
      "        ...,\n",
      "        [-8.5250e-05,  1.4000e-05,  5.8340e-06, -1.0202e-05],\n",
      "        [-8.5250e-05,  1.4000e-05,  5.8340e-06, -1.0202e-05],\n",
      "        [-2.5939e-02, -4.7180e-02,  1.0596e-03,  2.3939e-03]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 1.0703e-02, -1.7330e-02, -8.9922e-03, -1.4750e-02],\n",
      "        [ 2.0763e-02, -1.3896e-02,  9.6976e-03, -3.2745e-02],\n",
      "        [ 9.6666e-03, -4.4295e-02, -7.0295e-03,  3.5354e-03],\n",
      "        ...,\n",
      "        [-4.9273e-05,  5.9970e-06,  1.3985e-05, -2.0846e-05],\n",
      "        [-4.0667e-03, -1.0855e-02, -2.4475e-02, -2.9994e-02],\n",
      "        [ 6.9873e-03,  1.2669e-03,  1.1067e-02,  7.7495e-03]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 2.3954e-02, -2.7193e-02,  1.2333e-02, -2.4960e-02],\n",
      "        [ 3.0461e-02, -1.7295e-02,  1.5663e-02, -2.3970e-02],\n",
      "        [ 1.1771e-02, -3.4763e-03, -2.9704e-03,  6.2029e-03],\n",
      "        ...,\n",
      "        [ 3.4710e-02,  7.9892e-03,  1.5105e-02, -6.5508e-03],\n",
      "        [ 2.2207e-02,  1.7399e-03,  1.1440e-02,  2.0298e-02],\n",
      "        [-2.5816e-05,  1.1850e-05,  1.1673e-05, -1.8679e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 5.0948e-02, -1.9835e-02,  2.3557e-02, -3.4684e-02],\n",
      "        [ 5.6204e-02, -6.6827e-03,  8.5914e-06, -6.7256e-02],\n",
      "        [-5.7062e-03, -4.8064e-03, -1.9471e-02,  1.5240e-03],\n",
      "        ...,\n",
      "        [ 4.3068e-02,  4.1173e-02,  3.1787e-02, -4.7319e-02],\n",
      "        [ 2.8783e-02, -1.6101e-02, -7.0814e-03, -2.9403e-02],\n",
      "        [-2.2014e-05,  2.4142e-05, -2.0568e-06, -4.4847e-06]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 4.1490e-02,  2.1849e-02,  4.7633e-03, -3.2498e-02],\n",
      "        [ 1.8581e-02,  2.7801e-02, -8.2828e-03, -1.6857e-02],\n",
      "        [ 1.2140e-02,  1.5002e-02, -1.6732e-02, -3.3673e-04],\n",
      "        ...,\n",
      "        [-3.5450e-05,  4.2687e-05, -2.5849e-05,  1.7819e-05],\n",
      "        [ 2.5126e-02,  1.1116e-02, -1.6288e-02, -5.5011e-04],\n",
      "        [ 2.2591e-02,  3.4776e-02, -2.2936e-02, -5.5420e-03]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0107,  0.0328,  0.0023,  0.0383],\n",
      "        [-0.0075, -0.0076, -0.0341,  0.0184],\n",
      "        [ 0.0036,  0.0035, -0.0049, -0.0296],\n",
      "        ...,\n",
      "        [-0.0076, -0.0048, -0.0206,  0.0050],\n",
      "        [-0.0170, -0.0217,  0.0021, -0.0153],\n",
      "        [ 0.0059,  0.0111,  0.0002,  0.0025]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.0110, -0.0077, -0.0357, -0.0229],\n",
      "        [-0.0223, -0.0038, -0.0124,  0.0543],\n",
      "        [-0.0258,  0.0322, -0.0133,  0.0206],\n",
      "        ...,\n",
      "        [-0.0013,  0.0008, -0.0048,  0.0285],\n",
      "        [ 0.0074,  0.0018,  0.0123,  0.0149],\n",
      "        [ 0.0243,  0.0113, -0.0101,  0.0078]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-2.1303e-02, -5.7442e-03, -1.0536e-02,  1.5008e-02],\n",
      "        [-2.5061e-02, -2.0428e-02, -4.1872e-03,  3.5942e-02],\n",
      "        [-1.0447e-02,  5.1053e-02,  3.0261e-03,  2.5712e-02],\n",
      "        ...,\n",
      "        [-1.2220e-04,  3.2041e-05, -2.6807e-05,  2.9984e-05],\n",
      "        [-3.4754e-03,  8.5057e-03, -1.5905e-02,  1.3231e-02],\n",
      "        [-1.2220e-04,  3.2041e-05, -2.6807e-05,  2.9984e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "------------------------------\n",
      "| epoch           | 1        |\n",
      "| grad_norm       | 1.08     |\n",
      "| loss            | 0.669    |\n",
      "| loss_bbox       | 0.00231  |\n",
      "| loss_bbox_score | 0.0139   |\n",
      "| loss_cls        | 0.0254   |\n",
      "| loss_contra     | 0        |\n",
      "| loss_rpn_bbox   | 0.211    |\n",
      "| loss_rpn_cls    | 0        |\n",
      "| loss_rpn_obj    | 0.416    |\n",
      "| lr              | 0.000819 |\n",
      "| param_norm      | 372      |\n",
      "| samples         | 168      |\n",
      "| step            | 20       |\n",
      "------------------------------\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-5.8001e-02,  1.3116e-03, -2.5008e-02, -4.3804e-04],\n",
      "        [-2.4454e-03, -8.9307e-03,  3.0269e-02,  2.4106e-02],\n",
      "        [-4.5495e-02, -2.8638e-02,  1.7407e-02,  1.7016e-02],\n",
      "        ...,\n",
      "        [-2.6287e-02, -1.9105e-02, -3.2857e-03, -3.8487e-02],\n",
      "        [-9.3109e-04, -6.9112e-04,  4.5485e-03, -1.2744e-02],\n",
      "        [-1.1832e-04,  1.2566e-05, -1.3534e-05,  6.5751e-06]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-1.6827e-03, -3.7342e-02,  1.8748e-02,  4.1887e-03],\n",
      "        [ 8.8750e-03, -1.8350e-02, -1.0969e-02, -3.5084e-03],\n",
      "        [-2.0911e-03, -1.2946e-02,  9.6235e-04,  2.4206e-02],\n",
      "        ...,\n",
      "        [-9.4903e-05, -3.5842e-07, -1.4229e-06, -1.5105e-05],\n",
      "        [-4.2945e-02,  5.1856e-03,  2.2281e-02,  4.0779e-03],\n",
      "        [-3.1608e-02, -3.2795e-02,  5.9736e-02, -5.0070e-02]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-1.7855e-02, -4.1683e-02, -6.3298e-03,  1.7451e-02],\n",
      "        [-2.5657e-02, -1.7275e-02, -1.2931e-02,  9.7898e-03],\n",
      "        [-7.8866e-03, -1.8566e-02,  1.5618e-03, -3.3951e-02],\n",
      "        ...,\n",
      "        [ 2.2868e-02, -4.6989e-03,  5.1272e-03, -1.8008e-02],\n",
      "        [-5.8768e-05, -4.6182e-06,  7.3501e-06, -2.5854e-05],\n",
      "        [ 9.6949e-04,  6.6953e-03,  1.0552e-02, -2.3438e-02]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 1.9675e-02, -1.6917e-02, -6.2219e-03, -1.5796e-02],\n",
      "        [ 3.0838e-02, -1.4510e-02,  1.1634e-02,  6.5487e-03],\n",
      "        [ 2.9099e-02, -1.9348e-02, -1.3439e-03, -1.6032e-03],\n",
      "        ...,\n",
      "        [ 9.9394e-03,  2.5528e-03,  1.6639e-03,  1.2550e-03],\n",
      "        [ 2.8180e-02, -2.2365e-03,  1.0393e-02, -9.1805e-03],\n",
      "        [-3.2140e-05,  5.1586e-06, -1.9735e-08, -2.6772e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 1.8138e-02,  9.8043e-03,  2.5168e-02,  6.6603e-04],\n",
      "        [ 4.5756e-02,  6.3956e-03,  3.1213e-02, -1.0179e-02],\n",
      "        [ 2.3102e-02,  1.6024e-02, -1.7499e-02, -1.4185e-02],\n",
      "        ...,\n",
      "        [ 2.9804e-02,  1.4705e-02, -1.6847e-02, -1.6834e-02],\n",
      "        [ 1.5579e-02,  7.1927e-03, -1.2027e-02,  1.4753e-02],\n",
      "        [-2.8224e-05,  2.7746e-05, -2.6098e-05, -1.0390e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 3.5310e-02,  4.1870e-02, -2.4789e-02,  1.3341e-02],\n",
      "        [ 3.7789e-02,  7.9044e-03,  1.0048e-02,  2.4680e-02],\n",
      "        [ 2.3514e-02,  2.6518e-03, -1.1171e-02,  3.1313e-03],\n",
      "        ...,\n",
      "        [ 4.6161e-03,  7.6325e-03, -4.5068e-03,  1.1771e-02],\n",
      "        [-5.4475e-05,  4.3923e-05, -4.0558e-05,  9.9503e-06],\n",
      "        [-2.8786e-03,  9.3135e-03, -1.5768e-02,  2.3062e-02]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-1.0261e-02,  2.0490e-02, -2.0189e-02,  1.9532e-02],\n",
      "        [-1.9169e-02, -7.7419e-03, -9.6119e-03,  1.0730e-02],\n",
      "        [-1.3765e-02,  3.9602e-02, -1.7286e-02,  1.5130e-02],\n",
      "        ...,\n",
      "        [-1.1404e-02,  1.1101e-02, -2.5721e-02,  1.4180e-02],\n",
      "        [-9.9772e-05,  4.5585e-05, -4.2686e-05,  1.8614e-05],\n",
      "        [ 7.9037e-03,  3.1904e-02, -2.2593e-02, -5.4974e-03]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-4.0190e-03, -3.4093e-03,  9.1543e-03,  1.5464e-02],\n",
      "        [-2.5004e-02, -1.0289e-02, -1.6686e-02,  2.4712e-02],\n",
      "        [-1.7662e-02, -6.2456e-04,  1.5347e-02,  1.0365e-02],\n",
      "        ...,\n",
      "        [-1.2326e-04,  2.7233e-05, -2.9066e-05, -1.8069e-06],\n",
      "        [-1.2326e-04,  2.7233e-05, -2.9066e-05, -1.8069e-06],\n",
      "        [-1.2326e-04,  2.7233e-05, -2.9066e-05, -1.8069e-06]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-2.8475e-02, -3.6722e-02,  8.7116e-03, -3.0651e-02],\n",
      "        [-3.9276e-03,  2.8201e-03, -1.2813e-02, -2.0945e-02],\n",
      "        [ 1.0605e-03,  3.3497e-03,  3.4510e-02, -3.5747e-02],\n",
      "        ...,\n",
      "        [-1.6124e-03, -3.6567e-03,  6.2950e-03, -1.4102e-02],\n",
      "        [-7.8920e-03, -1.5090e-02, -3.4800e-03,  2.6147e-03],\n",
      "        [-1.1452e-04,  1.7437e-06, -2.3603e-05, -3.1456e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 2.8547e-02, -9.5577e-03,  1.1937e-02, -1.3657e-02],\n",
      "        [-2.0232e-02, -2.1903e-02, -3.6705e-03, -2.3909e-02],\n",
      "        [ 2.2378e-03, -2.1520e-02,  7.8909e-03, -1.2728e-03],\n",
      "        ...,\n",
      "        [ 9.1964e-03,  3.6772e-03, -4.1135e-03, -5.0217e-03],\n",
      "        [-8.0965e-05, -1.1621e-05, -3.1212e-05, -3.5994e-05],\n",
      "        [ 4.9322e-03, -4.8785e-02, -8.4649e-03, -6.6932e-03]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "------------------------------\n",
      "| epoch           | 1        |\n",
      "| grad_norm       | 0.916    |\n",
      "| loss            | 0.629    |\n",
      "| loss_bbox       | 0.00204  |\n",
      "| loss_bbox_score | 0.011    |\n",
      "| loss_cls        | 0.0245   |\n",
      "| loss_contra     | 0        |\n",
      "| loss_rpn_bbox   | 0.182    |\n",
      "| loss_rpn_cls    | 0        |\n",
      "| loss_rpn_obj    | 0.41     |\n",
      "| lr              | 0.00122  |\n",
      "| param_norm      | 372      |\n",
      "| samples         | 248      |\n",
      "| step            | 30       |\n",
      "------------------------------\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 2.8016e-02, -3.0209e-02, -2.1093e-02,  6.0486e-03],\n",
      "        [ 7.3909e-03, -1.4864e-02,  1.1976e-02,  2.5721e-02],\n",
      "        [ 1.1438e-02, -2.7567e-02, -1.5429e-02, -1.2259e-02],\n",
      "        ...,\n",
      "        [ 9.2888e-03, -4.1223e-02,  2.4991e-02, -2.5246e-02],\n",
      "        [ 1.1445e-02, -1.5495e-03,  9.1013e-03, -8.3780e-03],\n",
      "        [-4.9135e-05,  3.9973e-06, -4.9641e-05, -1.5744e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 7.1278e-03,  5.9027e-03, -1.2066e-02,  1.4943e-03],\n",
      "        [-1.3511e-02,  3.4215e-02, -2.9856e-02,  3.8137e-03],\n",
      "        [ 3.0306e-02, -2.8629e-03, -1.7630e-03,  1.4291e-02],\n",
      "        ...,\n",
      "        [ 1.9021e-02,  3.5106e-03, -6.0686e-03,  3.0998e-03],\n",
      "        [ 9.8343e-03,  5.4354e-03, -1.0051e-02, -1.8309e-03],\n",
      "        [-5.0988e-05,  3.2704e-05, -6.1232e-05,  1.1101e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.0100, -0.0106,  0.0311,  0.0223],\n",
      "        [-0.0046,  0.0040, -0.0073, -0.0135],\n",
      "        [ 0.0071,  0.0188,  0.0113,  0.0016],\n",
      "        ...,\n",
      "        [-0.0013,  0.0093, -0.0081,  0.0038],\n",
      "        [-0.0112,  0.0087,  0.0043,  0.0241],\n",
      "        [ 0.0212, -0.0082, -0.0055,  0.0381]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0129,  0.0078,  0.0088, -0.0008],\n",
      "        [-0.0335,  0.0137,  0.0093, -0.0079],\n",
      "        [-0.0165,  0.0003, -0.0130, -0.0291],\n",
      "        ...,\n",
      "        [-0.0004, -0.0030,  0.0001, -0.0128],\n",
      "        [-0.0069,  0.0097, -0.0181, -0.0218],\n",
      "        [-0.0055,  0.0002,  0.0071, -0.0093]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-6.6433e-03,  7.0285e-03,  1.1888e-02, -5.2457e-03],\n",
      "        [ 1.5395e-03, -2.7176e-02,  1.4942e-02, -2.4307e-02],\n",
      "        [-2.7788e-02, -8.9909e-03,  1.6151e-02, -2.3735e-02],\n",
      "        ...,\n",
      "        [-1.0135e-04,  5.5236e-06, -3.4379e-05, -1.8059e-05],\n",
      "        [-3.4080e-03, -1.7526e-02, -5.8549e-03,  4.7334e-03],\n",
      "        [-1.0135e-04,  5.5236e-06, -3.4379e-05, -1.8059e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.0234,  0.0235, -0.0185, -0.0215],\n",
      "        [-0.0179, -0.0337,  0.0179,  0.0083],\n",
      "        [ 0.0224, -0.0343,  0.0052,  0.0019],\n",
      "        ...,\n",
      "        [ 0.0118, -0.0129, -0.0021, -0.0073],\n",
      "        [-0.0034,  0.0048, -0.0059, -0.0101],\n",
      "        [ 0.0157,  0.0012, -0.0094, -0.0016]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-4.0578e-03, -6.8448e-03, -8.0601e-03, -8.5727e-03],\n",
      "        [ 1.2969e-02, -3.1176e-02, -1.2719e-02,  1.0236e-02],\n",
      "        [-1.7513e-02, -6.3611e-03,  4.4139e-03,  5.4798e-03],\n",
      "        ...,\n",
      "        [-5.9033e-05, -1.4037e-06, -7.4030e-05,  3.6847e-06],\n",
      "        [ 4.8171e-03,  2.4183e-03, -1.7773e-02, -1.5494e-02],\n",
      "        [ 1.8181e-02,  5.8171e-03, -2.5681e-02, -1.4640e-02]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-1.1021e-02,  1.8863e-02, -6.7193e-03, -2.5180e-02],\n",
      "        [ 4.8687e-03,  7.1134e-03, -5.3781e-03,  2.4829e-02],\n",
      "        [-7.5615e-03,  1.7298e-02,  1.2931e-02,  1.6106e-02],\n",
      "        ...,\n",
      "        [-7.0003e-05,  1.9866e-05, -5.7442e-05,  1.2866e-05],\n",
      "        [ 1.4424e-03, -7.0196e-03, -1.3140e-02, -2.7792e-03],\n",
      "        [-7.0003e-05,  1.9866e-05, -5.7442e-05,  1.2866e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 4.0810e-03, -2.7667e-03,  9.9614e-03,  1.4301e-02],\n",
      "        [-3.9920e-04,  6.5648e-03, -7.5531e-03,  8.5630e-03],\n",
      "        [-2.2842e-03,  1.3534e-02,  5.0163e-03,  1.8638e-02],\n",
      "        ...,\n",
      "        [-8.4397e-04,  5.7117e-03,  5.2861e-03, -2.7826e-02],\n",
      "        [-9.5241e-05, -4.2341e-06, -4.0607e-05, -2.8017e-06],\n",
      "        [ 1.1810e-02,  3.3532e-03, -1.1993e-02,  1.6042e-02]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-3.0270e-02, -2.3609e-03,  8.7526e-03, -1.6993e-04],\n",
      "        [-7.0404e-03, -2.5466e-02, -9.3644e-04,  1.0788e-02],\n",
      "        [ 9.1542e-03, -4.5619e-03, -1.9845e-02, -1.0726e-02],\n",
      "        ...,\n",
      "        [ 1.2959e-02, -1.3163e-03,  3.8679e-03,  1.0881e-02],\n",
      "        [-1.0849e-04, -4.2758e-05, -4.9079e-05, -1.0291e-05],\n",
      "        [-1.8112e-02,  1.0460e-02, -1.3891e-02, -2.0671e-02]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "------------------------------\n",
      "| epoch           | 1        |\n",
      "| grad_norm       | 0.809    |\n",
      "| loss            | 0.597    |\n",
      "| loss_bbox       | 0.00182  |\n",
      "| loss_bbox_score | 0.00839  |\n",
      "| loss_cls        | 0.0237   |\n",
      "| loss_contra     | 0        |\n",
      "| loss_rpn_bbox   | 0.151    |\n",
      "| loss_rpn_cls    | 0        |\n",
      "| loss_rpn_obj    | 0.413    |\n",
      "| lr              | 0.00162  |\n",
      "| param_norm      | 372      |\n",
      "| samples         | 328      |\n",
      "| step            | 40       |\n",
      "------------------------------\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-5.0677e-03,  6.5959e-03,  2.1935e-02,  2.2250e-02],\n",
      "        [ 1.5772e-02,  3.5558e-03, -3.8505e-04,  8.2617e-03],\n",
      "        [ 7.3181e-04,  6.7403e-03, -2.6223e-02, -1.1620e-02],\n",
      "        ...,\n",
      "        [-8.7345e-05, -3.8591e-05, -6.3269e-05,  1.8733e-06],\n",
      "        [-6.0901e-03, -9.3453e-03,  4.6779e-03, -2.1979e-02],\n",
      "        [ 6.6396e-03,  3.0441e-03,  1.3074e-03, -6.1023e-03]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0068, -0.0024,  0.0214, -0.0021],\n",
      "        [ 0.0194,  0.0207, -0.0027, -0.0169],\n",
      "        [-0.0112,  0.0158, -0.0028, -0.0094],\n",
      "        ...,\n",
      "        [ 0.0089,  0.0038, -0.0009,  0.0133],\n",
      "        [-0.0047,  0.0156, -0.0055,  0.0044],\n",
      "        [ 0.0094,  0.0233,  0.0143, -0.0169]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 3.9990e-04,  1.3980e-02, -8.0335e-04,  6.2508e-03],\n",
      "        [ 1.2572e-02, -5.7419e-03, -3.6377e-03,  1.0817e-02],\n",
      "        [-8.3421e-03, -1.3394e-02,  5.2874e-03, -9.0823e-03],\n",
      "        ...,\n",
      "        [ 2.9078e-03, -8.4672e-03, -1.4500e-02, -1.9381e-02],\n",
      "        [-1.0428e-04, -6.3277e-05, -2.5385e-05, -2.3559e-05],\n",
      "        [ 8.7760e-03,  2.1938e-03,  1.2429e-02,  6.8256e-03]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 4.3603e-03, -2.9404e-02, -2.0718e-02, -2.0029e-04],\n",
      "        [ 1.3236e-02, -1.3892e-02,  3.1395e-02,  1.6356e-02],\n",
      "        [ 1.8374e-03,  2.7796e-03,  1.7761e-02, -7.2224e-03],\n",
      "        ...,\n",
      "        [-3.9306e-03, -2.7580e-02,  1.3924e-02,  5.4426e-03],\n",
      "        [ 5.0879e-03, -4.0395e-03,  6.8948e-04,  7.3772e-03],\n",
      "        [-9.8302e-05, -8.6629e-05, -3.7042e-05, -3.1983e-06]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-1.0023e-02, -8.0633e-04, -9.7369e-03,  1.4488e-02],\n",
      "        [ 1.6367e-02,  1.0002e-02,  5.2120e-03,  9.8318e-04],\n",
      "        [ 1.7094e-02,  2.0545e-02, -2.4272e-02, -3.4914e-02],\n",
      "        ...,\n",
      "        [-9.8036e-05, -6.9653e-05, -6.5277e-05,  1.3794e-05],\n",
      "        [-9.8744e-03,  1.1398e-02,  1.8703e-03,  1.0056e-02],\n",
      "        [-9.8036e-05, -6.9653e-05, -6.5277e-05,  1.3794e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0102, -0.0086, -0.0079,  0.0119],\n",
      "        [ 0.0142,  0.0071, -0.0039,  0.0205],\n",
      "        [-0.0111,  0.0020,  0.0006,  0.0102],\n",
      "        ...,\n",
      "        [ 0.0182,  0.0056, -0.0052, -0.0052],\n",
      "        [ 0.0148,  0.0150, -0.0114,  0.0049],\n",
      "        [-0.0043,  0.0138, -0.0070, -0.0095]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.0003, -0.0058,  0.0136, -0.0122],\n",
      "        [ 0.0120, -0.0186,  0.0095, -0.0115],\n",
      "        [ 0.0055,  0.0068,  0.0408, -0.0320],\n",
      "        ...,\n",
      "        [ 0.0289, -0.0063,  0.0442, -0.0239],\n",
      "        [-0.0015, -0.0137,  0.0317, -0.0140],\n",
      "        [-0.0058, -0.0034,  0.0010, -0.0051]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0157, -0.0170,  0.0025, -0.0179],\n",
      "        [-0.0069, -0.0311,  0.0062,  0.0025],\n",
      "        [-0.0013, -0.0013,  0.0018,  0.0103],\n",
      "        ...,\n",
      "        [ 0.0083, -0.0070,  0.0042,  0.0178],\n",
      "        [ 0.0020,  0.0032,  0.0059,  0.0010],\n",
      "        [-0.0016, -0.0041,  0.0152, -0.0144]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.0115,  0.0115,  0.0050,  0.0033],\n",
      "        [-0.0060,  0.0057,  0.0214,  0.0415],\n",
      "        [ 0.0111,  0.0109,  0.0104,  0.0018],\n",
      "        ...,\n",
      "        [ 0.0112, -0.0131, -0.0133, -0.0089],\n",
      "        [-0.0032,  0.0096, -0.0094,  0.0151],\n",
      "        [-0.0063,  0.0155, -0.0142, -0.0179]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 4.8357e-03,  2.1880e-02, -8.7665e-03, -4.5764e-03],\n",
      "        [-1.3441e-02, -7.9138e-03, -9.8967e-03,  7.8715e-03],\n",
      "        [-5.3645e-03,  7.8050e-03, -8.2139e-03,  5.7997e-03],\n",
      "        ...,\n",
      "        [ 1.7714e-03, -1.7104e-04, -1.7611e-02, -1.1872e-02],\n",
      "        [-1.3568e-04, -7.8861e-05, -5.9187e-05,  3.1927e-05],\n",
      "        [ 3.1939e-02,  2.3598e-02,  5.5393e-03, -8.2979e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "------------------------------\n",
      "| epoch           | 1        |\n",
      "| grad_norm       | 0.749    |\n",
      "| loss            | 0.615    |\n",
      "| loss_bbox       | 0.00158  |\n",
      "| loss_bbox_score | 0.00544  |\n",
      "| loss_cls        | 0.0233   |\n",
      "| loss_contra     | 0        |\n",
      "| loss_rpn_bbox   | 0.185    |\n",
      "| loss_rpn_cls    | 0        |\n",
      "| loss_rpn_obj    | 0.399    |\n",
      "| lr              | 0.00202  |\n",
      "| param_norm      | 372      |\n",
      "| samples         | 408      |\n",
      "| step            | 50       |\n",
      "------------------------------\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 3.7527e-03,  2.3417e-03, -2.7936e-03,  1.7361e-03],\n",
      "        [ 4.0085e-03,  4.3803e-04,  9.1109e-04, -3.5642e-03],\n",
      "        [ 1.6592e-02,  9.4208e-03, -9.3881e-03, -3.7750e-03],\n",
      "        ...,\n",
      "        [ 2.3671e-03, -4.1154e-03, -1.2213e-02, -1.5001e-02],\n",
      "        [-1.4715e-04, -8.8277e-05, -2.9361e-05,  9.7095e-06],\n",
      "        [-1.4715e-04, -8.8277e-05, -2.9361e-05,  9.7095e-06]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.0087, -0.0215, -0.0031,  0.0089],\n",
      "        [ 0.0040, -0.0008,  0.0352,  0.0105],\n",
      "        [ 0.0049,  0.0072,  0.0108,  0.0080],\n",
      "        ...,\n",
      "        [-0.0072,  0.0040,  0.0069, -0.0016],\n",
      "        [ 0.0020, -0.0124,  0.0071, -0.0066],\n",
      "        [-0.0070,  0.0039,  0.0027, -0.0139]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0011, -0.0151, -0.0216, -0.0085],\n",
      "        [-0.0022,  0.0089, -0.0018, -0.0033],\n",
      "        [ 0.0129, -0.0002, -0.0083,  0.0043],\n",
      "        ...,\n",
      "        [-0.0061,  0.0058, -0.0032,  0.0072],\n",
      "        [-0.0015, -0.0048, -0.0006, -0.0064],\n",
      "        [ 0.0223,  0.0176, -0.0095, -0.0023]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-7.4643e-03, -3.4367e-03, -5.1957e-03,  1.1091e-02],\n",
      "        [-1.3881e-02, -2.1052e-03, -2.0505e-03,  8.8043e-03],\n",
      "        [-1.0349e-02,  1.0874e-02, -2.4289e-03,  1.3507e-02],\n",
      "        ...,\n",
      "        [ 8.8727e-03,  1.3177e-02, -1.0579e-02,  6.9804e-03],\n",
      "        [-7.7910e-03, -3.5562e-03, -8.4436e-03,  1.4760e-02],\n",
      "        [-1.6674e-04, -9.4798e-05, -4.0435e-05,  5.1095e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-6.7199e-03, -5.2655e-03, -1.1096e-02,  5.5397e-03],\n",
      "        [ 4.7978e-03, -1.0708e-02,  1.7473e-02, -8.7385e-03],\n",
      "        [-7.4991e-03, -7.8188e-03, -8.4919e-03, -8.8433e-03],\n",
      "        ...,\n",
      "        [ 7.9511e-04,  2.5483e-03, -2.3472e-02,  5.0460e-04],\n",
      "        [-1.8452e-04, -1.1173e-04, -1.8935e-05,  2.5101e-05],\n",
      "        [-1.8452e-04, -1.1173e-04, -1.8935e-05,  2.5101e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0047, -0.0011,  0.0180, -0.0050],\n",
      "        [ 0.0091, -0.0133,  0.0062, -0.0089],\n",
      "        [ 0.0043,  0.0092,  0.0188, -0.0030],\n",
      "        ...,\n",
      "        [ 0.0007,  0.0105,  0.0067, -0.0044],\n",
      "        [-0.0004,  0.0024,  0.0097, -0.0114],\n",
      "        [-0.0116, -0.0232,  0.0057,  0.0088]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.0129,  0.0134,  0.0001,  0.0007],\n",
      "        [ 0.0119, -0.0013,  0.0006,  0.0065],\n",
      "        [ 0.0064, -0.0108, -0.0162,  0.0042],\n",
      "        ...,\n",
      "        [ 0.0050, -0.0115,  0.0080, -0.0026],\n",
      "        [ 0.0014,  0.0012, -0.0036,  0.0018],\n",
      "        [-0.0008,  0.0179,  0.0190, -0.0022]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-6.2061e-03, -5.1781e-04, -2.9830e-02,  1.9097e-03],\n",
      "        [-5.5366e-03,  2.8071e-03, -8.7314e-03, -1.1842e-02],\n",
      "        [ 1.2682e-02,  1.1921e-02, -1.8087e-02,  9.6087e-03],\n",
      "        ...,\n",
      "        [-1.9422e-02,  9.5671e-04, -1.8066e-02, -2.6837e-02],\n",
      "        [-1.7335e-04, -1.1465e-04, -4.3618e-05,  4.0464e-05],\n",
      "        [-1.7335e-04, -1.1465e-04, -4.3618e-05,  4.0464e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 4.1892e-03, -1.1978e-02,  1.2338e-02, -6.1473e-03],\n",
      "        [-2.7243e-03,  8.6611e-03,  7.6172e-03, -6.3760e-03],\n",
      "        [-1.1301e-02, -5.8730e-03,  8.7351e-03, -1.1347e-02],\n",
      "        ...,\n",
      "        [-9.4342e-05,  1.4605e-03,  7.1514e-03,  4.4401e-03],\n",
      "        [ 8.7579e-04,  5.5710e-03, -1.2297e-03, -5.9456e-03],\n",
      "        [-1.8246e-04, -1.4910e-04,  7.2772e-06,  5.0606e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 3.3110e-03, -1.5509e-04,  1.8878e-02,  9.9050e-03],\n",
      "        [ 4.6672e-03, -2.6330e-02,  1.5838e-02,  1.4237e-03],\n",
      "        [ 3.2935e-03, -9.2881e-03, -4.1219e-03,  7.1525e-03],\n",
      "        ...,\n",
      "        [ 3.1486e-03,  5.0600e-03,  7.5479e-03, -3.3825e-03],\n",
      "        [-2.0132e-04, -1.5359e-04,  2.6849e-05,  7.9820e-05],\n",
      "        [-1.9177e-02,  1.0985e-03,  7.9977e-03, -1.9649e-03]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "------------------------------\n",
      "| epoch           | 1        |\n",
      "| grad_norm       | 0.692    |\n",
      "| loss            | 0.562    |\n",
      "| loss_bbox       | 0.00135  |\n",
      "| loss_bbox_score | 0.00333  |\n",
      "| loss_cls        | 0.0229   |\n",
      "| loss_contra     | 0        |\n",
      "| loss_rpn_bbox   | 0.15     |\n",
      "| loss_rpn_cls    | 0        |\n",
      "| loss_rpn_obj    | 0.384    |\n",
      "| lr              | 0.00242  |\n",
      "| param_norm      | 372      |\n",
      "| samples         | 488      |\n",
      "| step            | 60       |\n",
      "------------------------------\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0079,  0.0079,  0.0119,  0.0047],\n",
      "        [-0.0165,  0.0089, -0.0174,  0.0046],\n",
      "        [ 0.0173,  0.0032, -0.0218, -0.0165],\n",
      "        ...,\n",
      "        [-0.0037,  0.0091, -0.0076,  0.0029],\n",
      "        [-0.0077,  0.0080, -0.0064, -0.0143],\n",
      "        [-0.0089,  0.0024, -0.0107,  0.0074]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 3.5629e-03, -3.4027e-02, -8.9635e-03,  3.4950e-03],\n",
      "        [ 1.1964e-02,  5.1299e-04, -3.8101e-03, -1.7371e-02],\n",
      "        [-5.2021e-04, -5.4644e-03, -3.1729e-03, -2.6486e-03],\n",
      "        ...,\n",
      "        [ 1.5127e-02, -2.0044e-02, -2.2329e-02,  1.7147e-02],\n",
      "        [ 1.3258e-02, -2.4278e-03, -1.6898e-02, -3.9217e-03],\n",
      "        [-2.1609e-04, -1.6742e-04,  3.2174e-05,  7.5186e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.0163, -0.0131,  0.0102, -0.0055],\n",
      "        [-0.0015,  0.0085,  0.0099, -0.0210],\n",
      "        [-0.0048,  0.0068, -0.0213, -0.0006],\n",
      "        ...,\n",
      "        [ 0.0028,  0.0099,  0.0029, -0.0025],\n",
      "        [ 0.0094,  0.0078,  0.0005, -0.0017],\n",
      "        [-0.0005,  0.0114, -0.0025,  0.0033]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0006, -0.0052, -0.0038,  0.0073],\n",
      "        [-0.0015, -0.0150, -0.0020,  0.0021],\n",
      "        [-0.0152,  0.0011,  0.0118, -0.0202],\n",
      "        ...,\n",
      "        [-0.0080, -0.0075,  0.0032, -0.0009],\n",
      "        [ 0.0023, -0.0064, -0.0055,  0.0007],\n",
      "        [-0.0127, -0.0172, -0.0043, -0.0059]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 8.6210e-03,  2.0641e-03,  2.2636e-02, -1.4199e-02],\n",
      "        [ 8.7072e-03,  1.2180e-02,  3.0821e-03, -9.8400e-03],\n",
      "        [ 1.1102e-02,  1.0474e-02,  1.6745e-02,  3.0802e-03],\n",
      "        ...,\n",
      "        [ 3.7893e-03, -4.4719e-03, -6.8278e-03, -1.5470e-02],\n",
      "        [ 8.4694e-03, -1.7970e-03,  4.2844e-03,  9.1668e-04],\n",
      "        [-2.3695e-04, -1.5131e-04,  9.7368e-05,  7.7477e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 1.2977e-03,  1.5116e-02, -1.6570e-02, -1.4768e-02],\n",
      "        [ 1.5426e-02,  1.4788e-03, -5.1937e-03,  3.3130e-03],\n",
      "        [ 5.9785e-03, -1.2716e-03, -1.6698e-02,  3.9895e-03],\n",
      "        ...,\n",
      "        [-3.6957e-03,  1.4577e-03, -1.0088e-03,  8.5587e-04],\n",
      "        [ 9.0810e-03,  8.1765e-03, -1.0198e-02,  1.2930e-02],\n",
      "        [-2.6597e-04, -1.4438e-04,  5.3765e-05,  1.0026e-04]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.0119, -0.0032,  0.0060, -0.0221],\n",
      "        [ 0.0018, -0.0236, -0.0021, -0.0018],\n",
      "        [ 0.0015, -0.0065,  0.0091, -0.0216],\n",
      "        ...,\n",
      "        [-0.0067, -0.0042, -0.0154, -0.0110],\n",
      "        [-0.0061, -0.0192, -0.0180, -0.0014],\n",
      "        [-0.0005, -0.0100, -0.0032, -0.0075]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-4.1906e-03,  2.5241e-02,  3.5320e-03, -4.5783e-03],\n",
      "        [-2.2415e-03,  1.3351e-02, -1.4609e-03,  4.5206e-03],\n",
      "        [ 1.3945e-03,  1.3819e-02,  1.9265e-03,  1.1644e-02],\n",
      "        ...,\n",
      "        [ 3.9952e-03,  7.1061e-03,  5.7156e-03,  7.3389e-04],\n",
      "        [-2.8220e-04, -1.2635e-04,  1.0577e-04,  9.5928e-05],\n",
      "        [-2.8220e-04, -1.2635e-04,  1.0577e-04,  9.5928e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-1.1335e-02,  1.0236e-02,  1.1158e-02,  1.1139e-02],\n",
      "        [-1.0630e-02,  2.0765e-02,  2.7268e-02, -1.3859e-02],\n",
      "        [ 1.6361e-03,  7.5252e-03,  6.3805e-03,  4.7402e-03],\n",
      "        ...,\n",
      "        [ 4.8565e-03,  1.3571e-02, -2.3587e-04, -5.0250e-04],\n",
      "        [ 7.8805e-03,  6.2373e-03,  8.1054e-04,  4.8437e-03],\n",
      "        [-3.1188e-04, -1.5280e-04,  9.6004e-05,  9.7629e-05]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Process Process-3:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 201, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 201, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 201, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 1033, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 1033, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 1033, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 1049, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 1049, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 1049, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f85e80540d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/minhnh/python_venv/cv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/home/minhnh/python_venv/cv/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 1819344) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/train.py:97\u001b[0m\n\u001b[1;32m     93\u001b[0m         init_processes(dataset, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, cfg)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/train.py:93\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining on sigle GPU\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m---> 93\u001b[0m     \u001b[43minit_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/train.py:24\u001b[0m, in \u001b[0;36minit_processes\u001b[0;34m(dataset, rank, world_size, gpu_id, cfg)\u001b[0m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# print(\"Backbone\", model.backbone.conv1.weight.device)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mTrainLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msamples_per_gpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresume_checkpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mworkers_per_gpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m dist\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[1;32m     37\u001b[0m cleanup()\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/scripts/train_ddp_util.py:193\u001b[0m, in \u001b[0;36mTrainLoop.run_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_sampler\u001b[38;5;241m.\u001b[39mset_epoch(epoch)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata:\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/scripts/train_ddp_util.py:234\u001b[0m, in \u001b[0;36mTrainLoop.run_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_lr()\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m took_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_trainer\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m took_step:\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/scripts/train_ddp_util.py:253\u001b[0m, in \u001b[0;36mTrainLoop.forward_backward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    252\u001b[0m     log_loss_dict(outputs)\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmp_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/minhnh/project_drive/CV/FewshotObjectDetection/VoxDet-simplified/scripts/fp16_util.py:181\u001b[0m, in \u001b[0;36mMixedPrecisionTrainer.backward\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    179\u001b[0m     (loss \u001b[38;5;241m*\u001b[39m loss_scale)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 181\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/minhnh/python_venv/cv/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/minhnh/python_venv/cv/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run train.py --cuda_devices 0,1,2,3 --phase detection --config configs/train_detection_conf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
